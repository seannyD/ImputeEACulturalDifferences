}
#
phy <- getGlottologTree("atla1278","glottoid")
phy
?readLines
phy <- getGlottologTree("atla1278","glottoid", langNodesToTips = T)
phy
'gola1255' %in% phy$tip.labels
plot(phy)
d = read.csv("~/Downloads/midata8613.csv")
head(d)
d$X.Date
as.Date(d$X.Date)
as.Date(as.character(d$X.Date))
?as.Date(as.character(d$X.Date))
as.Date(as.character(d$X.Date),"%d/%m/%Y")
d$date = as.Date(as.character(d$X.Date),"%d/%m/%Y")
plot(d$Balance,d$date)
plot(d$Balance~d$date)
plot(d$date,d$Balance)
plot(d$date,d$Balance, type = 'line')
head(d)
head(d$Balance)
d$Balance = as.numeric(d$Balance)
d$Balance
d$date = as.Date(as.character(d$X.Date),"%d/%m/%Y")
d$date = as.Date(as.character(d$X.Date),"%d/%m/%Y")
as.numeric(as.character(substring(d$Balance,2))
head(d$Balance)
as.numeric(as.character(substring(d$Balance,2)))
d$date = as.Date(as.character(d$X.Date),"%d/%m/%Y")
head(d$Balance)
d = read.csv("~/Downloads/midata8613.csv")
d$date = as.Date(as.character(d$X.Date),"%d/%m/%Y")
head(d$Balance)
as.numeric(as.character(substring(d$Balance,2)))
substring(d$Balance,2)
?substring(d$Balance,2)
X = head(d$Balance)
X
d$Balance = as.character(d$Balance)
d$Balance
X = head(d$Balance)
substring(X,2)
substring(X,1)
substring(X,4)
substring(X,3)
as.numeric(as.character(substring(d$Balance,3)))
d = read.csv("~/Downloads/midata8613.csv")
d$date = as.Date(as.character(d$X.Date),"%d/%m/%Y")
d$Balance = as.character(d$Balance)
d$Balance = as.numeric(as.character(substring(d$Balance,3)))
plot(d$date,d$Balance, type = 'line')
abline(as.Date(2017-01-01))
abline(v=as.Date(2017-01-01))
abline(h=as.Date(2017-01-01))
as.Date(2017-01-01)
abline(h=as.Date("2017-01-01"))
abline(v=as.Date("2017-01-01"))
abline(v=as.Date("2017-02-01"))
abline(v=as.Date("2017-03-01"))
d
d[45:46,]
factor(10)
factorial(10)
factorial(20)
numberOfSamples = 137
numberOfSamples/2
68 + 68
d = read.csv("~/Documents/MPI/LuisM_K_Pronoun/data/Alldata_simple.csv", stringsAsFactors = F)
head(d)
names(d)
g = read.csv("~/Documents/MPI/Glottolog/glottolog-languoid.csv/languoid.csv",stringsAsFactors = F)
names(g)
g$family = g[match(g$family_pk,g$pk),]$name
head(g$id)
d$family = g[match(d$glotto,g$id),]$family
head(d$family)
table(d$family)
d2 = d[d$family=="Uto-Aztecan",]
table(d2$meaning.id)
table(d2$Language)
d = read.delim("~/Documents/MPI/LuisM_K_Pronoun/BEAST_analysis/models/2017/relaxedClock_excludeSmall/relaxedClock_resampled.log",sep="\t", skip = 790, nrows = 10)
head(d)
plot(d$posterior)
d = read.delim("~/Documents/MPI/LuisM_K_Pronoun/BEAST_analysis/models/2017/relaxedClock_excludeSmall/relaxedClock_resampled.log",sep="\t", skip = 790, nrows = 20000)
plot(d$posterior)
plot(log(d$posterior))
plot(log(absd$posterior))
plot(log(abs(d$posterior)))
plot((d$posterior))
plot((d$posterior[3:nrow(d)]))
library(RColorBrewer)
RColorBrewer::display.brewer.all()
?RColorBrewer::display.brewer.all()
?display.brewer.all()
RColorBrewer::display.brewer.all(colorblindFriendly=T)
?display.brewer.all(colorblindFriendly=T)
brewer.pal(4,'Dark2')
plot(1:4,col=brewer.pal(4,'Dark2'),pch=15, cex=4)
plot(1:4,col=brewer.pal(4,'Set2'),pch=15, cex=4)
plot(1:6,col=brewer.pal(6,'Set2'),pch=15, cex=4)
plot(1:6,col=brewer.pal(6,'Dark2'),pch=15, cex=4)
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/processing/")
l = read.delim("../data/FAIR_languages.tab", stringsAsFactors = F)
g = read.csv("../data/glottolog-languoid.csv/languoid.csv", stringsAsFactors = F)
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/processing/")
l = read.delim("../data/FAIR_languages.tab", stringsAsFactors = F)
g = read.csv("../data/glottolog-languoid.csv/languoid.csv", stringsAsFactors = F)
head(g)
head(l)
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/processing/")
l = read.delim("../data/FAIR_languages.tab", stringsAsFactors = F)
g = read.csv("../data/glottolog-languoid.csv/languoid.csv", stringsAsFactors = F)
l$glotto = g[match(g$name,l$Language),]$id
l$glotto = g[match(l$Language,g$name),]$id
head(k)
head(l)
sum(!is.na(l$glotto))
sum(is.na(l$glotto))
l$Language[is.na(l$glotto)]
l2 = l[is.na(l$glotto),]
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/processing/")
l = read.delim("../data/FAIR_languages.tab", stringsAsFactors = F)
l$Language2 = gsub("_"," ",l$Language)
g = read.csv("../data/glottolog-languoid.csv/languoid.csv", stringsAsFactors = F)
l$glotto = g[match(l$Language,g$name),]$id
sum(is.na(l$glotto))
l2 = l[is.na(l$glotto),]
write.table(l2, "../data/FAIR_languages_missing.tab")
l$Language2
l$glotto = g[match(l$Language2,g$name),]$id
sum(is.na(l$glotto))
l2 = l[is.na(l$glotto),]
l2
write.table(l2, "../data/FAIR_languages_missing.tab")
names(g)
g2 = read.csv("../data/languages-and-dialects-geo.csv", stringsAsFactors = F)
dim(g2)
dim(g)
head(g2)
write.table(l2, "../data/FAIR_languages_missing.tab", quote = F, row.names = F)
write.table(l2[,1], "../data/FAIR_languages_missing.tab", quote = F, row.names = F)
l3 = read.delim("../data/FAIR_languages_missing_edited.tab", sep='\t', quote = "", stringsAsFactors = F)
head(l3)
l3
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/processing/")
l = read.delim("../data/FAIR_languages.tab", stringsAsFactors = F)
l$Language2 = gsub("_"," ",l$Language)
g = read.csv("../data/glottolog-languoid.csv/languoid.csv", stringsAsFactors = F)
l$glotto = g[match(l$Language2,g$name),]$id
sum(is.na(l$glotto))
l2 = l[is.na(l$glotto),]
write.table(l2[,1], "../data/FAIR_languages_missing.tab", quote = F, row.names = F)
l3 = read.delim("../data/FAIR_languages_missing_edited.tab", sep='\t', quote = "", stringsAsFactors = F)
dpid = read.csv("../data/dplace-data-1.0/csv/xd_id_to_language.csv", stringsAsFactors = F)
l[is.na(l$glotto),]$glotto = l3[match(l[is.na(l$glotto),]$Language, l3$Lang),]$glotto
head(l)
sum(is.na(l$glotto))
sum(l$glotto=="")
names(dpid)
head(dpid)
l$xd.id = dpid[match(l$glotto,dpid$DialectLanguageGlottocode),]$xd_id
head(l)
l = l[!is.na(l$xd.id),]
dim(l)
l
write.csv("../data/FAIR_langauges_glotto_xdid.csv", row.names = F)
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/processing/")
l = read.delim("../data/FAIR_languages.tab", stringsAsFactors = F)
l$Language2 = gsub("_"," ",l$Language)
g = read.csv("../data/glottolog-languoid.csv/languoid.csv", stringsAsFactors = F)
l$glotto = g[match(l$Language2,g$name),]$id
sum(is.na(l$glotto))
l2 = l[is.na(l$glotto),]
write.table(l2[,1], "../data/FAIR_languages_missing.tab", quote = F, row.names = F)
l3 = read.delim("../data/FAIR_languages_missing_edited.tab", sep='\t', quote = "", stringsAsFactors = F)
l[is.na(l$glotto),]$glotto = l3[match(l[is.na(l$glotto),]$Language, l3$Lang),]$glotto
l = l[!is.na(l$glotto),]
l = l[l$glotto!="",]
dpid = read.csv("../data/dplace-data-1.0/csv/xd_id_to_language.csv", stringsAsFactors = F)
l$xd.id = dpid[match(l$glotto,dpid$DialectLanguageGlottocode),]$xd_id
l = l[!is.na(l$xd.id),]
write.csv(l,"../data/FAIR_langauges_glotto_xdid.csv", row.names = F)
sccs = read.csv("../data/dplace_SCCS/societies.csv")
head(sccs)
sum(sccs$xd_id %in% l$xd.id)
sccs = read.csv("../data/dplace_SCCS/societies.csv", stringsAsFactors = F)
sum(sccs$xd_id %in% l$xd.id)
ea = read.csv("../data/dplace-data-1.0/csv/EA_societies.csv", stringsAsFactors = F)
head(ea)
names(ea)
sum(ea$xd_id %in% l$xd.id)
dim(l)
ead = read.csv("../data/dplace-data-1.0/csv/EA_data.csv", stringsAsFactors = F)
dim(ead)
names(ead)
head(ea)
names(ea)
l$soc_id = ea[match(l$xd.id,ea$xd_id),]$soc_id
sum(is.na(l$soc_id))
ead = ead[ead$soc_id %in% l$soc_id,]
dim(ead)
library(tidyr)
library(mice)
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/processing/")
l = read.csv("../data/FAIR_langauges_glotto_xdid.csv", stringsAsFactors = F)
eav = read.csv("../data/dplace-data-1.0/csv/EAVariableList.csv", stringsAsFactors = F)
ead = read.csv("../data/dplace-data-1.0/csv/EA_data.csv", stringsAsFactors = F)
l$Language
dim(ead)
length(unique(ead$soc_id))
?spread
dim(l)
sum(is.na(ead))
sum(is.na(ead))/prod(dim(ead))
names(ead)
sum(is.na(ead$Code))
sum(is.na(ead$Code))/nrow(ead)
names(ead)[!names(ead) %in% c("Dataset","SubCase",'Year','VarID_Code',"Comment","EthnoReferences","SourceCodedData","AdminComment")]
ead = ead[,c("soc_id", "VarID",  "Code")]
eadx = spread(data = ead, VarID, Code)
dim(eadx)
names(eadx)
numObs = apply(eadx,2,function(X){sum(!is.na(X))})
numObs
eadx = eadx[,names(eadx) %in% names(numObs[numObs>60])]
numLangs = apply(eadx,1,function(X){sum(is.na(X))})
eadx = eadx[numLangs<20,]
dim(eadx)
sum(is.na(eadx[,2:ncol(eadx)])) / prod(dim(eadx[,2:ncol(eadx)]))
# Convert to factor
for(i in 2:ncol(eadx)){
eadx[,i] = as.factor(eadx[,i])
}
set = 1
paste0("../data/EA_imputed/EADX_Imputed",set,".csv")
?mice
head(eadx)
library(tidyr)
library(mice)
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/processing/")
l = read.csv("../data/FAIR_langauges_glotto_xdid.csv", stringsAsFactors = F)
eav = read.csv("../data/dplace-data-1.0/csv/EAVariableList.csv", stringsAsFactors = F)
ead = read.csv("../data/dplace-data-1.0/csv/EA_data.csv", stringsAsFactors = F)
# Proportion of missing data
sum(is.na(ead$Code))/nrow(ead)
# restrict societies to those in the facebook sample
ead = ead[ead$soc_id %in% l$soc.id,]
#ead = ead[,!names(ead) %in% c("Dataset","SubCase",'Year','VarID_Code',"Comment","EthnoReferences","SourceCodedData","AdminComment")]
ead = ead[,c("soc_id", "VarID",  "Code")]
eadx = spread(data = ead, VarID, Code)
# remove pop size
eadx = eadx[,names(eadx)!="202"]
numObs = apply(eadx,2,function(X){sum(!is.na(X))})
eadx = eadx[,names(eadx) %in% names(numObs[numObs>60])]
numLangs = apply(eadx,1,function(X){sum(is.na(X))})
eadx = eadx[numLangs<20,]
# missing data
sum(is.na(eadx[,2:ncol(eadx)])) / prod(dim(eadx[,2:ncol(eadx)]))
# Convert to factor
for(i in 2:ncol(eadx)){
eadx[,i] = as.factor(eadx[,i])
}
# impute 5 datasets
eadx.imputed = mice(data = eadx[,2:ncol(eadx)],
m=5, method='cart')
eadx = eadx[sample(1:nrow(eadx),10),1:10]
eadx.imputed = mice(data = eadx[,2:ncol(eadx)],
m=5, method='cart')
library(tidyr)
library(mice)
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/processing/")
l = read.csv("../data/FAIR_langauges_glotto_xdid.csv", stringsAsFactors = F)
eav = read.csv("../data/dplace-data-1.0/csv/EAVariableList.csv", stringsAsFactors = F)
ead = read.csv("../data/dplace-data-1.0/csv/EA_data.csv", stringsAsFactors = F)
# Proportion of missing data
sum(is.na(ead$Code))/nrow(ead)
# restrict societies to those in the facebook sample
ead = ead[ead$soc_id %in% l$soc.id,]
#ead = ead[,!names(ead) %in% c("Dataset","SubCase",'Year','VarID_Code',"Comment","EthnoReferences","SourceCodedData","AdminComment")]
ead = ead[,c("soc_id", "VarID",  "Code")]
eadx = spread(data = ead, VarID, Code)
# remove pop size
eadx = eadx[,names(eadx)!="202"]
numObs = apply(eadx,2,function(X){sum(!is.na(X))})
eadx = eadx[,names(eadx) %in% names(numObs[numObs>60])]
numLangs = apply(eadx,1,function(X){sum(is.na(X))})
eadx = eadx[numLangs<20,]
# missing data
sum(is.na(eadx[,2:ncol(eadx)])) / prod(dim(eadx[,2:ncol(eadx)]))
# Convert to factor
for(i in 2:ncol(eadx)){
eadx[,i] = as.factor(eadx[,i])
}
eadx = eadx[sample(1:nrow(eadx),10),1:10]
eadx.imputed = mice(data = eadx[,2:ncol(eadx)],
m=5, method='cart')
library(tidyr)
library(mice)
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/processing/")
l = read.csv("../data/FAIR_langauges_glotto_xdid.csv", stringsAsFactors = F)
eav = read.csv("../data/dplace-data-1.0/csv/EAVariableList.csv", stringsAsFactors = F)
ead = read.csv("../data/dplace-data-1.0/csv/EA_data.csv", stringsAsFactors = F)
# Proportion of missing data
sum(is.na(ead$Code))/nrow(ead)
# restrict societies to those in the facebook sample
ead = ead[ead$soc_id %in% l$soc.id,]
#ead = ead[,!names(ead) %in% c("Dataset","SubCase",'Year','VarID_Code',"Comment","EthnoReferences","SourceCodedData","AdminComment")]
ead = ead[,c("soc_id", "VarID",  "Code")]
eadx = spread(data = ead, VarID, Code)
# remove pop size
eadx = eadx[,names(eadx)!="202"]
numObs = apply(eadx,2,function(X){sum(!is.na(X))})
eadx = eadx[,names(eadx) %in% names(numObs[numObs>60])]
numLangs = apply(eadx,1,function(X){sum(is.na(X))})
eadx = eadx[numLangs<20,]
# missing data
sum(is.na(eadx[,2:ncol(eadx)])) / prod(dim(eadx[,2:ncol(eadx)]))
# Convert to factor
for(i in 2:ncol(eadx)){
eadx[,i] = as.factor(eadx[,i])
}
eadx = eadx[sample(1:nrow(eadx),10),c(1,sample(1:ncol(eadx),10))]
eadx.imputed = mice(data = eadx[,2:ncol(eadx)],
m=5, method='cart')
eadx.imputed = mice(data = eadx,#[,2:ncol(eadx)],
m=5, method='cart')
dim(eadx)
eadx
eadx.imputed = mice(data = eadx[,2:ncol(eadx)],
m=5, method='cart')
for(i in 2:ncol(eadx)){
eadx[,i] = as.factor(eadx[,i])
}
eadx.imputed = mice(data = eadx[,2:ncol(eadx)],
m=5, method='cart')
eadx
eadx[,2:ncol(eadx)]
eadx[,2:ncol(eadx)][,1]
eadx.imputed = mice(data = eadx[,2:ncol(eadx)],
m=1, method='cart')
eadx = eadx[sample(1:nrow(eadx),100),c(1,sample(1:ncol(eadx),10))]
library(tidyr)
library(mice)
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/processing/")
l = read.csv("../data/FAIR_langauges_glotto_xdid.csv", stringsAsFactors = F)
eav = read.csv("../data/dplace-data-1.0/csv/EAVariableList.csv", stringsAsFactors = F)
ead = read.csv("../data/dplace-data-1.0/csv/EA_data.csv", stringsAsFactors = F)
# Proportion of missing data
sum(is.na(ead$Code))/nrow(ead)
# restrict societies to those in the facebook sample
ead = ead[ead$soc_id %in% l$soc.id,]
#ead = ead[,!names(ead) %in% c("Dataset","SubCase",'Year','VarID_Code',"Comment","EthnoReferences","SourceCodedData","AdminComment")]
ead = ead[,c("soc_id", "VarID",  "Code")]
eadx = spread(data = ead, VarID, Code)
# remove pop size
eadx = eadx[,names(eadx)!="202"]
numObs = apply(eadx,2,function(X){sum(!is.na(X))})
eadx = eadx[,names(eadx) %in% names(numObs[numObs>60])]
numLangs = apply(eadx,1,function(X){sum(is.na(X))})
eadx = eadx[numLangs<20,]
# missing data
sum(is.na(eadx[,2:ncol(eadx)])) / prod(dim(eadx[,2:ncol(eadx)]))
# Convert to factor
for(i in 2:ncol(eadx)){
eadx[,i] = as.factor(eadx[,i])
}
eadx = eadx[sample(1:nrow(eadx),100),c(1,sample(1:ncol(eadx),10))]
dim(eadx)
library(tidyr)
library(mice)
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/processing/")
l = read.csv("../data/FAIR_langauges_glotto_xdid.csv", stringsAsFactors = F)
eav = read.csv("../data/dplace-data-1.0/csv/EAVariableList.csv", stringsAsFactors = F)
ead = read.csv("../data/dplace-data-1.0/csv/EA_data.csv", stringsAsFactors = F)
# Proportion of missing data
sum(is.na(ead$Code))/nrow(ead)
# restrict societies to those in the facebook sample
#ead = ead[ead$soc_id %in% l$soc.id,]
#ead = ead[,!names(ead) %in% c("Dataset","SubCase",'Year','VarID_Code',"Comment","EthnoReferences","SourceCodedData","AdminComment")]
ead = ead[,c("soc_id", "VarID",  "Code")]
eadx = spread(data = ead, VarID, Code)
# remove pop size
eadx = eadx[,names(eadx)!="202"]
numObs = apply(eadx,2,function(X){sum(!is.na(X))})
eadx = eadx[,names(eadx) %in% names(numObs[numObs>60])]
numLangs = apply(eadx,1,function(X){sum(is.na(X))})
eadx = eadx[numLangs<20,]
# missing data
sum(is.na(eadx[,2:ncol(eadx)])) / prod(dim(eadx[,2:ncol(eadx)]))
# Convert to factor
for(i in 2:ncol(eadx)){
eadx[,i] = as.factor(eadx[,i])
}
eadx = eadx[sample(1:nrow(eadx),100),c(1,sample(1:ncol(eadx),10))]
ead$soc_id
eas = read.csv("../data/dplace-data-1.0/csv/EA_societies.csv", stringsAsFactors = F)
head(eas)
names(eas)
l = read.csv("../data/FAIR_langauges_glotto_xdid.csv", stringsAsFactors = F)
head(l)
dim(l)
head(ead)
ead = read.csv("../data/dplace-data-1.0/csv/EA_data.csv", stringsAsFactors = F)
head(ead)
eag = read.csv("../data/dplace-data-1.0/csv/xd_id_to_language.csv", stringsAsFactors = F)
head(eag)
names(eag)
eag$FamilyLevel
names(eag)
FamilyGlottocode
eag$FamilyGlottocode
eag$FamilyGlottocode
head(eag)
ead = read.csv("../data/dplace-data-1.0/csv/EA_data.csv", stringsAsFactors = F)
names(ead)
eas = read.csv("../data/dplace-data-1.0/csv/EA_societies.csv")
head(eas)
eag$FamilyGlottocode
sort(table(eag$FamilyGlottocode))
library(tidyr)
library(mice)
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/processing/")
l = read.csv("../data/FAIR_langauges_glotto_xdid.csv", stringsAsFactors = F)
eav = read.csv("../data/dplace-data-1.0/csv/EAVariableList.csv", stringsAsFactors = F)
ead = read.csv("../data/dplace-data-1.0/csv/EA_data.csv", stringsAsFactors = F)
# Load society data
eag = read.csv("../data/dplace-data-1.0/csv/xd_id_to_language.csv", stringsAsFactors = F)
eas = read.csv("../data/dplace-data-1.0/csv/EA_societies.csv")
# Proportion of missing data
sum(is.na(ead$Code))/nrow(ead)
# restrict societies to those in the facebook sample
#ead = ead[ead$soc_id %in% l$soc.id,]
#ead = ead[,!names(ead) %in% c("Dataset","SubCase",'Year','VarID_Code',"Comment","EthnoReferences","SourceCodedData","AdminComment")]
ead = ead[,c("soc_id", "VarID",  "Code")]
eadx = spread(data = ead, VarID, Code)
xid = eas[match(eadx$soc_id, eas$soc_id),]$xd_id
eadx$Family = eag[match(xid,eag$xd_id),]$FamilyGlottocode
head(eadx)
eas[eas$soc_id=="Aa2",]
library(tidyr)
library(mice)
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/processing/")
l = read.csv("../data/FAIR_langauges_glotto_xdid.csv", stringsAsFactors = F)
eav = read.csv("../data/dplace-data-1.0/csv/EAVariableList.csv", stringsAsFactors = F)
ead = read.csv("../data/dplace-data-1.0/csv/EA_data.csv", stringsAsFactors = F)
# Load society data
eag = read.csv("../data/dplace-data-1.0/csv/xd_id_to_language.csv", stringsAsFactors = F)
eas = read.csv("../data/dplace-data-1.0/csv/EA_societies.csv")
# Proportion of missing data
sum(is.na(ead$Code))/nrow(ead)
# restrict societies to those in the facebook sample
#ead = ead[ead$soc_id %in% l$soc.id,]
#ead = ead[,!names(ead) %in% c("Dataset","SubCase",'Year','VarID_Code',"Comment","EthnoReferences","SourceCodedData","AdminComment")]
ead = ead[,c("soc_id", "VarID",  "Code")]
eadx = spread(data = ead, VarID, Code)
xid = eas[match(eadx$soc_id, eas$soc_id),]$xd_id
eadx$Family = eag[match(xid,eag$xd_id),]$FamilyGlottocode
# remove pop size
eadx = eadx[,names(eadx)!="202"]
numObs = apply(eadx,2,function(X){sum(!is.na(X))})
eadx = eadx[,names(eadx) %in% names(numObs[numObs>60])]
numLangs = apply(eadx,1,function(X){sum(is.na(X))})
eadx = eadx[numLangs<20,]
# missing data
sum(is.na(eadx[,2:ncol(eadx)])) / prod(dim(eadx[,2:ncol(eadx)]))
names(eadx)
sum(is.na(eadx[,2:(ncol(eadx)-1)])) / prod(dim(eadx[,2:ncol(eadx)]))
for(i in 2:ncol(eadx)){
eadx[,i] = as.factor(eadx[,i])
}
eadx$Family
eadx = eadx[sample(1:nrow(eadx),100),]
eadx.imputed = mice(data = eadx[,2:ncol(eadx)],
m=5, method='cart')
eadx = eadx[sample(1:nrow(eadx),100),c(2,3,4,ncol(eadx))]
eadx.imputed = mice(data = eadx[,2:ncol(eadx)],
m=5, method='cart')
# USE the mice package to do multiple imputation.
# The method used is classification trees.
#  Language family is added as a variable with which the tree can make guesses about the missing data, allowing some control for language-family-specific tendencies.
library(tidyr)
library(mice)
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/processing/")
l = read.csv("../data/FAIR_langauges_glotto_xdid.csv", stringsAsFactors = F)
eav = read.csv("../data/dplace-data-1.0/csv/EAVariableList.csv", stringsAsFactors = F)
ead = read.csv("../data/dplace-data-1.0/csv/EA_data.csv", stringsAsFactors = F)
# Load society data
eag = read.csv("../data/dplace-data-1.0/csv/xd_id_to_language.csv", stringsAsFactors = F)
eas = read.csv("../data/dplace-data-1.0/csv/EA_societies.csv")
# Proportion of missing data
sum(is.na(ead$Code))/nrow(ead)
# restrict societies to those in the facebook sample
#ead = ead[ead$soc_id %in% l$soc.id,]
#ead = ead[,!names(ead) %in% c("Dataset","SubCase",'Year','VarID_Code',"Comment","EthnoReferences","SourceCodedData","AdminComment")]
ead = ead[,c("soc_id", "VarID",  "Code")]
eadx = spread(data = ead, VarID, Code)
xid = eas[match(eadx$soc_id, eas$soc_id),]$xd_id
eadx$Family = eag[match(xid,eag$xd_id),]$FamilyGlottocode
# remove pop size
eadx = eadx[,names(eadx)!="202"]
numObs = apply(eadx,2,function(X){sum(!is.na(X))})
eadx = eadx[,names(eadx) %in% names(numObs[numObs>60])]
numLangs = apply(eadx,1,function(X){sum(is.na(X))})
eadx = eadx[numLangs<20,]
# missing data
sum(is.na(eadx[,2:(ncol(eadx)-1)])) / prod(dim(eadx[,2:ncol(eadx)]))
# Convert to factor
for(i in 2:ncol(eadx)){
eadx[,i] = as.factor(eadx[,i])
}

obS = g %>% gs_read(ws=sheetName)
obS = as.data.frame(obS)
if(names(obS)[1]=="Object"){
return(c(type="Object",
name=sheetName,
json=processObject(obS,sheetName)))
}
if(names(obS)[1]=="Item"){
return(c(type="Item",
name=sheetName,
json=processItem(obS,sheetName)))
}
}
processObject = function(obS,objectSheetName){
properties = obS[1:(which(obS[,1]=="Command")-1),2]
names(properties) = obS[1:(which(obS[,1]=="Command")-1),1]
obCommands = obS[(which(obS[,1]=="Command")+1):nrow(obS),]
names(obCommands) = obS[which(obS[,1]=="Command"),]
obProperties = paste0(
paste(names(properties),":",
sapply(properties, function(p){
if(p=="N" || p=="Y"){
p = c("false",'true')[(p=="Y")+1]
}else{
if(is.na(as.numeric(p))){
p = paste0('"',p,'"')
}
}
return(p)
})),
collapse=",\n"
)
obCommands = obCommands[!is.na(obCommands$Command),]
obCommands = obCommands[obCommands$Command!="",]
obCommands$Command = gsub('"',"",obCommands$Command)
obCommands$Command = gsub(' +'," ",obCommands$Command)
obCommands$Command = tolower(obCommands$Command)
obCommands$ReturnMessage = gsub('"',"'",obCommands$ReturnMessage)
obCommands = as.data.frame(obCommands)
entries = sapply(1:nrow(obCommands), function(i){
paste0('"',obCommands$Command[i],'":{\n',
paste("\t",sapply(colnames(obCommands)[2:ncol(obCommands)], function(col){
value = obCommands[i,col]
if(is.na(as.numeric(value))){
value = paste0('"',value,'"')
}
paste0('"',col,'":',value)
}),collapse=",\n"),"}")
})
commandDetails = paste0(entries,collapse=",\n")
ret = paste0('"',objectSheetName,'":{',
obProperties,",\n",
"commands : {",
commandDetails,
"}}",collapse="")
return(ret)
}
processItem = function(obS,objectSheetName){
properties = obS[,2]
names(properties) = obS[,1]
obProperties = paste0(
paste(names(properties),":",
sapply(properties, function(p){
if(p=="N" || p=="Y"){
p = c("false",'true')[(p=="Y")+1]
}else{
if(is.na(as.numeric(p))){
p = paste0('"',p,'"')
}
}
return(p)
})),
collapse=",")
paste0("{",obProperties,"}")
}
##################
gx = gs_ls()
g = gs_key("1uWWM6Qvn3P5XZYMErD1TalOIMdbv4q2H80bZwdNRauI")
mapObjects = gs_ws_ls(g)
mapObjects = mapObjects[mapObjects!="map"]
#library(jsonlite)
mapObjectAndItemsParts = sapply(mapObjects, processItemsAndObjects)
#mapObjectParts = prettify(paste0("{\n",paste0(mapObjectParts,collapse=",\n"),"\n}"),)
mapObjectAndItemsParts = as.data.frame(t(as.data.frame(mapObjectAndItemsParts,stringsAsFactors=F)),stringsAsFactors = F)
mapObjectJSON = mapObjectAndItemsParts[mapObjectAndItemsParts$type=="Object",]$json
mapObjectJSON = paste0("map_objects = {\n",paste0(mapObjectJSON,collapse=",\n"),"}")
mapItemParts = mapObjectAndItemsParts[mapObjectAndItemsParts$type=="Item",]
######################
###### ROOMS
d = g %>% gs_read(ws="map")
d = as.matrix(d)
d[is.na(d)] = ""
roomJSONS = list()
startRooms = c()
roomItemsToAdd = data.frame();
for(i in 1:ncol(d)){
for(j in 1:nrow(d)){
roomName = paste0("R",i,"X",j)
exits = getExits(i,j)
if(length(exits)>0){
description = d[j,i]
if(grepl("START:",description)){
startRooms = c(startRooms,roomName)
}
roomJSONS = c(roomJSONS,
makeRoomJSON(roomName,
description,
exits))
}
}
}
mapJSON = paste0("map = {\n",
paste(roomJSONS,collapse=",\n"),
"\n}")
startJSON = paste0("map_start_rooms = [",
paste(shQuote(startRooms),collapse=","),
"]")
####################
# Put everything together
totalJSON = paste0(mapJSON,"\n",startJSON,"\n",mapObjectJSON)
#prettify(totalJSON)
cat(totalJSON, file="../../lib/map.js")
# Download the google sheet:
# https://docs.google.com/spreadsheets/d/1uWWM6Qvn3P5XZYMErD1TalOIMdbv4q2H80bZwdNRauI/edit#gid=0
# And make a json
try(setwd("/Library/WebServer/Documents/Halloween/SGT6/build/map/"))
library(dplyr)
library(googlesheets)
library(stringr)
isOdd = function(x){
(x %% 2) == 1
}
isEven = function(x){
(x %% 2)==0
}
getExits = function(i,j){
if(is.na(d[j,i])){
return(list())
}
if(d[j,i]=="Z" || d[j,i]==""){
return(list())
}
if(!(isOdd(j) && isEven(i))){
# Not a room square
return(list())
}
exits = list()
if(i<ncol(d) && nchar(d[j,i+1])>0){
exits[[length(exits)+1]] = c("E",paste0("R",i+2,"X",j),d[j,i+1])
}
if(i>1 && nchar(d[j,i-1])>0){
exits[[length(exits)+1]] = c("W",paste0("R",i-2,"X",j),d[j,i-1])
}
if(j<nrow(d) && nchar(d[j+1,i])>0){
exits[[length(exits)+1]] = c("S",paste0("R",i,"X",j+2),d[j+1,i])
}
if(j>1 && nchar(d[j-1,i])>0){
exits[[length(exits)+1]] = c("N",paste0("R",i,"X",j-2),d[j-1,i])
}
return(exits)
}
makeRoomObjects = function(roomDescription){
rob = str_extract_all(roomDescription,"\\[[^\\]]+\\]")[[1]]
rob = gsub("\\[","",rob)
rob = gsub("\\]","",rob)
if(length(rob)>0){
for(rx in rob){
if(!(rx %in% mapObjectAndItemsParts$name)){
warning(paste("No definition for [",rx,"]"))
}
}
ritems = rob[rob %in% mapObjectAndItemsParts[mapObjectAndItemsParts$type=="Item",]$name]
ritemsJSON = "items:[]"
if(length(ritems)>0){
ritemsX = mapObjectAndItemsParts[mapObjectAndItemsParts$name %in% ritems,]$json
ritemsJSON = paste0("items:[",paste0(ritemsX,collapse=","),"]")
}
rob = rob[rob %in% mapObjectAndItemsParts[mapObjectAndItemsParts$type=="Object",]$name]
robJSON = "objects:[]"
if(length(rob)>0){
robJSON = paste0("objects:[",paste0(paste0('"',rob,'"'),collapse=","),"]")
}
return(paste0(robJSON,",",ritemsJSON))
} else{
return("objects:[],items:[]")
}
}
makeRoomJSON = function(roomName,description,exits){
gsub("  +"," ",description)
if(substr(
description,nchar(description),
nchar(description)+1)!="."){
description = paste0(description,".")
}
description = paste0('"',
gsub('"',"'",description),
'"')
description = gsub("START:","",description)
roomObjects = makeRoomObjects(description)
# Remove items and objects
description = gsub("\\[.+\\]","",description)
description = gsub("  +"," ",description)
paste0(roomName,
":{description:",description,",",
"exits:{",
paste(
sapply(exits,function(X){
open = "true"
key = X[3]
if(key!="X"){
return(paste0(X[1],":{destination:",'"',X[2],'",',
'key:"',key,'",open:false',
'}'))
} else{
return(paste0(X[1],":{destination:",'"',X[2],'"}'))
}
}), collapse=','),
"}",
",",roomObjects,
"}"
)
}
####################
##### Objects
processItemsAndObjects = function(sheetName){
obS = g %>% gs_read(ws=sheetName)
obS = as.data.frame(obS)
if(names(obS)[1]=="Object"){
return(c(type="Object",
name=sheetName,
json=processObject(obS,sheetName)))
}
if(names(obS)[1]=="Item"){
return(c(type="Item",
name=sheetName,
json=processItem(obS,sheetName)))
}
}
processObject = function(obS,objectSheetName){
properties = obS[1:(which(obS[,1]=="Command")-1),2]
names(properties) = obS[1:(which(obS[,1]=="Command")-1),1]
obCommands = obS[(which(obS[,1]=="Command")+1):nrow(obS),]
names(obCommands) = obS[which(obS[,1]=="Command"),]
obProperties = paste0(
paste(names(properties),":",
sapply(properties, function(p){
if(p=="N" || p=="Y"){
p = c("false",'true')[(p=="Y")+1]
}else{
if(is.na(as.numeric(p))){
p = paste0('"',p,'"')
}
}
return(p)
})),
collapse=",\n"
)
obCommands = obCommands[!is.na(obCommands$Command),]
obCommands = obCommands[obCommands$Command!="",]
obCommands$Command = gsub('"',"",obCommands$Command)
obCommands$Command = gsub(' +'," ",obCommands$Command)
obCommands$Command = tolower(obCommands$Command)
obCommands$ReturnMessage = gsub('"',"'",obCommands$ReturnMessage)
obCommands = as.data.frame(obCommands)
entries = sapply(1:nrow(obCommands), function(i){
paste0('"',obCommands$Command[i],'":{\n',
paste("\t",sapply(colnames(obCommands)[2:ncol(obCommands)], function(col){
value = obCommands[i,col]
if(is.na(as.numeric(value))){
value = paste0('"',value,'"')
}
paste0('"',col,'":',value)
}),collapse=",\n"),"}")
})
commandDetails = paste0(entries,collapse=",\n")
ret = paste0('"',objectSheetName,'":{',
obProperties,",\n",
"commands : {",
commandDetails,
"}}",collapse="")
return(ret)
}
processItem = function(obS,objectSheetName){
properties = obS[,2]
names(properties) = obS[,1]
obProperties = paste0(
paste(names(properties),":",
sapply(properties, function(p){
if(p=="N" || p=="Y"){
p = c("false",'true')[(p=="Y")+1]
}else{
if(is.na(as.numeric(p))){
p = paste0('"',p,'"')
}
}
return(p)
})),
collapse=",")
paste0("{",obProperties,"}")
}
##################
gx = gs_ls()
g = gs_key("1uWWM6Qvn3P5XZYMErD1TalOIMdbv4q2H80bZwdNRauI")
mapObjects = gs_ws_ls(g)
mapObjects = mapObjects[mapObjects!="map"]
#library(jsonlite)
mapObjectAndItemsParts = sapply(mapObjects, processItemsAndObjects)
#mapObjectParts = prettify(paste0("{\n",paste0(mapObjectParts,collapse=",\n"),"\n}"),)
mapObjectAndItemsParts = as.data.frame(t(as.data.frame(mapObjectAndItemsParts,stringsAsFactors=F)),stringsAsFactors = F)
mapObjectJSON = mapObjectAndItemsParts[mapObjectAndItemsParts$type=="Object",]$json
mapObjectJSON = paste0("map_objects = {\n",paste0(mapObjectJSON,collapse=",\n"),"}")
mapItemParts = mapObjectAndItemsParts[mapObjectAndItemsParts$type=="Item",]
######################
###### ROOMS
d = g %>% gs_read(ws="map")
d = as.matrix(d)
d[is.na(d)] = ""
roomJSONS = list()
startRooms = c()
roomItemsToAdd = data.frame();
for(i in 1:ncol(d)){
for(j in 1:nrow(d)){
roomName = paste0("R",i,"X",j)
exits = getExits(i,j)
if(length(exits)>0){
description = d[j,i]
if(grepl("START:",description)){
startRooms = c(startRooms,roomName)
}
roomJSONS = c(roomJSONS,
makeRoomJSON(roomName,
description,
exits))
}
}
}
mapJSON = paste0("map = {\n",
paste(roomJSONS,collapse=",\n"),
"\n}")
startJSON = paste0("map_start_rooms = [",
paste(shQuote(startRooms),collapse=","),
"]")
####################
# Put everything together
totalJSON = paste0(mapJSON,"\n",startJSON,"\n",mapObjectJSON)
#prettify(totalJSON)
cat(totalJSON, file="../../lib/map.js")
# Take a cultural database and make a distance matrix between societies
library(cluster)
library(reshape2)
library(mclust)
try(setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/processing/"))
# Load society data
eas = read.csv("../data/dplace-data-1.0/csv/EA_societies.csv", stringsAsFactors = F)
# Load data about variables
eav = read.csv("../data/dplace-data-1.0/csv/EAVariableList.csv", stringsAsFactors = F)
# Load language data
l = read.csv("../data/FAIR_langauges_glotto_xdid.csv", stringsAsFactors = F,encoding = "UTF-8",fileEncoding = "UTF-8")
makeDistanceMatrix = function(filename, variables=c(),keepOnlyFAIRLangs=T){
# Load imputed Ethnogrpahic Atlas data
eadx = read.csv(filename, stringsAsFactors = F)
if(keepOnlyFAIRLangs){
# Keep only FAIR langauges
eadx = eadx[eadx$soc_id %in% l$soc.id,]
}
# Remove family and area data
eadx = eadx[,!names(eadx) %in% c("Family","autotyp.area")]
# Optionally only keep some variables
if(length(variables)>0){
eadx = eadx[,names(eadx) %in% variables]
}
# Remove any variables that still have missing data
eadx = eadx[,apply(eadx,2,function(X){sum(is.na(X))==0})]
#eadx = eadx[,names(eadx)!="X69"]
eadx = eadx[names(eadx)!="X",]
# Convert to factor
for(i in 1:ncol(eadx)){
eadx[,i] = as.factor(eadx[,i])
}
# Convert soc_id back to character
eadx$soc_id = as.character(eadx$soc_id)
# names of languages according to Facebook
nx = l[match(eadx$soc_id,l$soc.id),]$Language
rownames(eadx) = nx
# Make distance matrix from factors
#dist = dist(eadx[,2:ncol(eadx)])
dist = daisy(eadx[,-which(names(eadx)=="soc_id")], metric = "gower")
# Convert to regular matrix
dist.m = as.matrix(dist)
rownames(dist.m) = nx
colnames(dist.m) = nx
return(dist.m)
}
###############
files = list.files("../data/EA_imputed/completeDataframes/","*.csv")
distsALL = list()
for(i in 1:length(files)){
print(files[i])
distsALL[[i]] = makeDistanceMatrix(paste0("../data/EA_imputed/completeDataframes/",files[i]), keepOnlyFAIRLangs = F)
}
filename = paste0("../data/EA_imputed/completeDataframes/",files[i])
eadx = read.csv(filename, stringsAsFactors = F)
eadx$soc_id
sum(duplicated(eadx$soc_id))
eadx = eadx[,!names(eadx) %in% c("Family","autotyp.area")]
eadx = eadx[,apply(eadx,2,function(X){sum(is.na(X))==0})]
#eadx = eadx[,names(eadx)!="X69"]
eadx = eadx[names(eadx)!="X",]
# Convert to factor
for(i in 1:ncol(eadx)){
eadx[,i] = as.factor(eadx[,i])
}
eadx$soc_id = as.character(eadx$soc_id)
nx = l[match(eadx$soc_id,l$soc.id),]$Language
duplicated(nx)
nx
dim(l)
head(eas)
head(l)
xdid2lang = read.csv("../data/dplace-data-1.0/csv/xd_id_to_language.csv",stringsAsFactors = F,fileEncoding = "utf-8",encoding = 'utf-8')
head(eadx)
head(xdid2lang)
socid2xdid = read.csv("../data/dplace-data-1.0/csv/EA_societies.csv",stringsAsFactors = F,fileEncoding = "utf-8",encoding = 'utf-8')
xdid2lang$soc_id = socid2xdid[match(xdid2lang$xd_id,socid2xdid$xd_id),]$soc_id
xdid2lang$soc_id
xdid2lang[is.na(xdid2lang$soc_id),]
xdid2lang$xd_id
socid2xdid$xd_id
nx = xdid2lang[match(eadx$soc_id,xdid2lang$soc_id),]$DialectLanguageGlottocode
length(nx)
nx
sum(is.na(nx))
rownames(eadx) = nx
dim(eadx)
length(nx)
nx = xdid2lang[match(eadx$soc_id,xdid2lang$soc_id),]$DialectLanguageGlottocode
nx[duplicated(nx)] = NA
eadx = eadx[!is.na(nx),]
nx = nx[!is.na(nx)]
rownames(eadx) = nx
dist = daisy(eadx[,-which(names(eadx)=="soc_id")], metric = "gower")
dist.m = as.matrix(dist)
rownames(dist.m) = nx
colnames(dist.m) = nx
sum(dist.m)
# Take a cultural database and make a distance matrix between societies
library(cluster)
library(reshape2)
library(mclust)
try(setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/processing/"))
# Load society data
eas = read.csv("../data/dplace-data-1.0/csv/EA_societies.csv", stringsAsFactors = F)
# Load data about variables
eav = read.csv("../data/dplace-data-1.0/csv/EAVariableList.csv", stringsAsFactors = F)
# Load language data
l = read.csv("../data/FAIR_langauges_glotto_xdid.csv", stringsAsFactors = F,encoding = "UTF-8",fileEncoding = "UTF-8")
makeDistanceMatrix = function(filename, variables=c(),keepOnlyFAIRLangs=T){
# Load imputed Ethnogrpahic Atlas data
eadx = read.csv(filename, stringsAsFactors = F)
if(keepOnlyFAIRLangs){
# Keep only FAIR langauges
eadx = eadx[eadx$soc_id %in% l$soc.id,]
}
# Remove family and area data
eadx = eadx[,!names(eadx) %in% c("Family","autotyp.area")]
# Optionally only keep some variables
if(length(variables)>0){
eadx = eadx[,names(eadx) %in% variables]
}
# Remove any variables that still have missing data
eadx = eadx[,apply(eadx,2,function(X){sum(is.na(X))==0})]
#eadx = eadx[,names(eadx)!="X69"]
eadx = eadx[names(eadx)!="X",]
# Convert to factor
for(i in 1:ncol(eadx)){
eadx[,i] = as.factor(eadx[,i])
}
# Convert soc_id back to character
eadx$soc_id = as.character(eadx$soc_id)
# names of languages according to Facebook
if(keepOnlyFAIRLangs){
nx = l[match(eadx$soc_id,l$soc.id),]$Language
rownames(eadx) = nx
} else{
nx = xdid2lang[match(eadx$soc_id,xdid2lang$soc_id),]$DialectLanguageGlottocode
nx[duplicated(nx)] = NA
eadx = eadx[!is.na(nx),]
nx = nx[!is.na(nx)]
rownames(eadx) = nx
}
# Make distance matrix from factors
#dist = dist(eadx[,2:ncol(eadx)])
dist = daisy(eadx[,-which(names(eadx)=="soc_id")], metric = "gower")
# Convert to regular matrix
dist.m = as.matrix(dist)
rownames(dist.m) = nx
colnames(dist.m) = nx
return(dist.m)
}
xdid2lang = read.csv("../data/dplace-data-1.0/csv/xd_id_to_language.csv",stringsAsFactors = F,fileEncoding = "utf-8",encoding = 'utf-8')
socid2xdid = read.csv("../data/dplace-data-1.0/csv/EA_societies.csv",stringsAsFactors = F,fileEncoding = "utf-8",encoding = 'utf-8')
xdid2lang$soc_id = socid2xdid[match(xdid2lang$xd_id,socid2xdid$xd_id),]$soc_id
files = list.files("../data/EA_imputed/completeDataframes/","*.csv")
distsALL = list()
for(i in 1:length(files)){
print(files[i])
distsALL[[i]] = makeDistanceMatrix(paste0("../data/EA_imputed/completeDataframes/",files[i]), keepOnlyFAIRLangs = F)
}
distALL.m = Reduce('+', distsALL)
distALL.m = distALL.m / length(distsALL)
distALL.long = melt(distALL.m)
write.csv(distALL.long, file="../results/EA_distances/CulturalDistances_AllDPlaceLangs_Long.csv", row.names = F)

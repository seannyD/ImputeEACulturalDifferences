---
title: "Predicting semantic alignment by cultural similarity"
output: 
  pdf_document:
    toc: true
---

```{r echo=F, eval=F}
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/analysis/")
```

# Introduction

We compare cultural distances between socieites with linguistic similarities between societies, controlling for shared history in two ways.

The first test uses mixed effects modelling.  The pairing of the language family of each language (according to Glottolog) is used as a random effect.  That means that the model can capture the likelihood that two languages from the Indo-European language family will be more similar to each other than two languages from different language families.  The same is done with geographic area according to Autotyp.

The second test controls for history using distances from a phylogenetic tree.  The tree comes from Bouckaert et al. (2012).  Patristic distances between languages are used as a measure of historical distance between societies in a Mantel test.  Note that the Mantel test assumes a strict distance metric, which is not necessarily the case with this data, but there are few other ways to deal with continuous pairwise distances. 

# Load libraries
```{r warning=F, message=F}
library(ape)
library(ecodist)
library(lme4)
library(sjPlot)
library(ggplot2)
library(igraph)
library(lattice)
library(dplyr)
```

Parameters (using data from Northuralex and Wikipedia, k=100, unfiltered):

```{r}
datasetName = "wikipedia-main"
lingDistancesFile = "../data/FAIR/nel-wiki-k100-alignments-by-language-pair.csv"
lingDistancesFileNK = "../data/FAIR/nel-wiki-k100-alignments-by-language-pair-without-kinship.csv"
lingDistancesByDomainFile = "../results/EA_distances/nel-wiki-k100_with_ling.csv"
# (generated by ../processing/combineCultAndLingDistances.R)
```

\newpage


# All domains

## Load data

Read the cultural distances:

```{r}
cult = read.csv("../results/EA_distances/CulturalDistances_Long.csv", stringsAsFactors = F)
names(cult) = c("l1","l2","cult.dist")
```

Add language family:

```{r}
l = read.csv("../data/FAIR_langauges_glotto_xdid.csv", stringsAsFactors = F)
g = read.csv("../data/glottolog-languoid.csv/languoid.csv", stringsAsFactors = F)
l$family = g[match(l$glotto,g$id),]$family_pk
l$family = g[match(l$family,g$pk),]$name
```

Read the semantic distances

```{r}
ling = read.csv(lingDistancesFile, stringsAsFactors = F)
```

There are very few possible comparisons for Slovenian and Northern Sami, so we'll remove these:

```{r}
ling = ling[!(ling$l1=="se" | ling$l2 == "se"),]
ling = ling[!(ling$l1=="sl" | ling$l2 == "sl"),]
```


Combine the lingusitic and cultural distances. Note that we flip the cultural measure from a distance measure to a similarity measure.

```{r}
cult$l1.iso2 = l[match(cult$l1,l$Language2),]$iso2
cult$l2.iso2 = l[match(cult$l2,l$Language2),]$iso2

fairisos = unique(c(ling$l1,ling$l2))
cultisos = unique(c(cult$l1.iso2, cult$l2.iso2))

cult = cult[(cult$l1.iso2 %in% fairisos) & (cult$l2.iso2 %in% fairisos),]
ling = ling[(ling$l1 %in% cultisos) & (ling$l2 %in% cultisos),]

matches = sapply(1:nrow(ling), function(i){
  which(cult$l1.iso2==ling$l1[i] & cult$l2.iso2==ling$l2[i])
})

ling$cult.dist = cult[matches,]$cult.dist
# Flip
ling$cult.dist = 1 - ling$cult.dist
# Scale
ling$cult.dist.center = scale(ling$cult.dist)
cdc.s = attr(ling$cult.dist.center,"scaled:scale")
cdc.c = attr(ling$cult.dist.center,"scaled:center")
ling$cult.dist.center = as.numeric(ling$cult.dist.center)
ling$comparison_count.center = 
  scale(ling$comparison_count)

ling$family1 = l[match(ling$l1, l$iso2),]$family
ling$family2 = l[match(ling$l2, l$iso2),]$family
l[l$Language=="Arabic",]$autotyp.area= "Greater Mesopotamia"
l[l$Language=="Persian",]$autotyp.area= "Greater Mesopotamia"
ling$area1 = l[match(ling$l1, l$iso2),]$autotyp.area
ling$area2 = l[match(ling$l2, l$iso2),]$autotyp.area


fgroup = cbind(ling$family1,ling$family2)
fgroup = apply(fgroup,1,sort)
ling$family.group = apply(fgroup,2,paste,collapse=":")
agroup = cbind(ling$area1,ling$area2)
agroup = apply(agroup,1,sort)
ling$area.group = apply(agroup,2,paste,collapse=":")

ling$rho.center = scale(ling$local_alignment)

```

Each observation is now assocaited with a language family pair:

```{r}
head(ling[,c("l1","l2","local_alignment",'family.group')])
```

And the same is true for area:

```{r}
tail(ling[,c("l1","l2","local_alignment",'area.group')])
```

Number of observations:

```{r}
# Number of datapoints:
nrow(ling)
# Number of unique languages:
length(unique(unlist(ling[,c("l1","l2")])))
# Number of unique langauge families:
uniqueFamilies = unique(unlist(ling[,c("family1","family2")]))
length(uniqueFamilies)
# Number of unique areas:
uniqueAreas = unique(unlist(ling[,c("area1","area2")]))
length(uniqueAreas)
```

Cross-over between language famlies and areas:

```{r}
tx = data.frame(lang= c(ling$l1,ling$l2),
           fam = c(ling$family1,ling$family2),
           area= c(ling$area1,ling$area2))
tx = tx[!duplicated(tx),]
table(tx$fam,tx$area)
```


\newpage

## LMER models

Mixed effects model, predicting Linguistic similaritys from cultural similarity, with random intercept for family and area and random slope for cultural similarity for family and area.

We start with a null model with random intercepts for family and area, and random slopes for cultural similarity by both. We add a fixed effect of the number of comparisons made for each datapoint (number of concepts that were available to compare). Then we add a fixed effect of cultural similarity

```{r}
m0 = lmer(
  rho.center ~ 1 +
    (1 + cult.dist.center | family.group) +
    (1 + cult.dist.center | area.group),
  data = ling
)
m0.5 = lmer(
  rho.center ~ 1 +
    comparison_count.center +
    (1 + cult.dist.center | family.group) +
    (1 + cult.dist.center | area.group),
  data = ling
)
m1 = lmer(
  rho.center ~ 1 +
    comparison_count.center +
    cult.dist.center +
    (1 + cult.dist.center | family.group) +
    (1 + cult.dist.center | area.group),
  data = ling
)
an1 = anova(m0,m0.5,m1)
an1
```

Cultural similarity is not significantly correlated with Linguistic similarity.  Here are the model estimates:

```{r}
summary(m1)
```

```{r echo=F,message=F,warning=F}
stat0 = sprintf("$\\beta$= %s, $\\chi^2$(%s)= %s, $p$=%s",
  signif(fixef(m1)[3],2),
  an1$`Chi Df`[3],
  round(an1$Chisq[3],2),
  format(signif(an1$`Pr(>Chisq)`[3],1),scientific=F))

cat(stat0,file="../results/stats/tex/MEM_CulturalVsLinguistic.tex")

```


Plot the estimates, rescaling the variables back to the original units:

```{r}
trans = function(X){
  X * attr(ling$rho.center,"scaled:scale") +
  attr(ling$rho.center,"scaled:center")
}

gx = plot_model(m1,'pred',terms='cult.dist.center')
gx$data$predicted = trans(gx$data$predicted)
gx$data$conf.low = trans(gx$data$conf.low)
gx$data$conf.high = trans(gx$data$conf.high)
gx$data$x = gx$data$x *
  cdc.s +cdc.c
gx = gx + #coord_cartesian(ylim=c(0,0.5),
          #                xlim=c(0.15,0.85)) +
  xlab("Cultural similarity") +
  ylab("Semantic alignment") +
  ggtitle("") +
  geom_point(data=ling,aes(x=cult.dist,y=local_alignment))
gx
pdf(paste0("../results/stats/",datasetName,"/CulturalDistance_Rho_Graph.pdf"),
    height=2.5, width=2.5)
gx
dev.off()
```

Plot the random effects:

```{r}
plot_model(m1,'re', sort.est = "cult.dist.center")
```

\newpage

## Without Kinship data

The analyses below show that the strongest relationship is with Kinship.  Here we run the analysis as above, but using semantic distances computed without concepts that relate to kinship.  Note that the local alignment values correlate with r > 0.99.

Code for constructing the data is hidden, but it is the same as above and available in the Rmd file:

```{r echo=F,warning=F}

lingNK = read.csv(lingDistancesFileNK, stringsAsFactors = F)
lingNK = lingNK[!(lingNK$l1=="se" | lingNK$l2 == "se"),]
lingNK = lingNK[!(lingNK$l1=="sl" | lingNK$l2 == "sl"),]

lingNK = ling[(ling$l1 %in% cultisos) & (ling$l2 %in% cultisos),]

matchesNK = sapply(1:nrow(lingNK), function(i){
which(cult$l1.iso2==lingNK$l1[i] & cult$l2.iso2==lingNK$l2[i])
})

lingNK$cult.dist = cult[matches,]$cult.dist
# Flip
lingNK$cult.dist = 1 - lingNK$cult.dist
# Scale
lingNK$cult.dist.center = scale(lingNK$cult.dist)
cdc.sNK = attr(lingNK$cult.dist.center,"scaled:scale")
cdc.cNK = attr(lingNK$cult.dist.center,"scaled:center")
lingNK$cult.dist.center = as.numeric(lingNK$cult.dist.center)
lingNK$comparison_count.center = 
scale(lingNK$comparison_count)

lingNK$family1 = l[match(lingNK$l1, l$iso2),]$family
lingNK$family2 = l[match(lingNK$l2, l$iso2),]$family
lingNK$area1 = l[match(lingNK$l1, l$iso2),]$autotyp.area
lingNK$area2 = l[match(lingNK$l2, l$iso2),]$autotyp.area


fgroupNK = cbind(lingNK$family1,lingNK$family2)
fgroupNK = apply(fgroupNK,1,sort)
lingNK$family.group = apply(fgroupNK,2,paste,collapse=":")
agroupNK = cbind(lingNK$area1,lingNK$area2)
agroupNK = apply(agroupNK,1,sort)
lingNK$area.group = apply(agroupNK,2,paste,collapse=":")

lingNK$rho.center = scale(ling$local_alignment)
```

Run the lmer models:

```{r}
m0NK = lmer(
  rho.center ~ 1 +
    (1 + cult.dist.center | family.group) +
    (1 + cult.dist.center | area.group),
  data = lingNK
)
m0.5NK = lmer(
  rho.center ~ 1 +
    comparison_count.center +
    (1 + cult.dist.center | family.group) +
    (1 + cult.dist.center | area.group),
  data = lingNK
)
m1NK = lmer(
  rho.center ~ 1 +
    comparison_count.center +
    cult.dist.center +
    (1 + cult.dist.center | family.group) +
    (1 + cult.dist.center | area.group),
  data = lingNK
)
anova(m0NK,m0.5NK,m1NK)
summary(m1NK)
```

\newpage

##  MRM

Use multiple regression on distance matrices (Lichstein, 2007) to do the same test as above.  The code below loads the data into a matrix format:

```{r}
# Use graph method to make distance matrix
grph <- graph.data.frame(ling[,c("l1",'l2','local_alignment')], directed=FALSE)
# add value as a weight attribute
ling.m = get.adjacency(grph, attr="local_alignment", sparse=FALSE)
rownames(ling.m) = l[match(rownames(ling.m),l$iso2),]$Language2
colnames(ling.m) = l[match(colnames(ling.m),l$iso2),]$Language2
# Same for comparison_count.center
grph <- graph.data.frame(ling[,c("l1",'l2','comparison_count')], directed=FALSE)
# add value as a weight attribute
cc.m = get.adjacency(grph, attr="comparison_count", sparse=FALSE)
rownames(cc.m) = l[match(rownames(cc.m),l$iso2),]$Language2
colnames(cc.m) = l[match(colnames(cc.m),l$iso2),]$Language2

cult.m = read.csv("../results/EA_distances/CulturalDistances.csv", stringsAsFactors = F)
rownames(cult.m) = cult.m[,1]
cult.m = cult.m[,2:ncol(cult.m)]
cult.m = as.matrix(cult.m)
# Flip cultural value to distance
cult.m = 1-cult.m
mx = match(rownames(ling.m),rownames(cult.m))
cult.m = cult.m[mx,mx]
colnames(cult.m) = rownames(cult.m)

# Same/different matrix for language family
family.matrix = l[match(rownames(ling.m),l$Language),]$family
family.matrix = outer(family.matrix,family.matrix,"!=") *1

# Load ASJP distances for second test
asjp = readRDS("../data/ASJP/asjp17-dists_FAIR.RData")
ling.m.glotto = l[match(rownames(cult.m),l$Language2),]$glotto
ling.m.glotto = ling.m.glotto[ling.m.glotto %in% rownames(asjp)]
asjp.m = asjp[ling.m.glotto,ling.m.glotto]
asjp.lang.names = l[match(rownames(asjp.m),l$glotto),]$Language2
# Matrices for second analysis with asjp
ling.m2 = ling.m[asjp.lang.names,asjp.lang.names]
cult.m2 = cult.m[asjp.lang.names,asjp.lang.names]
cc.m2 =  cc.m[asjp.lang.names,asjp.lang.names]

# Load the geographic distances:
geoDist = read.csv("../data/GeographicDistances.csv",stringsAsFactors = F)
geoDist.m = as.matrix(geoDist)
geoDist.m = geoDist.m[!is.na(geoDist.m[,1]),!is.na(geoDist.m[1,])]
# Convert to log distance in thousand km
geoDist.m = log10(geoDist.m/1000)
geoDist.m[is.infinite(geoDist.m)] = 0
colnames(geoDist.m) = gsub("\\."," ",colnames(geoDist.m))
rownames(geoDist.m) = colnames(geoDist.m)
geoDist.m1 = geoDist.m[rownames(ling.m),rownames(ling.m)]
geoDist.m2 = geoDist.m[rownames(ling.m2),rownames(ling.m2)]

# center and scale values
ling.m =  matrix(scale(as.vector(ling.m)),nrow=nrow(ling.m))
cc.m =  matrix(scale(as.vector(cc.m)),nrow=nrow(cc.m))
cult.m = matrix(scale(as.vector(cult.m)),nrow=nrow(cult.m))
geoDist.m1 = matrix(scale(as.vector(geoDist.m1)),nrow=nrow(geoDist.m1))

asjp.m = matrix(scale(as.vector(asjp.m)),nrow=nrow(asjp.m))
ling.m2 = matrix(scale(as.vector(ling.m2)),nrow=nrow(ling.m2))
cc.m2 =  matrix(scale(as.vector(cc.m2)),nrow=nrow(cc.m2))
cult.m2 = matrix(scale(as.vector(cult.m2)),nrow=nrow(cult.m2))
geoDist.m2 = matrix(scale(as.vector(geoDist.m2)),nrow=nrow(geoDist.m2))
```

\newpage

Run the MRM model, predicting semantic alignment by cultural distance, controlling for family distance, geographic ditance, and the comparison count (number of observations). Here, the family distance between two languages is just whether they are part of the same family.  Note that this does not take into account particular values for particular families, nor the random slopes within families.

```{r}
set.seed(1282)
ecodist::MRM(as.dist(ling.m) ~
               as.dist(cult.m) + 
               as.dist(family.matrix) + 
               as.dist(geoDist.m1)  +
               as.dist(cc.m),nperm = 10000)
```

Semantic alignment is significantly correlated with cultural distance.

In the result above, geographic distance is not correlated with semantic distance. Geographic distance turns out to be moderately correlated with cultural distance:

```{r}
ecodist::MRM(as.dist(geoDist.m1) ~
               as.dist(cult.m),
             nperm = 10000)
```

Even when testing for non-linear geographic effects, the main result still holds:

```{r}
ecodist::MRM(as.dist(ling.m) ~
               as.dist(cult.m) + 
               as.dist(family.matrix) + 
               as.dist(geoDist.m1)  +
               as.dist(geoDist.m1^2)  +
               as.dist(geoDist.m1^3)  +
               as.dist(cc.m),nperm = 10000)
```


Below, we run the same test, but using average string distances in basic vocabulary from the ASJP (Wichmann, Holman & Brown, 2018) as controls for history. We used the distances as calculated in Jäger (2018), which used them to construct historical phylogenies.

```{r}
ecodist::MRM(as.dist(ling.m2) ~
               as.dist(cult.m2) + 
               as.dist(asjp.m) + 
               as.dist(geoDist.m2) +
               as.dist(cc.m2),nperm = 10000)
```


\newpage

# Mantel tests

Read the historical distances for Indo-European, based on the phylogenetic distances.

## Data prep

The geographic distances are loaded above (from "../data/GeographicDistances.csv").

Load historical distances:

```{r}
hist = read.csv("../data/trees/IndoEuropean_historical_distances.csv", stringsAsFactors = F)
hist = hist[!duplicated(hist[,1]),!duplicated(hist[,1])]
rownames(hist) = hist[,1]
hist = hist[,2:ncol(hist)]
hist.m = as.matrix(hist)
colnames(hist.m) = rownames(hist.m)
hist.m = hist.m/max(hist.m)
```

Read the cultural distance as a matrix:

```{r}
cult.m = read.csv("../results/EA_distances/CulturalDistances.csv", stringsAsFactors = F)
rownames(cult.m) = cult.m[,1]
cult.m = cult.m[,2:ncol(cult.m)]
```

Flip the cultural distance into a cultural similarity measure:

```{r}
cult.m = 1-cult.m
```

Convert the linguistic similarities to a matrix.  This uses `igraph` to make an undirected graph from the long format with `local_alignment` as the edge weights, then output a matrix of adjacencies.

```{r}
grph <- graph.data.frame(ling[,c("l1",'l2','local_alignment')], directed=FALSE)
# add value as a weight attribute
ling.m = get.adjacency(grph, attr="local_alignment", sparse=FALSE)
rownames(ling.m) = l[match(rownames(ling.m),l$iso2),]$Language2
colnames(ling.m) = l[match(colnames(ling.m),l$iso2),]$Language2
```

Match the distance matrices

```{r}
in.analysis = intersect(rownames(ling.m),rownames(cult.m))
in.analysis = intersect(in.analysis, rownames(hist.m))
cult.m2 = cult.m[in.analysis,in.analysis]
ling.m2 = ling.m[in.analysis,in.analysis]
hist.m2 = hist.m[in.analysis,in.analysis]
geo.m2 = geoDist.m[in.analysis,in.analysis]
```

Note that there are only `r length(in.analysis)` languages with data on lingusitic, cultural and historical distance.

```{r}
plot(as.dist(cult.m2),as.dist(ling.m2),
     xlab="Cultural similarity",
     ylab="Linguistic similarity")
plot(as.dist(cult.m2),as.dist(hist.m2),
     xlab="Cultural similarity",
     ylab="Historical distance")
plot(as.dist(ling.m2),as.dist(hist.m2),
     xlab="Linguistic similarity",
     ylab="Historical distance")
```

```{r warning=F,echo=F}
t = read.nexus("../data/trees/bouckaert_et_al2012-d-place_2.NEXUS")
treenames = read.csv("../data/trees/taxa.csv", stringsAsFactors = F)
# These are not necessarily the right glottocode, but they do link the right data
treenames[treenames$taxon=="Albanian_G",]$glottocode = "gheg1238"
treenames[treenames$taxon=="Greek_Mod",]$glottocode = "mode1248"

# convert tip labels to glotto codes
t$tip.label = treenames[match(t$tip.label,treenames$taxon),]$glottocode
t2 = drop.tip(t,t$tip.label[!t$tip.label %in% l[match(in.analysis,l$Language),]$glotto])
t2 = drop.tip(t2,which(duplicated(t2$tip.label)))
t2$tip.label = l[match(t2$tip.label,l$glotto),]$Language
plot(t2)
```

\newpage

## Tests

The results of the test list the following measures:

-  mantelr: Mantel correlation coefficient.
-  pval1: one-tailed p-value (null hypothesis: r <= 0).
-  pval2: one-tailed p-value (null hypothesis: r >= 0).
-  pval3: two-tailed p-value (null hypothesis: r = 0).
-  llim: lower confidence limit for r.
-  ulim: upper confidence limit for r.

```{r}
set.seed(1498)
```

Run tests between each pair of measures.

```{r}
distms = list("Cultrual"= cult.m2,
              "Linguistic" = ling.m2,
              "Historical" = hist.m2,
              "Geographic" = geo.m2)
for(i in 1:3){
  for(j in (i+1):4){
    var1 = names(distms)[i]
    var2 = names(distms)[j]
    print(paste("Correlation between",
                var1,"and",var2))
    stat = ecodist::mantel(as.dist(distms[[i]]) ~
                as.dist(distms[[j]]),
                nperm = 100000)
    print(stat)
    stat = round(stat,2)
    stat2 = sprintf("$r$ = %s[%s,%s], one-tailed $p$ = %s",
      stat[1],
      stat[5],
      stat[6],
      min(c(stat[2],stat[3])))
    cat(stat2,file=
          paste0("../results/stats/tex/Mantel",var1,"Vs",var2,"Distance.tex"))
  }
}
```


Run a mantel test comparing the Linguistic alignment to the cultural similarity, controlling for the historical distance between languages:

```{r}
ecodist::mantel(as.dist(ling.m2)~
                  as.dist(cult.m2) + 
                  as.dist(hist.m2),
                nperm = 100000)
```

*Main Test*: Run a mantel test comparing the Linguistic alignment to the cultural similarity, controlling for the historical distance and geographic distance between languages:

```{r}
mainMantel = ecodist::mantel(as.dist(ling.m2)~
                  as.dist(cult.m2) + 
                  as.dist(hist.m2) +
                  as.dist(geo.m2),
                nperm = 100000)
mainMantel
```

```{r}
mainMantel = round(mainMantel,2)
mainMantel2 = sprintf("$r$ = %s[%s,%s], one-tailed $p$ = %s",
        mainMantel[1],
        mainMantel[5],
        mainMantel[6],
        mainMantel[2]
      )
cat(mainMantel2,
    file="../results/stats/tex/MantelCultrualVsLinguisticDistance_Partial.tex")
```


## MRM

Perform the main test, but using multiple regression on distance matrices (MRM).

```{r}
set.seed(21889)
mainMRM = ecodist::MRM(as.dist(ling.m2)~
                  as.dist(cult.m2) + 
                  as.dist(hist.m2) +
                  as.dist(geo.m2), nperm=10000)
mainMRM
```

```{r}
mainMRM2 = sprintf("$\\beta= $%s, $p=$%s",
                   round(mainMRM$coef[2,1],2),
                   round(mainMRM$coef[2,2],2))
cat(mainMRM2,
    file="../results/stats/tex/MRMCultrualVsLinguisticDistance_Partial.tex")
```


\clearpage
\newpage

# Analysis of filtered data

The analyses in this section use local alignment values based on (a) data that passes the wikipedia filter, and (b) data that passes the semantic filter.


## Wikipedia filter


```{r}
ling.filtered = read.csv(
  "../data/FAIR/nel-wiki-k100-alignments-by-language-pair_Filtered.csv",
  stringsAsFactors = F)
```

Note that the semantic alignment for the filtered and unfiltered data are essentially exactly the same, but for fewer languages:

```{r}
ling.filtered$unfiltered.rho = 
  apply(ling.filtered[,
      c("iso2_l1","iso2_l2")],1,
  function(X){
    ling[(ling$l1==X[1] & ling$l2==X[2]) | 
           (ling$l1==X[2] & ling$l2==X[1]),]$local_alignment[1]
  })
cor(ling.filtered$unfiltered.rho,ling.filtered$rho,use = "complete.obs")
```

Continue to build data for replication:

```{r}
ling.filtered$area1 = l[match(ling.filtered$name_l1,l$Language),]$autotyp.area
ling.filtered$area2 = l[match(ling.filtered$name_l2,l$Language),]$autotyp.area

fgroup = cbind(ling.filtered$family1,ling.filtered$family2)
fgroup = apply(fgroup,1,sort)
ling.filtered$family.group = apply(fgroup,2,paste,collapse=":")
agroup = cbind(ling.filtered$area1,ling.filtered$area2)
agroup = apply(agroup,1,sort)
ling.filtered$area.group = apply(agroup,2,paste,collapse=":")

ling.filtered$rho.center = scale(ling.filtered$rho)
ling.filtered$comparison_count.center = scale(ling.filtered$comparison_count)

matches = sapply(1:nrow(ling.filtered), function(i){
  x = which((cult$l1==ling.filtered$name_l1[i] & 
          cult$l2==ling.filtered$name_l2[i]) |
            (cult$l2==ling.filtered$name_l1[i] & 
          cult$l1==ling.filtered$name_l2[i]))
  x[1]
})

ling.filtered$cult.dist = cult[matches,]$cult.dist
# flip
ling.filtered$cult.dist = 1 - ling.filtered$cult.dist
ling.filtered = ling.filtered[!is.na(ling.filtered$cult.dist),]

ling.filtered$cult.dist.center = scale(ling.filtered$cult.dist)
```


```{r}
m0F = lmer(
  rho.center ~ 1 +
    (1 + cult.dist.center | family.group) +
    (1 + cult.dist.center | area.group),
  data = ling.filtered
)
m0.5F = lmer(
  rho.center ~ 1 +
    comparison_count.center +
    (1 + cult.dist.center | family.group) +
    (1 + cult.dist.center | area.group),
  data = ling.filtered
)
m1F = lmer(
  rho.center ~ 1 +
    comparison_count.center +
    cult.dist.center +
    (1 + cult.dist.center | family.group) +
    (1 + cult.dist.center | area.group),
  data = ling.filtered
)
an1F = anova(m0F,m0.5F,m1F)
an1F
```

Cultural similarity is significantly correlated with Linguistic similarity, even in the filtered data.  Here are the model estimates:

```{r}
summary(m1F)
```

\clearpage
\newpage

## Semantic filter

```{r}
ling.semFiltered = read.csv(
  "../data/FAIR/nel-wiki-k100-alignments-by-language-pair_SemanticFiltered.csv",
  stringsAsFactors = F)

ling.semFiltered$area1 = l[match(ling.semFiltered$name_l1,l$Language),]$autotyp.area
ling.semFiltered$area2 = l[match(ling.semFiltered$name_l2,l$Language),]$autotyp.area

fgroup = cbind(ling.semFiltered$family1,ling.semFiltered$family2)
fgroup = apply(fgroup,1,sort)
ling.semFiltered$family.group = apply(fgroup,2,paste,collapse=":")
agroup = cbind(ling.semFiltered$area1,ling.semFiltered$area2)
agroup = apply(agroup,1,sort)
ling.semFiltered$area.group = apply(agroup,2,paste,collapse=":")

ling.semFiltered$rho.center = scale(ling.semFiltered$rho)
ling.semFiltered$comparison_count.center = scale(ling.semFiltered$comparison_count)

matches = sapply(1:nrow(ling.semFiltered), function(i){
  x = which((cult$l1==ling.semFiltered$name_l1[i] & 
          cult$l2==ling.semFiltered$name_l2[i]) |
            (cult$l2==ling.semFiltered$name_l1[i] & 
          cult$l1==ling.semFiltered$name_l2[i]))
  x[1]
})

ling.semFiltered$cult.dist = cult[matches,]$cult.dist
# flip
ling.semFiltered$cult.dist = 1 - ling.semFiltered$cult.dist
ling.semFiltered = ling.semFiltered[!is.na(ling.semFiltered$cult.dist),]

ling.semFiltered$cult.dist.center = scale(ling.semFiltered$cult.dist)
```


```{r}
m0F = lmer(
  rho.center ~ 1 +
    (1 + cult.dist.center | family.group) +
    (1 + cult.dist.center | area.group),
  data = ling.semFiltered
)
m0.5F = lmer(
  rho.center ~ 1 +
    comparison_count.center +
    (1 + cult.dist.center | family.group) +
    (1 + cult.dist.center | area.group),
  data = ling.semFiltered
)
m1F = lmer(
  rho.center ~ 1 +
    comparison_count.center +
    cult.dist.center +
    (1 + cult.dist.center | family.group) +
    (1 + cult.dist.center | area.group),
  data = ling.semFiltered
)
an1F = anova(m0F,m0.5F,m1F)
an1F
```

Cultural similarity is significantly correlated with Linguistic similarity, even in the semantic filtered data.  Here are the model estimates:

```{r}
summary(m1F)
```



\newpage

# Comparison between domains

The code that produce the results of this section can be found in `analysis/compareDomains.R`.

## Part 1: Compare each linguistic domain to the overall cultural similarity

We fit a mixed effects model to compare the linguistic similarity in a given domain to the overall cultural distance. The linguistic similarity for the given domain is the dependent variable.  There are random intercepts for language family and area pairs, and random slopes for overall cultural similarity by language family and by area.  The `comparison_count` variable is added as a fixed effect. This null model is compared to a model with an additional fixed effect for the overall cultural similairty.

There are 21 linguistic domains with enough data. All correlations are positive and 11 are significant at the 0.05 level (adjusted for multiple comparisons).

The full results are in the file:

`../results/stats/wikipedia-main/Cor_LingAlignmentByDomains_vs_OverallCulturalSimilarity.csv`

```{r echo=F}
compareDomainsPart1Results = 
  read.csv("../results/stats/wikipedia-main/Cor_LingAlignmentByDomains_vs_OverallCulturalSimilarity.csv",
           stringsAsFactors = F)
compareDomainsPart1Results = 
  compareDomainsPart1Results[order(
    compareDomainsPart1Results$lmeModel.CultSimilarity.ChiSquared,decreasing = T),]
p1res = compareDomainsPart1Results[,c(2,4,7,8)]
names(p1res) = c("Domain","Beta","p","Adjusted p")
p1res$sig = c("","*")[as.numeric(p1res[,"Adjusted p"]<0.05)+1]
```

Summary:

```{r}
p1res
```

\newpage

## Part 2: Compare each linguistic domain to the cultural similarity of each original D-PLACE domain

The method is the same as for part 1, except the cultural distance for a particular cultural domain is used instead of the overall cultural distance.

The full results are in the file:

`../results/stats/wikipedia-main/Cor_LingAlignmentByDomains_vs_DPlaceCulturalDomains.csv`

The graph below shows the mixed effects model coefficient estimate for the relationship between each linguistic domain and each cultural domain.  Pink colours indicate positive correlations and blue colours indicate negative correlations.  Stronger colours indicate stronger correlations.  An asterisk  indicates that the correlation is stronger than would be expected by chance, when adjusting the p-value for multiple comparisons.

The insert in the top left shows the distribution of Beta values. 

The domains are clustered using higherarchical clustering. This is for visualisaiton and reflects similarity in the numeric relations, not history or conceptual hierarchies.

![](../results/stats/wikipedia-main/LingAlignmentByDomains_vs_DPlaceCulturalDomains_Beta.pdf)

List of significant correlations (after adjusting p-value for multiple comparisons):

```{r echo=F}
p2res = read.csv("../results/stats/wikipedia-main/Cor_LingAlignmentByDomains_vs_DPlaceCulturalDomains.csv",stringsAsFactors = F)

p2resSig = p2res[p2res$lmeModel.CultSimilarity.p.adjusted<0.05,
      c("lingDomain","cultDomainDP","lmeModel.CultSimilarity.Beta","lmeModel.CultSimilarity.p.adjusted")]
p2resSig = p2resSig[order(p2resSig$cultDomainDP,p2resSig$lingDomain),]
names(p2resSig) = c("Ling Domain","Cult Domain","Beta","Adjusted p")
p2resSig
```


\newpage

## Part 3: Compare each linguistic domain to the phylogenetic and geographic distance

This test compares each linguistic similarity scores to each of three target distances:  the cultural distance, the historical distance and the geographic distance.  We use a partial Mantel test (from the package `ecodist`) to estimate the strength of the relationship between the linguistic domain and the target distance, while controlling for the other two distances.  The test uses 100,000 permutations.

The full results are in the file:

`Cor_LingAlignmentByDomains_vs_HistoricalAndGeographicalDistance.csv`

The graph below shows the results.  Point estimates are the estimated Mantel R. The error bars show the 95% confidence intervals from the permutation test.

![](../results/stats/wikipedia-main/LingAlignmentByDomains_vs_HistoricalAndGeographicalProximity.pdf
)

There appears to be a trade-off: The stronger the relationship with geographic distance, the weaker the relationship with cultural distance (r = -0.529, t = -2.72, df=19, p = 0.014).  This does not hold for  historical and cultural distance (r = 0.27, t = 1.22, df=19, p = 0.24).

Note that, after controlling for multiple comparisons, only 2 domains are significant:  

```{r echo=F}
p3res = read.csv("../results/stats/wikipedia-main/Cor_LingAlignmentByDomains_vs_HistoricalAndGeographicalDistance.csv",stringsAsFactors = F)
p3res[p3res$p.adjusted<0.05,c("domain","comparison","mantelr","lower","upper","pval3","p.adjusted")]
```

\newpage

# Summary of alternative data sources

The github repository also includes the main tests in this document, but applied to data where the alignments are done according to the Common Crawl or Subtitles databases.

## Common Crawl

Mixed effects model: The correlation between semantic alignment and cultural similarity was significant (\input{"../results/stats/tex/MEM_CulturalVsLinguistic_CC.tex"}).  See figure 4.

![Semantic alignment and cultural similarity for data using the Common Crawl alignments](../results/stats/cc/CulturalDistance_Rho_Graph.pdf)

MRM results:
\input{../results/stats/tex/MRM_family_CC.tex}

\input{../results/stats/tex/MRM_ASJP_CC.tex}

Mantel tests:

\input{../results/stats/tex/Mantel_CC.tex}

## Subtitles

Mixed effects model: The correlation between semantic alignment and cultural similarity was not significant (\input{"../results/stats/tex/MEM_CulturalVsLinguistic_SUBS.tex"}).  See figure 5

![Semantic alignment and cultural similarity for data using the Subtitles alignments](../results/stats/subs/CulturalDistance_Rho_Graph.pdf)

MRM results:
\input{../results/stats/tex/MRM_family_SUBS.tex}

\input{../results/stats/tex/MRM_ASJP_SUBS.tex}

Mantel tests:

\input{../results/stats/tex/Mantel_SUBS.tex}

\clearpage
\newpage

# References

Bouckaert, Remco, Philippe Lemey, Michael Dunn, Simon J. Greenhill, Alexander V. Alekseyenko, Alexei J. Drummond, Russell D. Gray, Marc A. Suchard, and Quentin D. Atkinson (2012). Mapping the origins and expansion of the Indo-European language family. Science, 337(6097), 957-960.

Lichstein, J. W. (2007). Multiple regression on distance matrices: a multivariate spatial analysis tool. Plant Ecology, 188(2), 117-131.

Jäger, G. (2018). Global-scale phylogenetic linguistic inference from lexical resources. Scientific data, 5, 180189.

Wichmann, Søren, Eric W. Holman, and Cecil H. Brown (eds.). 2018. The ASJP Database (version 17). 
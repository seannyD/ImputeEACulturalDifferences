i=
1
print(c2ea$concepticon[i])
c2ea
ling.dom[ling.dom$l1=="se" | ling.dom$l2 == "se",]
ling.dom[ling.dom$l1=="se" | ling.dom$l2 == "se",]
c2ea
print(c2ea$concepticon[i])
cats = strsplit(c2ea[i,]$ea,"-")[[1]]
eavars = c()
for(cx in cats){
eavars = c(eavars,eav[grepl(cx,eav$IndexCategory),]$VarID)
}
eavars
eavars = unique(eavars)
j = 1
filename = paste0("../data/EA_imputed/completeDataframes/",files[j])
files = list.files("../data/EA_imputed/completeDataframes/","*.csv")
filename = paste0("../data/EA_imputed/completeDataframes/",files[j])
variables=c(paste0("X",eavars),"soc_id")
eadx = read.csv(filename, stringsAsFactors = F)
eadx = eadx[eadx$soc_id %in% l$soc.id,]
# Remove family and area data
eadx = read.csv(filename, stringsAsFactors = F)
dim(eadx)
eadx = eadx[eadx$soc_id %in% l$soc.id,]
dim(eadx)
eadx = eadx[,!names(eadx) %in% c("Family","autotyp.area")]
dim(eadx)
if(length(variables)>0){
eadx = eadx[,names(eadx) %in% variables]
}
dim(eadx)
length(variables)
eadx = eadx[,apply(eadx,2,function(X){sum(is.na(X))==0})]
dim(eadx)
eadx = eadx[names(eadx)!="X",]
dim(eadx)
names(eadx)
for(i in 1:ncol(eadx)){
eadx[,i] = as.factor(eadx[,i])
}
# Convert soc_id back to character
eadx$soc_id = as.character(eadx$soc_id)
nx = l[match(eadx$soc_id,l$soc.id),]$Language
nx
rownames(eadx) = nx
eadx = read.csv(filename, stringsAsFactors = F)
# Keep only FAIR langauges
eadx = eadx[eadx$soc_id %in% l$soc.id,]
# Remove family and area data
eadx = eadx[,!names(eadx) %in% c("Family","autotyp.area")]
# Optionally only keep some variables
if(length(variables)>0){
eadx = eadx[,names(eadx) %in% variables]
}
# Remove any variables that still have missing data
eadx = eadx[,apply(eadx,2,function(X){sum(is.na(X))==0})]
#eadx = eadx[,names(eadx)!="X69"]
eadx = eadx[names(eadx)!="X",]
# Convert to factor
for(i in 1:ncol(eadx)){
eadx[,i] = as.factor(eadx[,i])
}
# Convert soc_id back to character
eadx$soc_id = as.character(eadx$soc_id)
# names of languages according to Facebook
nx = l[match(eadx$soc_id,l$soc.id),]$Language
rownames(eadx)
rownames(eadx) = nx
dist = daisy(eadx[,-which(names(eadx)=="soc_id")], metric = "gower")
dist
image(dist)
image(as.matrix(dist))
sum(is.na(as.matrix(dist)))
sort(nx)
cultisos
ling.dom = read.csv(
lingDistancesByDomainFile,
stringsAsFactors = F)
ling.dom = ling.dom[!is.na(ling.dom$cult.dist),]
ling.dom = ling[(ling.dom$l1 %in% cultisos) & (ling.dom$l2 %in% cultisos),]
ling.dom$family1 = l[match(ling.dom$l1, l$iso2),]$family
ling.dom$family2 = l[match(ling.dom$l2, l$iso2),]$family
ling.dom$area1 = l[match(ling.dom$l1, l$iso2),]$autotyp.area
ling.dom$area2 = l[match(ling.dom$l2, l$iso2),]$autotyp.area
ling.dom$l1 %in% cultisos
table(.dom)
ling.dom = read.csv(
lingDistancesByDomainFile,
stringsAsFactors = F)
ling.dom = ling.dom[!is.na(ling.dom$cult.dist),]
table((ling.dom$l1 %in% cultisos))
table((ling.dom$l2 %in% cultisos))
sort(unique(ling.dom$l1))
"se" %in% cultisos
sort(cultisos)
ling.dom = read.csv(
lingDistancesByDomainFile,
stringsAsFactors = F)
ling.dom = ling.dom[!is.na(ling.dom$cult.dist),]
ling.dom = ling.dom[(ling.dom$l1 %in% cultisos) &
(ling.dom$l2 %in% cultisos),]
table(ling.dom$l1)
table(c(ling.dom$l1,ling.dom$l2)
)
sort(table(c(ling.dom$l1,ling.dom$l2)))
distsC[[j]] = makeDistanceMatrix(
paste0("../data/EA_imputed/completeDataframes/",files[j]),
variables=c(paste0("X",eavars),"soc_id"))
makeDistanceMatrix = function(filename, variables=c()){
# Load imputed Ethnogrpahic Atlas data
eadx = read.csv(filename, stringsAsFactors = F)
# Keep only FAIR langauges
eadx = eadx[eadx$soc_id %in% l$soc.id,]
# Remove family and area data
eadx = eadx[,!names(eadx) %in% c("Family","autotyp.area")]
# Optionally only keep some variables
if(length(variables)>0){
eadx = eadx[,names(eadx) %in% variables]
}
# Remove any variables that still have missing data
eadx = eadx[,apply(eadx,2,function(X){sum(is.na(X))==0})]
#eadx = eadx[,names(eadx)!="X69"]
eadx = eadx[names(eadx)!="X",]
# Convert to factor
for(i in 1:ncol(eadx)){
eadx[,i] = as.factor(eadx[,i])
}
# Convert soc_id back to character
eadx$soc_id = as.character(eadx$soc_id)
# names of languages according to Facebook
nx = l[match(eadx$soc_id,l$soc.id),]$Language
rownames(eadx) = nx
# Make distance matrix from factors
#dist = dist(eadx[,2:ncol(eadx)])
dist = daisy(eadx[,-which(names(eadx)=="soc_id")], metric = "gower")
# Convert to regular matrix
dist.m = as.matrix(dist)
rownames(dist.m) = nx
colnames(dist.m) = nx
return(dist.m)
}
distsC = list()
distsC[[j]] = makeDistanceMatrix(
paste0("../data/EA_imputed/completeDataframes/",files[j]),
variables=c(paste0("X",eavars),"soc_id"))
distsC[[1]]
distsC[[1]]["Northern Sami",]
for(j in 1:length(files)){
print(files[j])
distsC[[j]] = makeDistanceMatrix(
paste0("../data/EA_imputed/completeDataframes/",files[j]),
variables=c(paste0("X",eavars),"soc_id"))
}
distx.m = Reduce('+', distsC)
rownames(distx.m)
sort(rownames(distx.m)
)
distx.m["Northern Sami",]
distx.m / length(distsC)
distx.m = distx.m / length(distsC)
filenamex = gsub(' ',"_",c2ea[i,]$concepticon)
distx.long = melt(distx.m)
library(reshape2)
library(mclust)
distx.long = melt(distx.m)
distx.long
sum(is.na(distx.long$Var1))
sum(is.na(distx.long$Var2))
sum(is.na(distx.long$value))
head(distx.long)
distx.long[distx.long$Var1=="Northern Sami",]
table(distx.long$Var1)
table(distx.long$Var2)
# combine the distances for linguistic and cultural
# features for each domain
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/processing/")
l = read.csv("../data/FAIR_langauges_glotto_xdid.csv",
stringsAsFactors = F)
inputFile = "../data/FAIR/main-data-nel-wikipedia-k100-by-language-pair-and-domain.csv"
ling.domain = read.csv(inputFile, stringsAsFactors = F)
ling.domain$cult.dist = NA
ling.langs = unique(c(ling.domain$l1,
ling.domain$l2))
table(ling.domain$l1)
table(c(ling.domain$l1,ling.domain$l2))
sort(table(c(ling.domain$l1,ling.domain$l2)))
ling = read.csv(lingDistancesFile, stringsAsFactors = F)
table(c(ling$l1,ling$l2))
sort(table(c(ling$l1,ling$l2)))
ling[ling$l1=="sl",]
ling[ling$l2=="sl",]
cult$l1.iso2 = l[match(cult$l1,l$Language2),]$iso2
cult$l2.iso2 = l[match(cult$l2,l$Language2),]$iso2
fairisos = unique(c(ling$l1,ling$l2))
cultisos = unique(c(cult$l1.iso2, cult$l2.iso2))
cult = cult[(cult$l1.iso2 %in% fairisos) & (cult$l2.iso2 %in% fairisos),]
ling = ling[(ling$l1 %in% cultisos) & (ling$l2 %in% cultisos),]
matches = sapply(1:nrow(ling), function(i){
which(cult$l1.iso2==ling$l1[i] & cult$l2.iso2==ling$l2[i])
})
ling$cult.dist = cult[matches,]$cult.dist
ling$cult.dist.center = scale(ling$cult.dist)
cdc.s = attr(ling$cult.dist.center,"scaled:scale")
cdc.c = attr(ling$cult.dist.center,"scaled:center")
ling$cult.dist.center = as.numeric(ling$cult.dist.center)
ling$family1 = l[match(ling$l1, l$iso2),]$family
ling$family2 = l[match(ling$l2, l$iso2),]$family
ling$area1 = l[match(ling$l1, l$iso2),]$autotyp.area
ling$area2 = l[match(ling$l2, l$iso2),]$autotyp.area
ling[ling$l2=="sl",]
ling[ling$l1=="sl",]
head(ling.dom)
head(ling.dom$imputed_semantic_domain,20)
x = ling.dom[1:16,]
head(x)
reshape(x, idvar = c(l1,l2), timevar = c("local_alignment","cult.dist"), direction = "wide")
reshape(x, idvar = c("l1","l2"), timevar = c("local_alignment","cult.dist"), direction = "wide")
reshape(x, idvar = c("l1","l2"), timevar = "imputed_semantic_domain", direction = "wide")
x2 = reshape(x, idvar = c("l1","l2"), timevar = "imputed_semantic_domain", direction = "wide")
x2[,1:4]
head(x)
cor(x2)
cor(x2[,3:ncol(x2)])
ling.dom.wide = reshape(ling.dom,
idvar = c("l1","l2"),
timevar = "imputed_semantic_domain",
direction = "wide")
cor(ling.dom.wide[,3:5])
head(ling.dom.wide)
ling.dom.wide[,1]
ling.dom.wide[,3]
cor(ling.dom.wide[,3],ling.dom.wide[,4])
ling.dom.wide[,4]
sum(is.na(ling.dom.wide[,4]))
ling.dom.wide[is.na(ling.dom.wide[,4]),]
cor(ling.dom.wide[,3:5],na.rm=T)
?cor
cor(ling.dom.wide[,3:5],use="complete.obs")
cor(ling.dom.wide[,grepl("local_alignment",names(ling.dom.wide))],
ling.dom.wide[,grepl("cult\\.dist",names(ling.dom.wide))]
use="complete.obs")
cor(ling.dom.wide[,grepl("local_alignment",names(ling.dom.wide))],
ling.dom.wide[,grepl("cult\.dist",names(ling.dom.wide))],
use="complete.obs")
cor(ling.dom.wide[,grepl("local_alignment",names(ling.dom.wide))],
ling.dom.wide[,grepl("cult\\.dist",names(ling.dom.wide))],
use="complete.obs")
?pairs
compareAllDomains =
cor(ling.dom.wide[,
grepl("local_alignment",names(ling.dom.wide))],
ling.dom.wide[,
grepl("cult\\.dist",names(ling.dom.wide))],
use="complete.obs")
image(compareAllDomains)
compareAllDomains
dim(compareAllDomains)
abbreviate(names(compareAllDomains))
abbreviate(names(ling.dom.wide))
snames = c("Agri","Tech","Emot","Kin","Poss","Soc","Hous","Wrld")
sort(names(ling.dom.wide))
ling.dom.wide = cbind(ling.dom.wide[1:2,],
ling.dom.wide[,3:ncol(ling.dom.wide)][
order(names(ling.dom.wide[,3:ncol(ling.dom.wide)]))
])
ling.dom.wide = reshape(ling.dom,
idvar = c("l1","l2"),
timevar = "imputed_semantic_domain",
direction = "wide")
ling.dom.wide = cbind(ling.dom.wide[,1:2],
ling.dom.wide[,3:ncol(ling.dom.wide)][
order(names(ling.dom.wide[,3:ncol(ling.dom.wide)]))
])
names(ling.dom.wide)
snames = c("Agri","Tech","Emot","Kin","Poss","Soc","Hous","Wrld")
names(ling.dom.wide) = c("l1","l2",
paste0("L.",snames),
pate0("C.",snames))
snames = c("Agri","Tech","Emot","Kin","Poss","Soc","Hous","Wrld")
names(ling.dom.wide) = c("l1","l2",
paste0("L.",snames),
paste0("C.",snames))
compareAllDomains =
cor(ling.dom.wide[,
grepl("local_alignment",names(ling.dom.wide))],
ling.dom.wide[,
grepl("cult\\.dist",names(ling.dom.wide))],
use="complete.obs")
compareAllDomains =
cor(ling.dom.wide[,
grepl("L\\.",names(ling.dom.wide))],
ling.dom.wide[,
grepl("C\\.",names(ling.dom.wide))],
use="complete.obs")
compareAllDomains
round(compareAllDomains,2)
rm(list=ls())
---
title: "Cultural distances: Wikipedia data"
output:
pdf_document:
toc: true
---
```{r echo=F, eval=F}
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/analysis/")
```
# Introduction
We compare cultural distances between socieites with linguistic similarities between societies, controlling for shared history in two ways.
The first test uses mixed effects modelling.  The pairing of the language family of each language (according to Glottolog) is used as a random effect.  That means that the model can capture the likelihood that two languages from the Indo-European language family will be more similar to each other than two languages from different language families.  The same is done with geographic area according to Autotyp.
The second test controls for history using distances from a phylogenetic tree.  The tree comes from Bouckaert et al. (2012).  Patristic distances between languages are used as a measure of historical distance between societies in a Mantel test.  Note that the Mantel test assumes a strict distance metric, which is not necessarily the case with this data, but there are few other ways to deal with continuous pairwise distances.
# Load libraries
```{r warning=F, message=F}
library(ape)
library(ecodist)
library(lme4)
library(sjPlot)
library(ggplot2)
library(igraph)
library(lattice)
```
Parameters:
```{r}
datasetName = "wikipedia-main"
lingDistancesFile = "../data/FAIR/main-data-nel-wikipedia-k100-by-language-pair.csv"
lingDistancesByDomainFile = "../results/EA_distances/wikipedia_All_Domains_with_ling.csv"
# (generated by ../processing/combineCultAndLingDistances.R)
```
\newpage
# All domains
## Load data
Read the cultural distances:
```{r}
cult = read.csv("../results/EA_distances/CulturalDistances_Long.csv", stringsAsFactors = F)
names(cult) = c("l1","l2","cult.dist")
cultLangs = unique(c(cult$Var1,cult$Var2))
```
Add language family:
```{r}
l = read.csv("../data/FAIR_langauges_glotto_xdid.csv", stringsAsFactors = F)
g = read.csv("../data/glottolog-languoid.csv/languoid.csv", stringsAsFactors = F)
l$family = g[match(l$glotto,g$id),]$family_pk
l$family = g[match(l$family,g$pk),]$name
```
Read the semantic distances
```{r}
ling = read.csv(lingDistancesFile, stringsAsFactors = F)
```
There are very few possible comparisons for Slovenian and Northern Sami, so we'll remove these:
```{r}
ling = ling[!(ling$l1=="se" || ling$l2 == "se"),]
ling = ling[!(ling$l1=="sl" || ling$l2 == "sl"),]
```
Combine the lingusitic and cultural distances
cult$l1.iso2 = l[match(cult$l1,l$Language2),]$iso2
cult$l2.iso2 = l[match(cult$l2,l$Language2),]$iso2
dim(cult)
fairisos = unique(c(ling$l1,ling$l2))
cultisos = unique(c(cult$l1.iso2, cult$l2.iso2))
cult = cult[(cult$l1.iso2 %in% fairisos) & (cult$l2.iso2 %in% fairisos),]
ling = ling[(ling$l1 %in% cultisos) & (ling$l2 %in% cultisos),]
matches = sapply(1:nrow(ling), function(i){
which(cult$l1.iso2==ling$l1[i] & cult$l2.iso2==ling$l2[i])
})
ling$cult.dist = cult[matches,]$cult.dist
ling$cult.dist.center = scale(ling$cult.dist)
cdc.s = attr(ling$cult.dist.center,"scaled:scale")
cdc.c = attr(ling$cult.dist.center,"scaled:center")
ling$cult.dist.center = as.numeric(ling$cult.dist.center)
ling$family1 = l[match(ling$l1, l$iso2),]$family
ling$family2 = l[match(ling$l2, l$iso2),]$family
ling$area1 = l[match(ling$l1, l$iso2),]$autotyp.area
ling$area2 = l[match(ling$l2, l$iso2),]$autotyp.area
fgroup = cbind(ling$family1,ling$family2)
fgroup = apply(fgroup,1,sort)
ling$family.group = apply(fgroup,2,paste,collapse=":")
agroup = cbind(ling$area1,ling$area2)
agroup = apply(agroup,1,sort)
ling$area.group = apply(agroup,2,paste,collapse=":")
ling$rho.center = scale(ling$local_alignment)
fgroup
ling.dom.wide = reshape(ling.dom,
idvar = c("l1","l2"),
timevar = "imputed_semantic_domain",
direction = "wide")
ling.dom.wide = cbind(ling.dom.wide[,1:2],
ling.dom.wide[,3:ncol(ling.dom.wide)][
order(names(ling.dom.wide[,3:ncol(ling.dom.wide)]))
])
snames = c("Agri","Tech","Emot","Kin","Poss","Soc","Hous","Wrld")
names(ling.dom.wide) = c("l1","l2",
paste0("L.",snames),
paste0("C.",snames))
ling.dom = read.csv(
lingDistancesByDomainFile,
stringsAsFactors = F)
ling.dom = ling.dom[!is.na(ling.dom$cult.dist),]
ling.dom = ling.dom[(ling.dom$l1 %in% cultisos) &
(ling.dom$l2 %in% cultisos),]
```
There are very few possible comparisons for Slovenian and Northern Sami, so we'll remove these:
```{r}
ling.dom = ling.dom[!(ling.dom$l1=="se" || ling.dom$l2 == "se"),]
ling.dom = ling.dom[!(ling.dom$l1=="sl" || ling.dom$l2 == "sl"),]
```
Match family and area data:
```{r}
ling.dom$family1 = l[match(ling.dom$l1, l$iso2),]$family
ling.dom$family2 = l[match(ling.dom$l2, l$iso2),]$family
ling.dom$area1 = l[match(ling.dom$l1, l$iso2),]$autotyp.area
ling.dom$area2 = l[match(ling.dom$l2, l$iso2),]$autotyp.area
# Paste language family names together,
# but order shouldn't matter, so sort first
fgroup = cbind(ling.dom$family1,ling.dom$family2)
fgroup = apply(fgroup,1,sort)
ling.dom$family.group = apply(fgroup,2,paste,collapse=":")
agroup = cbind(ling.dom$area1,ling.dom$area2)
agroup = apply(agroup,1,sort)
ling.dom$area.group = apply(agroup,2,paste,collapse=":")
```
Center the data:
```{r}
ling.dom$cult.dist.center = scale(ling.dom$cult.dist)
ling.dom$rho.center = scale(ling.dom$local_alignment)
ling.dom.wide = reshape(ling.dom,
idvar = c("l1","l2"),
timevar = "imputed_semantic_domain",
direction = "wide")
ling.dom.wide = cbind(ling.dom.wide[,1:2],
ling.dom.wide[,3:ncol(ling.dom.wide)][
order(names(ling.dom.wide[,3:ncol(ling.dom.wide)]))
])
snames = c("Agri","Tech","Emot","Kin","Poss","Soc","Hous","Wrld")
names(ling.dom.wide) = c("l1","l2",
paste0("L.",snames),
paste0("C.",snames))
compareAllDomains =
cor(ling.dom.wide[,
grepl("L\\.",names(ling.dom.wide))],
ling.dom.wide[,
grepl("C\\.",names(ling.dom.wide))],
use="complete.obs")
head(ling.dom.wide)
ling.dom.wide = reshape(ling.dom,
idvar = c("l1","l2"),
timevar = "imputed_semantic_domain",
direction = "wide")
ling.dom.wide = cbind(ling.dom.wide[,1:2],
ling.dom.wide[,3:ncol(ling.dom.wide)][
order(names(ling.dom.wide[,3:ncol(ling.dom.wide)]))
])
head(ling.dom.wide)
names(ling.dom)
ling.dom.wide = ling.dom[,c("l1",'l2',"local_alignment","cult.dist")]
ling.dom.wide = reshape(ling.dom,
idvar = c("l1","l2"),
timevar = "imputed_semantic_domain",
direction = "wide")
ling.dom.wide = cbind(ling.dom.wide[,1:2],
ling.dom.wide[,3:ncol(ling.dom.wide)][
order(names(ling.dom.wide[,3:ncol(ling.dom.wide)]))
])
snames = c("Agri","Tech","Emot","Kin","Poss","Soc","Hous","Wrld")
names(ling.dom.wide) = c("l1","l2",
paste0("L.",snames),
paste0("C.",snames))
head(ling.dom.wide)
ling.dom.wide = ling.dom[,c("l1",'l2',"local_alignment","cult.dist")]
ling.dom.wide = reshape(ling.dom.wide,
idvar = c("l1","l2"),
timevar = "imputed_semantic_domain",
direction = "wide")
ling.dom.wide = cbind(ling.dom.wide[,1:2],
ling.dom.wide[,3:ncol(ling.dom.wide)][
order(names(ling.dom.wide[,3:ncol(ling.dom.wide)]))
])
snames = c("Agri","Tech","Emot","Kin","Poss","Soc","Hous","Wrld")
names(ling.dom.wide) = c("l1","l2",
paste0("L.",snames),
paste0("C.",snames))
ling.dom.wide = ling.dom[,c("l1",'l2',
'imputed_semantic_domain',
"local_alignment","cult.dist")]
ling.dom.wide = reshape(ling.dom.wide,
idvar = c("l1","l2"),
timevar = "imputed_semantic_domain",
direction = "wide")
ling.dom.wide = cbind(ling.dom.wide[,1:2],
ling.dom.wide[,3:ncol(ling.dom.wide)][
order(names(ling.dom.wide[,3:ncol(ling.dom.wide)]))
])
snames = c("Agri","Tech","Emot","Kin","Poss","Soc","Hous","Wrld")
names(ling.dom.wide) = c("l1","l2",
paste0("L.",snames),
paste0("C.",snames))
names(ling.dom.wide)
compareAllDomains =
cor(ling.dom.wide[,
grepl("L\\.",names(ling.dom.wide))],
ling.dom.wide[,
grepl("C\\.",names(ling.dom.wide))],
use="complete.obs")
round(compareAllDomains,2)
compareAllDomains =
cor(ling.dom.wide[,
grepl("L\\.",names(ling.dom.wide))],
ling.dom.wide[,
grepl("C\\.",names(ling.dom.wide))],
use="complete.obs")
round(compareAllDomains,2)
unique(ling.dom$imputed_semantic_domain)

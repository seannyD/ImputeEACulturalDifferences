edge.length=edge.length,
Nnode=1)
class(tip)<-"phylo"
obj<-bind.tree(tree,tip,where=where)
return(obj)
}
setNodeToTip = function(nodeName,tree, edge.length=0.001){
bind.tip(tree,nodeName, edge.length,which(tree$node.label==nodeName)[1] + length(tree$tip.label))
}
nodesToTips = function(phy, nodesToFix = phy$node.label[phy$node.label!='']){
for(nx in nodesToFix){
phy = setNodeToTip(nx,phy)
}
return(phy)
}
downloadTree <- function(glottoid){
url = paste("http://glottolog.org/resource/languoid/id/",glottoid,'.newick.txt',sep='')
tx = readLines(url)
return(tx[1])
}
#' Download glottolog trees from the web and convert to phylo objects
#'
#' @param glottoid The glottoid of the family to get (will be downloaded from the web) or local filename.
#' @param nodeLabelsBy How should the node labels be returned?  Glottolog trees have nodes labelled with glottoids, language names and sometimes iso codes. Defaults to "glottoid" for returning glottoids.
#' @param langNodesToTips Some languages in glottolog are not tips on the tree, but nodes with children (e.g. for languages with dialects).  If langNodesToTips is TRUE, the returned tree has extra tips for all nodes with non-blank labels.
#' @return phylo tree
#' @keywords Glottolog
#' @export
#' @examples
#' phy <- getGlottologTree("atla1278","glottoid")
getGlottologTree <- function(glottoid, nodeLabelsBy="glottoid", langNodesToTips=F, dichotomosTree=F){
if(grepl("^[a-z][a-z][a-z][a-z][0-9][0-9][0-9][0-9]$",glottoid)){
tx = downloadTree(glottoid)
} else{
tx = readLines(glottoid)[1]
}
# Add ending semicolon so that read.newick works
if(substr(tx,nchar(tx),nchar(tx))!=";"){
tx = paste(tx,";",sep='')
}
phy<-phytools::read.newick(text=tx)
phy$tip.label = editGlottologTipLabels(phy$tip.label,nodeLabelsBy)
phy$node.label = editGlottologTipLabels(phy$node.label,nodeLabelsBy)
if(langNodesToTips){
phy = nodesToTips(phy)
}
if(dichotomosTree){
phy = ape::multi2di(phy)
}
return(phy)
}
#
phy <- getGlottologTree("atla1278","glottoid")
phy
?readLines
phy <- getGlottologTree("atla1278","glottoid", langNodesToTips = T)
phy
'gola1255' %in% phy$tip.labels
plot(phy)
d = read.csv("~/Downloads/midata8613.csv")
head(d)
d$X.Date
as.Date(d$X.Date)
as.Date(as.character(d$X.Date))
?as.Date(as.character(d$X.Date))
as.Date(as.character(d$X.Date),"%d/%m/%Y")
d$date = as.Date(as.character(d$X.Date),"%d/%m/%Y")
plot(d$Balance,d$date)
plot(d$Balance~d$date)
plot(d$date,d$Balance)
plot(d$date,d$Balance, type = 'line')
head(d)
head(d$Balance)
d$Balance = as.numeric(d$Balance)
d$Balance
d$date = as.Date(as.character(d$X.Date),"%d/%m/%Y")
d$date = as.Date(as.character(d$X.Date),"%d/%m/%Y")
as.numeric(as.character(substring(d$Balance,2))
head(d$Balance)
as.numeric(as.character(substring(d$Balance,2)))
d$date = as.Date(as.character(d$X.Date),"%d/%m/%Y")
head(d$Balance)
d = read.csv("~/Downloads/midata8613.csv")
d$date = as.Date(as.character(d$X.Date),"%d/%m/%Y")
head(d$Balance)
as.numeric(as.character(substring(d$Balance,2)))
substring(d$Balance,2)
?substring(d$Balance,2)
X = head(d$Balance)
X
d$Balance = as.character(d$Balance)
d$Balance
X = head(d$Balance)
substring(X,2)
substring(X,1)
substring(X,4)
substring(X,3)
as.numeric(as.character(substring(d$Balance,3)))
d = read.csv("~/Downloads/midata8613.csv")
d$date = as.Date(as.character(d$X.Date),"%d/%m/%Y")
d$Balance = as.character(d$Balance)
d$Balance = as.numeric(as.character(substring(d$Balance,3)))
plot(d$date,d$Balance, type = 'line')
abline(as.Date(2017-01-01))
abline(v=as.Date(2017-01-01))
abline(h=as.Date(2017-01-01))
as.Date(2017-01-01)
abline(h=as.Date("2017-01-01"))
abline(v=as.Date("2017-01-01"))
abline(v=as.Date("2017-02-01"))
abline(v=as.Date("2017-03-01"))
d
d[45:46,]
factor(10)
factorial(10)
factorial(20)
numberOfSamples = 137
numberOfSamples/2
68 + 68
d = read.csv("~/Documents/MPI/LuisM_K_Pronoun/data/Alldata_simple.csv", stringsAsFactors = F)
head(d)
names(d)
g = read.csv("~/Documents/MPI/Glottolog/glottolog-languoid.csv/languoid.csv",stringsAsFactors = F)
names(g)
g$family = g[match(g$family_pk,g$pk),]$name
head(g$id)
d$family = g[match(d$glotto,g$id),]$family
head(d$family)
table(d$family)
d2 = d[d$family=="Uto-Aztecan",]
table(d2$meaning.id)
table(d2$Language)
d = read.delim("~/Documents/MPI/LuisM_K_Pronoun/BEAST_analysis/models/2017/relaxedClock_excludeSmall/relaxedClock_resampled.log",sep="\t", skip = 790, nrows = 10)
head(d)
plot(d$posterior)
d = read.delim("~/Documents/MPI/LuisM_K_Pronoun/BEAST_analysis/models/2017/relaxedClock_excludeSmall/relaxedClock_resampled.log",sep="\t", skip = 790, nrows = 20000)
plot(d$posterior)
plot(log(d$posterior))
plot(log(absd$posterior))
plot(log(abs(d$posterior)))
plot((d$posterior))
plot((d$posterior[3:nrow(d)]))
library(RColorBrewer)
RColorBrewer::display.brewer.all()
?RColorBrewer::display.brewer.all()
?display.brewer.all()
RColorBrewer::display.brewer.all(colorblindFriendly=T)
?display.brewer.all(colorblindFriendly=T)
brewer.pal(4,'Dark2')
plot(1:4,col=brewer.pal(4,'Dark2'),pch=15, cex=4)
plot(1:4,col=brewer.pal(4,'Set2'),pch=15, cex=4)
plot(1:6,col=brewer.pal(6,'Set2'),pch=15, cex=4)
plot(1:6,col=brewer.pal(6,'Dark2'),pch=15, cex=4)
pi
pi*0.5
library(REEMtree)
n = 300
x = as.factor(sample(1:4,n,replace = T))
y = as.factor(sample(1:4,n,replace = T))
REEMtree(x~y)
r = as.factor(rep(1:2,n/2))
library(REEMtree)
n = 300
x = as.factor(sample(1:4,n,replace = T))
y = as.factor(sample(1:4,n,replace = T))
r = as.factor(rep(1:2,n/2))
data = data.frame(x=x,y=y,r=r)
REEMtree(x~y,data=data,random=r)
x
# TODO:
# Include data on geographic area (+ sub-family?)
# Analyse accuracy on FAIR languages only?
library(reshape2)
library(ggplot2)
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/analysis/")
load("../data/EA_imputed/preImputed.Rdat")
# take out socid
eadx = eadx[,-1]
getAccuracy = function(f){
print(f)
load(f)
test.arrInd = test.arrInd[test.arrInd[,1]!=0,]
accuracy = sum(eadx2[test.arrInd] == eadx[test.arrInd])/nrow(test.arrInd)
# baseline
baseline = replicate(2,getRandomBaseline(test.arrInd,eadx,eadx2))
z = (accuracy - mean(baseline))/sd(baseline)
return(c(accuracy=accuracy, baseline=mean(baseline), z=z))
}
getRandomBaseline = function(test.arrInd, eadx, eadx2){
# imputation by random sampling
randomBaseline =
sapply(test.arrInd[,2], function(X){
sx = eadx2[,X]
sx = sx[!is.na(sx)]
sample(sx,1)
})
sum(randomBaseline == eadx[test.arrInd])/nrow(test.arrInd)
}
accuracy = sapply(
paste0("../results/imputationTests/",
list.files("../results/imputationTests/test2/","imputeTest_[0-9]*.rDat")),
getAccuracy)
accuracy = as.data.frame(t(accuracy))
mean(accuracy$accuracy)
mean(accuracy$baseline)
mean(accuracy$z)
ggplot(melt(accuracy[,1:2]), aes(x=variable,y=value,fill=variable)) + geom_boxplot() + coord_cartesian(ylim = c(0,1))
# TODO:
# Include data on geographic area (+ sub-family?)
# Analyse accuracy on FAIR languages only?
library(reshape2)
library(ggplot2)
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/analysis/")
load("../data/EA_imputed/preImputed.Rdat")
eadx = eadx[,-1]
getAccuracy = function(f){
print(f)
load(f)
test.arrInd = test.arrInd[test.arrInd[,1]!=0,]
accuracy = sum(eadx2[test.arrInd] == eadx[test.arrInd])/nrow(test.arrInd)
# baseline
baseline = replicate(2,getRandomBaseline(test.arrInd,eadx,eadx2))
z = (accuracy - mean(baseline))/sd(baseline)
return(c(accuracy=accuracy, baseline=mean(baseline), z=z))
}
getRandomBaseline = function(test.arrInd, eadx, eadx2){
# imputation by random sampling
randomBaseline =
sapply(test.arrInd[,2], function(X){
sx = eadx2[,X]
sx = sx[!is.na(sx)]
sample(sx,1)
})
sum(randomBaseline == eadx[test.arrInd])/nrow(test.arrInd)
}
# TODO:
# Include data on geographic area (+ sub-family?)
# Analyse accuracy on FAIR languages only?
library(reshape2)
library(ggplot2)
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/analysis/")
load("../data/EA_imputed/preImputed.Rdat")
# take out socid
eadx = eadx[,-1]
getAccuracy = function(f){
print(f)
load(f)
test.arrInd = test.arrInd[test.arrInd[,1]!=0,]
accuracy = sum(eadx2[test.arrInd] == eadx[test.arrInd])/nrow(test.arrInd)
# baseline
baseline = replicate(2,getRandomBaseline(test.arrInd,eadx,eadx2))
z = (accuracy - mean(baseline))/sd(baseline)
return(c(accuracy=accuracy, baseline=mean(baseline), z=z))
}
getRandomBaseline = function(test.arrInd, eadx, eadx2){
# imputation by random sampling
randomBaseline =
sapply(test.arrInd[,2], function(X){
sx = eadx2[,X]
sx = sx[!is.na(sx)]
sample(sx,1)
})
sum(randomBaseline == eadx[test.arrInd])/nrow(test.arrInd)
}
accuracy = sapply(
paste0("../results/imputationTests/test2/",
list.files("../results/imputationTests/test2/","imputeTest_[0-9]*.rDat")),
getAccuracy)
accuracy = as.data.frame(t(accuracy))
mean(accuracy$accuracy)
mean(accuracy$baseline)
mean(accuracy$z)
ggplot(melt(accuracy[,1:2]), aes(x=variable,y=value,fill=variable)) + geom_boxplot() + coord_cartesian(ylim = c(0,1))
accuracy = sapply(
paste0("../results/imputationTests/testFAIR/",
list.files("../results/imputationTests/testFAIR/","imputeTest_[0-9]*.rDat")),
getAccuracy)
accuracy = as.data.frame(t(accuracy))
mean(accuracy$accuracy)
mean(accuracy$baseline)
mean(accuracy$z)
list.files("../results/imputationTests/testFAIR/","imputeTest_*.rDat")
list.files("../results/imputationTests/testFAIR/")
list.files("../results/imputationTests/testFAIR/","imputeTest_*")
accuracy = sapply(
paste0("../results/imputationTests/testFAIR/",
list.files("../results/imputationTests/testFAIR/","imputeTest_*")),
getAccuracy)
accuracy = as.data.frame(t(accuracy))
mean(accuracy$accuracy)
mean(accuracy$baseline)
mean(accuracy$z)
accuracy.fair.area = sapply(
paste0("../results/imputationTests/testFAIR/",
list.files("../results/imputationTests/testFAIR/","imputeTest_*")),
getAccuracy)
accuracy.fair.area = as.data.frame(t(accuracy.fair.area))
mean(accuracy.fair.area$accuracy)
mean(accuracy.fair.area$baseline)
mean(accuracy.fair.area$z)
# TODO:
# Include data on geographic area (+ sub-family?)
# Analyse accuracy on FAIR languages only?
library(reshape2)
library(ggplot2)
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/analysis/")
load("../data/EA_imputed/preImputed.Rdat")
# take out socid
eadx = eadx[,-1]
getAccuracy = function(f){
print(f)
load(f)
test.arrInd = test.arrInd[test.arrInd[,1]!=0,]
accuracy = sum(eadx2[test.arrInd] == eadx[test.arrInd])/nrow(test.arrInd)
# baseline
baseline = replicate(3,getRandomBaseline(test.arrInd,eadx,eadx2))
z = (accuracy - mean(baseline))/sd(baseline)
return(c(accuracy=accuracy, baseline=mean(baseline), z=z))
}
getRandomBaseline = function(test.arrInd, eadx, eadx2){
# imputation by random sampling
randomBaseline =
sapply(test.arrInd[,2], function(X){
sx = eadx2[,X]
sx = sx[!is.na(sx)]
sample(sx,1)
})
sum(randomBaseline == eadx[test.arrInd])/nrow(test.arrInd)
}
accuracy = sapply(
paste0("../results/imputationTests/test2/",
list.files("../results/imputationTests/test2/","imputeTest_[0-9]*.rDat")),
getAccuracy)
accuracy = as.data.frame(t(accuracy))
mean(accuracy$accuracy)
mean(accuracy$baseline)
mean(accuracy$z)
ggplot(melt(accuracy[,1:2]), aes(x=variable,y=value,fill=variable)) + geom_boxplot() + coord_cartesian(ylim = c(0,1))
#####
accuracy.fair = sapply(
paste0("../results/imputationTests/testFAIR/",
list.files("../results/imputationTests/testFAIR/","imputeTest_*")),
getAccuracy)
accuracy.fair = as.data.frame(t(accuracy.fair))
mean(accuracy.fair$accuracy)
mean(accuracy.fair$baseline)
mean(accuracy.fair$z)
#####
accuracy.fair.area = sapply(
paste0("../results/imputationTests/testFAIR/",
list.files("../results/imputationTests/testFAIR/","imputeTest_*")),
getAccuracy)
accuracy.fair.area = as.data.frame(t(accuracy.fair.area))
mean(accuracy.fair.area$accuracy)
mean(accuracy.fair.area$baseline)
mean(accuracy.fair.area$z)
mean(accuracy.fair$accuracy)
mean(accuracy.fair$baseline)
mean(accuracy.fair.area$accuracy)
accuracy.fair.area = sapply(
paste0("../results/imputationTests/testFAIR_Area/",
list.files("../results/imputationTests/testFAIR_Area/","imputeTest_*")),
getAccuracy)
accuracy.fair.area = as.data.frame(t(accuracy.fair.area))
mean(accuracy.fair.area$accuracy)
mean(accuracy.fair.area$baseline)
mean(accuracy.fair.area$z)
accuracy.orig = sapply(
paste0("../results/imputationTests/test1/",
list.files("../results/imputationTests/test2/","imputeTest_[0-9]*.rDat")),
getAccuracy)
accuracy.orig = sapply(
paste0("../results/imputationTests/test1/",
list.files("../results/imputationTests/test1/","imputeTest_[0-9]*.rDat")),
getAccuracy)
accuracy.orig = as.data.frame(t(accuracy.orig))
mean(accuracy.orig$accuracy)
mean(accuracy.orig$baseline)
mean(accuracy.orig$z)
accuracy = as.data.frame(t(accuracy))
mean(accuracy$accuracy)
accuracy = sapply(
paste0("../results/imputationTests/test2/",
list.files("../results/imputationTests/test2/","imputeTest_[0-9]*.rDat")),
getAccuracy)
accuracy = as.data.frame(t(accuracy))
mean(accuracy$accuracy)
mean(accuracy$baseline)
mean(accuracy$z)
accuracy.fair = sapply(
paste0("../results/imputationTests/testFAIR/",
list.files("../results/imputationTests/testFAIR/","imputeTest_*")),
getAccuracy)
accuracy.fair = as.data.frame(t(accuracy.fair))
mean(accuracy.fair$accuracy)
mean(accuracy.fair$baseline)
mean(accuracy.fair$z)
accuracy.fair.area = sapply(
paste0("../results/imputationTests/testFAIR_Area/",
list.files("../results/imputationTests/testFAIR_Area/","imputeTest_*")),
getAccuracy)
accuracy.fair.area = as.data.frame(t(accuracy.fair.area))
mean(accuracy.fair.area$accuracy)
mean(accuracy.fair.area$baseline)
mean(accuracy.fair.area$z)
accuracy.fair.area$accuracy
hist(accuracy.fair.area$accuracy)
mean(accuracy.fair.area$accuracy)
median(accuracy.fair.area$accuracy)
max(accuracy.fair.area$accuracy)
list.files("../results/imputationTests/testFAIR_Area/","imputeTest_*")
list.files("../results/imputationTests/testFAIR_Area/","imputeTest_*")[1]
f = list.files("../results/imputationTests/testFAIR_Area/","imputeTest_*")[1]
f = "../results/imputationTests/testFAIR_Area/imputeTest_FAIR_Area_1037029.rDat"
print(f)
load(f)
ls()
dim(eadx2)
f
f = "../results/imputationTests/test2/imputeTest_1094235.rDat"
load(f)
dim(eadx2)
head(eadx2)
f = "../results/imputationTests/testFAIR_Area/imputeTest_FAIR_Area_1037029.rDat"
load(f)
head(eadx2)
table(eadx2$autotyp.area)
head(eadx2)
test.arrInd[,1]
eadx2[test.arrInd] == eadx[test.arrInd]
names(eadx)
head(eadx2)
names(eadx2)
names(eadx)
sum(eadx2[test.arrInd] == eadx[test.arrInd])/nrow(test.arrInd)
# TODO:
# Include data on geographic area (+ sub-family?)
# Analyse accuracy on FAIR languages only?
library(reshape2)
library(ggplot2)
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/analysis/")
load("../data/EA_imputed/preImputed.Rdat")
eadx$soc.id = eadx[,1]
# take out socid
eadx = eadx[,-1]
eadx$soc.id
test.arrInd[,1]
eadxtest.arrInd[,1]
# TODO:
# Include data on geographic area (+ sub-family?)
# Analyse accuracy on FAIR languages only?
library(reshape2)
library(ggplot2)
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/analysis/")
load("../data/EA_imputed/preImputed.Rdat")
soc.id = eadx[,1]
# take out socid
eadx = eadx[,-1]
soc.id[test.arrInd[,1]]
unique(soc.id[test.arrInd[,1]])
dim(test.arrInd)
dim(eadx)
sum(is.na(eadx))
baseline = replicate(10,getRandomBaseline(test.arrInd,eadx,eadx2))
z = (accuracy - mean(baseline))/sd(baseline)
c(accuracy=accuracy, baseline=mean(baseline), z=z)
(accuracy - mean(baseline))/sd(baseline)
test.arrInd = test.arrInd[test.arrInd[,1]!=0,]
accuracy = sum(eadx2[test.arrInd] == eadx[test.arrInd])/nrow(test.arrInd)
# baseline
baseline = replicate(10,getRandomBaseline(test.arrInd,eadx,eadx2))
z = (accuracy - mean(baseline))/sd(baseline)
z
c(accuracy=accuracy, baseline=mean(baseline), z=z)
# TODO:
# Include data on geographic area (+ sub-family?)
# Analyse accuracy on FAIR languages only?
library(reshape2)
library(ggplot2)
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/analysis/")
load("../data/EA_imputed/preImputed.Rdat")
soc.id = eadx[,1]
# take out socid
eadx = eadx[,-1]
getAccuracy = function(f){
print(f)
load(f)
test.arrInd = test.arrInd[test.arrInd[,1]!=0,]
accuracy = sum(eadx2[test.arrInd] == eadx[test.arrInd])/nrow(test.arrInd)
# baseline
baseline = replicate(10,getRandomBaseline(test.arrInd,eadx,eadx2))
z = (accuracy - mean(baseline))/sd(baseline)
return(c(accuracy=accuracy, baseline=mean(baseline), z=z))
}
getRandomBaseline = function(test.arrInd, eadx, eadx2){
# imputation by random sampling
randomBaseline =
sapply(test.arrInd[,2], function(X){
sx = eadx2[,X]
sx = sx[!is.na(sx)]
sample(sx,1)
})
sum(randomBaseline == eadx[test.arrInd])/nrow(test.arrInd)
}
accuracy.fair.area = sapply(
paste0("../results/imputationTests/testFAIR_Area/",
list.files("../results/imputationTests/testFAIR_Area/","imputeTest_*")),
getAccuracy)
accuracy.fair.area = as.data.frame(t(accuracy.fair.area))
mean(accuracy.fair.area$accuracy)
mean(accuracy.fair.area$baseline)
mean(accuracy.fair.area$z)

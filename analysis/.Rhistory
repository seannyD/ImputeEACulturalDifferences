str = prop.table(table(rc$KS.Try.marking))[1]
scu
st0
st1
stt
str
cbind(rc$KS.Try.marking, rc$Try.marking)
dim()
dim(cbind(rc$KS.Try.marking, rc$Try.marking))
dim(tm[complete.cases(tm),])
cohen.kappa(tm)
library(psych)
setwd("~/Documents/MPI/KangSukColours/ColourExperiment/processing/")
millisecondsToReadbleTime = function(t){
seconds = floor((t/1000)) %% 60
minutes = floor((t/1000)/60)
return(paste(minutes,"min",seconds,"sec"))
}
d = read.csv("../data/processedData/variants_processed.csv", stringsAsFactors = F)
colourNumbers = as.numeric(c("1","5","7","14",'18','24','6'))
d = d[d$trial_value %in% colourNumbers,]
rc = read.delim("../data/reliability/RandomVariants21oktober2017.txt",sep="\t", stringsAsFactors = F)
rc = rc[rc$Try.marking!="No coding",]
rc2 = read.delim("../data/reliability/RandomVariants3December2017.txt",sep="\t", stringsAsFactors = F)
names(rc2)[names(rc2)=="X.2"] = "Comments"
if(!"Candidate.Understanding" %in% names(rc2)){
rc2$Candidate.Understanding = NA
}
rc2 = rc2[,names(rc)]
rc = rbind(rc,rc2)
for(v in c("Try.marking","T0",'T.1', 'Teaching', 'Candidate.Understanding')){
print(v)
rc[!is.na(rc[,v]) & rc[,v]=="YES",v] = TRUE
rc[!is.na(rc[,v]) & rc[,v]=="NO",v] = FALSE
rc[(!is.na(rc[,v])) & (!rc[,v]%in% c(TRUE,FALSE)),v] = NA
rc[,v] = rc[,v]=="TRUE"
}
# Check matching of cases is correct
rc$sign_start == millisecondsToReadbleTime(d[match(rc$X, d$X),]$sign_start)
rc$KS.Try.marking = d[match(rc$X, d$X),]$TryMarked
rc$KS.T0 = d[match(rc$X, d$X),]$T0
rc$KS.T.1 = d[match(rc$X, d$X),]$T_minus_1
rc$KS.Teaching = d[match(rc$X, d$X),]$Teach
rc$KS.Candidate.Understanding = d[match(rc$X, d$X),]$CandidateUnderstanding=="Yes"
table(rc$KS.Try.marking, rc$Try.marking)
tm = cbind(rc$KS.Try.marking, rc$Try.marking)
tm = tm[complete.cases(tm),]
cohen.kappa(tm)
table(rc$KS.T0, rc$T0)
t0 = cbind(rc$KS.T0, rc$T0)
t0 = t0[complete.cases(t0),]
cohen.kappa(t0)
table(rc$KS.T.1, rc$T.1)
tm1 = cbind(rc$KS.T.1, rc$T.1)
tm1 = tm1[complete.cases(tm1),]
cohen.kappa(tm1)
table(rc$KS.Teaching, rc$Teaching)
tteaching = cbind(rc$KS.Teaching, rc$Teaching)
tteaching = tteaching[complete.cases(tteaching),]
cohen.kappa(tteaching)
table(rc$KS.Candidate.Understanding, rc$Candidate.Understanding)
tcu = cbind(rc$KS.Candidate.Understanding, rc$Candidate.Understanding)
tcu = tcu[complete.cases(tcu),]
cohen.kappa(tcu)
#write.csv(rc, "")
scu = prop.table(table(rc$KS.Candidate.Understanding))[1]
st0 = prop.table(table(rc$KS.T0))[1]
st1 = prop.table(table(rc$KS.T.1))[1]
stt = prop.table(table(rc$KS.Teaching))[1]
str = prop.table(table(rc$KS.Try.marking))[1]
scu
st0
st1
stt
str
sum(rc$KS.Try.marking!=rc$Try.marking)
sum(rc$KS.Try.marking!=rc$Try.marking,na.rm=T)
!is.na(rc$Candidate.Understanding) & rc$KS.Candidate.Understanding!=rc$Candidate.Understanding
library(psych)
setwd("~/Documents/MPI/KangSukColours/ColourExperiment/processing/")
millisecondsToReadbleTime = function(t){
seconds = floor((t/1000)) %% 60
minutes = floor((t/1000)/60)
return(paste(minutes,"min",seconds,"sec"))
}
d = read.csv("../data/processedData/variants_processed.csv", stringsAsFactors = F)
colourNumbers = as.numeric(c("1","5","7","14",'18','24','6'))
d = d[d$trial_value %in% colourNumbers,]
rc = read.delim("../data/reliability/RandomVariants21oktober2017.txt",sep="\t", stringsAsFactors = F)
rc = rc[rc$Try.marking!="No coding",]
rc2 = read.delim("../data/reliability/RandomVariants3December2017.txt",sep="\t", stringsAsFactors = F)
names(rc2)[names(rc2)=="X.2"] = "Comments"
if(!"Candidate.Understanding" %in% names(rc2)){
rc2$Candidate.Understanding = NA
}
rc2 = rc2[,names(rc)]
rc = rbind(rc,rc2)
for(v in c("Try.marking","T0",'T.1', 'Teaching', 'Candidate.Understanding')){
print(v)
rc[!is.na(rc[,v]) & rc[,v]=="YES",v] = TRUE
rc[!is.na(rc[,v]) & rc[,v]=="NO",v] = FALSE
rc[(!is.na(rc[,v])) & (!rc[,v]%in% c(TRUE,FALSE)),v] = NA
rc[,v] = rc[,v]=="TRUE"
}
# Check matching of cases is correct
rc$sign_start == millisecondsToReadbleTime(d[match(rc$X, d$X),]$sign_start)
rc$KS.Try.marking = d[match(rc$X, d$X),]$TryMarked
rc$KS.T0 = d[match(rc$X, d$X),]$T0
rc$KS.T.1 = d[match(rc$X, d$X),]$T_minus_1
rc$KS.Teaching = d[match(rc$X, d$X),]$Teach
rc$KS.Candidate.Understanding = d[match(rc$X, d$X),]$CandidateUnderstanding=="Yes"
table(rc$KS.Try.marking, rc$Try.marking)
tm = cbind(rc$KS.Try.marking, rc$Try.marking)
tm = tm[complete.cases(tm),]
cohen.kappa(tm)
table(rc$KS.T0, rc$T0)
t0 = cbind(rc$KS.T0, rc$T0)
t0 = t0[complete.cases(t0),]
cohen.kappa(t0)
table(rc$KS.T.1, rc$T.1)
tm1 = cbind(rc$KS.T.1, rc$T.1)
tm1 = tm1[complete.cases(tm1),]
cohen.kappa(tm1)
table(rc$KS.Teaching, rc$Teaching)
tteaching = cbind(rc$KS.Teaching, rc$Teaching)
tteaching = tteaching[complete.cases(tteaching),]
cohen.kappa(tteaching)
table(rc$KS.Candidate.Understanding, rc$Candidate.Understanding)
tcu = cbind(rc$KS.Candidate.Understanding, rc$Candidate.Understanding)
tcu = tcu[complete.cases(tcu),]
cohen.kappa(tcu)
#write.csv(rc, "")
scu = prop.table(table(rc$KS.Candidate.Understanding))[1]
st0 = prop.table(table(rc$KS.T0))[1]
st1 = prop.table(table(rc$KS.T.1))[1]
stt = prop.table(table(rc$KS.Teaching))[1]
str = prop.table(table(rc$KS.Try.marking))[1]
scu
st0
st1
stt
str
rc$CU.disagree = !is.na(rc$Candidate.Understanding) & rc$KS.Candidate.Understanding!=rc$Candidate.Understanding
rc$T0.disagree = !is.na(rc$T0) & rc$KS.T0!=rc$T0
rc$T.1.disagree = !is.na(rc$T.1) & rc$KS.T.1!=rc$T.1
rc$Teaching.disagree = !is.na(rc$Teaching) & rc$KS.Teaching!=rc$Teaching
rc$Try.marking.disagree = !is.na(rc$Try.marking) & rc$KS.Try.marking!=rc$Try.marking
rc$CU.disagree
rc.disagree = rc[rc$CU.disagree | rc$T0.disagree | rc$T.1.disagree | rc$Teaching.disagree | rc$Try.marking.disagree,]
dim(rc.disagree)
rc.disagree
rc.disagree[order(rc.disagree$T.1.disagree, rc.disagree$CU.disagree, rc.disagree$Try.marking, rc.disagree$Teaching, rc.disagree$T0),]
?order
rc.disagree[order(rc.disagree$T.1.disagree, rc.disagree$CU.disagree, rc.disagree$Try.marking, rc.disagree$Teaching, rc.disagree$T0, decreasing = T),]
write.csv("../data/reliability/Disagreements.csv")
write.csv(rc.disagree,"../data/reliability/Disagreements.csv")
dim(rc)
table(rc$KS.T0, rc$T0)
cohen.kappa(t0)
cohen.kappa(tm1)
table(rc$KS.T.1, rc$T.1)
sum(table(rc$KS.T.1, rc$T.1))
33/sum(table(rc$KS.T.1, rc$T.1))
names(rc.disagree)
library(reshape2)
library(ggplot2)
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/analysis/")
load("../data/EA_imputed/preImputed.Rdat")
soc.id = eadx[,1]
# take out socid
eadx = eadx[,-1]
getAccuracy = function(f){
#print(f)
load(f)
test.arrInd = test.arrInd[test.arrInd[,1]!=0,]
accuracy = sum(eadx2[test.arrInd] == eadx[test.arrInd])/nrow(test.arrInd)
# baseline
baseline = replicate(10,getRandomBaseline(test.arrInd,eadx,eadx2))
z = (accuracy - mean(baseline))/sd(baseline)
return(c(accuracy=accuracy, baseline=mean(baseline), z=z))
}
getRandomBaseline = function(test.arrInd, eadx, eadx2){
# imputation by random sampling
randomBaseline =
sapply(test.arrInd[,2], function(X){
sx = eadx2[,X]
sx = sx[!is.na(sx)]
sample(sx,1)
})
sum(randomBaseline == eadx[test.arrInd])/nrow(test.arrInd)
}
getFolderAccuracy = function(folder,prefix){
accuracy.orig = sapply(
paste0(folder,
list.files(folder,prefix)),
getAccuracy)
accuracy.orig = as.data.frame(t(accuracy.orig))
return(c(mean(accuracy.orig$accuracy),
(mean(accuracy.orig$baseline)),
(mean(accuracy.orig$z))))
}
getFolderAccuracy("../results/imputationTests/testFAIR_15/","imputeTest_*")
folder = ""../results/imputationTests/testFAIR_15/"
folder = "../results/imputationTests/testFAIR_15/"
prfix = "imputeTest_*"
perfix = "imputeTest_*"
prefix = "imputeTest_*"
accuracy.orig = sapply(
paste0(folder,
list.files(folder,prefix)),
getAccuracy)
paste0(folder,
list.files(folder,prefix)[1])
f = paste0(folder,
list.files(folder,prefix)[1])
load(f)
test.arrInd = test.arrInd[test.arrInd[,1]!=0,]
accuracy = sum(eadx2[test.arrInd] == eadx[test.arrInd])/nrow(test.arrInd)
accuracy
test.arrInd
accuracy.orig = sapply(
paste0(folder,
list.files(folder,prefix)),
getAccuracy)
accuracy.orig
sum(is.na(accuracy.orig))
f = '../results/imputationTests/testFAIR_15/imputeTest_FAIR_1519781.rDat'
load(f)
test.arrInd[test.arrInd[,1]!=0,]
test.arrInd = test.arrInd[test.arrInd[,1]!=0,]
sum(eadx2[test.arrInd] == eadx[test.arrInd])/nrow(test.arrInd)
sum(eadx2[test.arrInd] == eadx[test.arrInd])
eadx2[test.arrInd] == eadx[test.arrInd]
test.arrInd
eadx2[test.arrInd]
eadx[test.arrInd]
test.arrInd
max(test.arrInd[,1])
dim(eadx)
dim(eadx2)
head(eadx)
load("../data/EA_imputed/preImputed.Rdat")
soc.id = eadx[,1]
# take out socid
eadx = eadx[,-1]
head(soc.id)
head(eadx2)
head(eadx2$Family)
eadx2$Family
dim(eadx2)
load(f)
dim(eadx)
dim(eadx2)
# Includes family and area
library(mice)
prop.missing = 0.025
load("../data/EA_imputed/preImputed.Rdat")
fairlangs = read.csv("../data/FAIR_langauges_glotto_xdid.csv",stringsAsFactors = F)
eadx.in.final.analysis = fairlangs[match(eadx$soc_id, fairlangs$soc.id),]$in.final.analysis
eadx.in.final.analysis[is.na(eadx.in.final.analysis)] = F
numFairLangs = sum(eadx.in.final.analysis)
non.fair.langs = which(!eadx.in.final.analysis)
eadx.soc.id = eadx[,1]
# take out socid
eadx = eadx[,-1]
non.fair.langs.cells = matrix(T,nrow=nrow(eadx),ncol=ncol(eadx))
non.fair.langs.cells[non.fair.langs,] = F
n.test = round(prop.missing * numFairLangs * (ncol(eadx)-2))
# potential cells to use for testing
idx = 1:prod(dim(eadx))
# exclude cells that are already NA, or in the
#  family column
nas = which(is.na(eadx),arr.ind = F)
# Last two columns
familyAreaCells = (prod(dim(eadx))-(2*nrow(eadx))):prod(dim(eadx))
idx = idx[!idx %in% nas]
idx = idx[!idx %in% familyAreaCells]
idx = idx[idx %in% which(non.fair.langs.cells)]
test = sample(idx, n.test)
test.arrInd = cbind(
test %% nrow(eadx),
ceiling(test/(nrow(eadx))))
# create new NAs
for(i in 1:nrow(test.arrInd)){
eadx[test.arrInd[i,1], test.arrInd[i,2]] = NA
}
dim(eadx)
# USE the mice package to do multiple imputation.
# The method used is classification trees.
#  Language family is added as a variable with which the tree can make guesses about the missing data, allowing some control for language-family-specific tendencies.
library(tidyr)
library(mice)
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/processing/")
l = read.csv("../data/FAIR_langauges_glotto_xdid.csv", stringsAsFactors = F)
eav = read.csv("../data/dplace-data-1.0/csv/EAVariableList.csv", stringsAsFactors = F)
ead = read.csv("../data/dplace-data-1.0/csv/EA_data.csv", stringsAsFactors = F)
# Load society data
eag = read.csv("../data/xd_id_to_language_and_area.csv", stringsAsFactors = F)
eas = read.csv("../data/dplace-data-1.0/csv/EA_societies.csv")
# Proportion of missing data
sum(is.na(ead$Code))/nrow(ead)
# restrict societies to those in the facebook sample
#ead = ead[ead$soc_id %in% l$soc.id,]
#ead = ead[,!names(ead) %in% c("Dataset","SubCase",'Year','VarID_Code',"Comment","EthnoReferences","SourceCodedData","AdminComment")]
ead = ead[,c("soc_id", "VarID",  "Code")]
eadx = spread(data = ead, VarID, Code)
xid = eas[match(eadx$soc_id, eas$soc_id),]$xd_id
eadx$Family = eag[match(xid,eag$xd_id),]$FamilyGlottocode
eadx$autotyp.area = eag[match(xid,eag$xd_id),]$autotyp.area
# remove pop size
eadx = eadx[,names(eadx)!="202"]
numObs = apply(eadx,2,function(X){sum(!is.na(X))})
eadx = eadx[,names(eadx) %in% names(numObs[numObs>60])]
numLangs = apply(eadx,1,function(X){sum(is.na(X))})
eadx = eadx[numLangs<31,]
in.final.and.ea = eadx$soc_id %in% l[l$in.final.analysis & !is.na(l$soc.id),]$soc.id
# missing data total
sum(is.na(eadx[,2:(ncol(eadx)-2)])) / prod(dim(eadx[,2:(ncol(eadx)-2)]))
# Missing data FAIR
sum(is.na(eadx[in.final.and.ea,2:(ncol(eadx)-2)])) / prod(dim(eadx[in.final.and.ea,2:(ncol(eadx)-2)]))
# Convert to factor
for(i in 2:ncol(eadx)){
isOrdered = F
ox = eav[match(names(eadx)[i],eav$VarID),]$VarType
if(!is.na(ox)){
if(ox=="Ordinal"){
isOrdered = T
}
}
if(isOrdered){
eadx[,i] = as.ordered(eadx[,i])
} else{
eadx[,i] = as.factor(eadx[,i])
}
}
# eadx = eadx[sample(1:nrow(eadx),100),c(2,3,4,ncol(eadx))]
dim(eadx)
accuracy
f
load(f)
test.arrInd = test.arrInd[test.arrInd[,1]!=0,]
accuracy = sum(eadx2[test.arrInd] == eadx[test.arrInd])/nrow(test.arrInd)
accuracy
f = "../results/imputationTests/testFAIR_15/imputeTest_FAIR_15_120852.rDat"
load(f)
test.arrInd = test.arrInd[test.arrInd[,1]!=0,]
accuracy = sum(eadx2[test.arrInd] == eadx[test.arrInd])/nrow(test.arrInd)
accuracy
accuracy.orig
f = "../results/imputationTests/testFAIR_15/imputeTest_FAIR_15_992457.rDat"
load(f)
test.arrInd = test.arrInd[test.arrInd[,1]!=0,]
accuracy = sum(eadx2[test.arrInd] == eadx[test.arrInd])/nrow(test.arrInd)
accuracy
dim(eadx2)
dim(eadx)
load(f)
test.arrInd = test.arrInd[test.arrInd[,1]!=0,]
accuracy = sum(eadx2[test.arrInd] == eadx[test.arrInd])/nrow(test.arrInd)
accuracy
eadx2[test.arrInd]
eadx[test.arrInd]
library(reshape2)
library(ggplot2)
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/analysis/")
load("../data/EA_imputed/preImputed.Rdat")
soc.id = eadx[,1]
# take out socid
eadx = eadx[,-1]
dim(eadx)
dim(eadx2)
load(f)
test.arrInd = test.arrInd[test.arrInd[,1]!=0,]
accuracy = sum(eadx2[test.arrInd] == eadx[test.arrInd])/nrow(test.arrInd)
accuracy
eadx2[test.arrInd]
eadx[test.arrInd]
library(reshape2)
library(ggplot2)
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/analysis/")
load("../data/EA_imputed/preImputed.Rdat")
soc.id = eadx[,1]
# take out socid
eadx = eadx[,-1]
getAccuracy = function(f){
#print(f)
load(f)
if(nrow(eadx2)==nrow(eadx)){
test.arrInd = test.arrInd[test.arrInd[,1]!=0,]
accuracy = sum(eadx2[test.arrInd] == eadx[test.arrInd])/nrow(test.arrInd)
# baseline
baseline = replicate(10,getRandomBaseline(test.arrInd,eadx,eadx2))
z = (accuracy - mean(baseline))/sd(baseline)
return(c(accuracy=accuracy, baseline=mean(baseline), z=z))} else{
return(c(accuracy=NA, baseline=NA, z=NA))
}
}
getRandomBaseline = function(test.arrInd, eadx, eadx2){
# imputation by random sampling
randomBaseline =
sapply(test.arrInd[,2], function(X){
sx = eadx2[,X]
sx = sx[!is.na(sx)]
sample(sx,1)
})
sum(randomBaseline == eadx[test.arrInd])/nrow(test.arrInd)
}
getFolderAccuracy = function(folder,prefix){
accuracy.orig = sapply(
paste0(folder,
list.files(folder,prefix)),
getAccuracy)
accuracy.orig = as.data.frame(t(accuracy.orig))
return(c(mean(accuracy.orig$accuracy,na.rm=T),
(mean(accuracy.orig$baseline,na.rm=T)),
(mean(accuracy.orig$z,na.rm=T))))
}
getFolderAccuracy("../results/imputationTests/testFAIR_15/","imputeTest_*")
accuracy.orig = sapply(
paste0(folder,
list.files(folder,prefix)),
getAccuracy)
accuracy.orig
accuracy.orig = as.data.frame(t(accuracy.orig))
sum(is.na(accuracy.orig$accuracy))
sum(is.na(accuracy.orig$baseline))
sum(is.na(accuracy.orig$z))
length(accuracy.orig$accuracy)
getFolderAccuracy("../results/imputationTests/testFAIR_15/","imputeTest_FAIR_15_*")
library(reshape2)
library(ggplot2)
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/analysis/")
load("../data/EA_imputed/preImputed.Rdat")
soc.id = eadx[,1]
# take out socid
eadx = eadx[,-1]
getAccuracy = function(f){
#print(f)
load(f)
if(nrow(eadx2)==nrow(eadx)){
test.arrInd = test.arrInd[test.arrInd[,1]!=0,]
accuracy = sum(eadx2[test.arrInd] == eadx[test.arrInd])/nrow(test.arrInd)
# baseline
baseline = replicate(10,getRandomBaseline(test.arrInd,eadx,eadx2))
z = (accuracy - mean(baseline))/sd(baseline)
return(c(accuracy=accuracy, baseline=mean(baseline), z=z))} else{
print("Row numbers don't match")
}
}
getRandomBaseline = function(test.arrInd, eadx, eadx2){
# imputation by random sampling
randomBaseline =
sapply(test.arrInd[,2], function(X){
sx = eadx2[,X]
sx = sx[!is.na(sx)]
sample(sx,1)
})
sum(randomBaseline == eadx[test.arrInd])/nrow(test.arrInd)
}
getFolderAccuracy = function(folder,prefix){
accuracy.orig = sapply(
paste0(folder,
list.files(folder,prefix)),
getAccuracy)
accuracy.orig = as.data.frame(t(accuracy.orig))
return(c(mean(accuracy.orig$accuracy,na.rm=T),
(mean(accuracy.orig$baseline,na.rm=T)),
(mean(accuracy.orig$z,na.rm=T))))
}
########################
getFolderAccuracy("../results/imputationTests/testFAIR_15/","imputeTest_FAIR_15_*")
library(reshape2)
library(ggplot2)
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/analysis/")
load("../data/EA_imputed/preImputed.Rdat")
soc.id = eadx[,1]
# take out socid
eadx = eadx[,-1]
getAccuracy = function(f){
#print(f)
load(f)
if(nrow(eadx2)==nrow(eadx)){
test.arrInd = test.arrInd[test.arrInd[,1]!=0,]
accuracy = sum(eadx2[test.arrInd] == eadx[test.arrInd])/nrow(test.arrInd)
# baseline
baseline = replicate(100,getRandomBaseline(test.arrInd,eadx,eadx2))
z = (accuracy - mean(baseline))/sd(baseline)
return(c(accuracy=accuracy, baseline=mean(baseline), z=z))} else{
print("Row numbers don't match")
}
}
getRandomBaseline = function(test.arrInd, eadx, eadx2){
# imputation by random sampling
randomBaseline =
sapply(test.arrInd[,2], function(X){
sx = eadx2[,X]
sx = sx[!is.na(sx)]
sample(sx,1)
})
sum(randomBaseline == eadx[test.arrInd])/nrow(test.arrInd)
}
getFolderAccuracy = function(folder,prefix){
accuracy.orig = sapply(
paste0(folder,
list.files(folder,prefix)),
getAccuracy)
accuracy.orig = as.data.frame(t(accuracy.orig))
return(c(mean(accuracy.orig$accuracy,na.rm=T),
(mean(accuracy.orig$baseline,na.rm=T)),
(mean(accuracy.orig$z,na.rm=T))))
}
getFolderAccuracy("../results/imputationTests/testFAIR_15/","imputeTest_FAIR_15_*")

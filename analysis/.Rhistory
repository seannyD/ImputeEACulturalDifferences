dists[[cbx[2,cx]]][upperx]))
}
mean(cor.x)
# Get mean values of each cell across imputations
dist.m = Reduce('+', dists)
dist.m = dist.m / length(dists)
# get variation
var = apply(simplify2array(dists), 1:2, sd)
hist(var[upper.tri(var,diag = F)])
# variation over mean distance
hist((var/dist.m)[upper.tri(var,diag=F)])
quantile((var/dist.m)[upper.tri(var,diag=F)], probs = c(0.95))
# tests of normality
norm.test = apply(simplify2array(dists), 1:2,
function(X){
if(length(unique(as.vector(X)))>3){
return(shapiro.test(X)$p.value)}
else{
return(NA)
}
})
# Write distance matrix
write.csv(dist.m, "../results/EA_distances/CulturalDistances.csv")
# convert to long form
dist.long = melt(dist.m)
write.csv(dist.long, file="../results/EA_distances/CulturalDistances_Long.csv", row.names = F)
# Visualise the distances
hc = hclust(dist(dist.m))
pdf("../results/CulturalDistanceTrees/CulturalDistance.pdf", width=20, height=10)
plot(hc)
dev.off()
#################
# Make geographic distances
g = read.csv("../data/glottolog-languoid.csv/languoid.csv",stringsAsFactors = F,encoding = "UTF-8",fileEncoding = "UTF-8")
l$lat = g[match(l$glotto,g$id),]$latitude
l$long = g[match(l$glotto,g$id),]$longitude
library(fields)
geoDist = fields::rdist.earth(l[,c("long","lat")],miles=F)
rownames(geoDist) = l$Language
colnames(geoDist) = l$Language
geoDist = geoDist[l$in.final.analysis,l$in.final.analysis]
write.csv(geoDist,file="../data/GeographicDistances.csv",row.names = F,fileEncoding = "UTF-8")
####################################
# Make sub-domain distance matrices according to the original D-PLACE domains:
dpCultDistLong = data.frame()
for(dom in unique(eav$MainCategory)){
print(dom)
eavars = eav[eav$MainCategory==dom,]$VarID
if(length(eavars)>1){
distsC = list()
for(j in 1:length(files)){
#print(files[j])
distsC[[j]] = makeDistanceMatrix(
paste0("../data/EA_imputed/completeDataframes/",files[j]),
variables=c(paste0("X",eavars),"soc_id"))
}
distx.m = Reduce('+', distsC)
distx.m = distx.m / length(distsC)
distx.long = melt(distx.m)
names(distx.long) = c("l1","l2","cult.dist")
distx.long$domain = dom
distx.long$numCultVars = length(eavars)
dpCultDistLong = rbind(dpCultDistLong,distx.long)
#filenamex = gsub(' ',"_",dom)
#write.csv(distx.long,
#          file=paste0("../results/EA_distances_DPlaceDomains/",filenamex,'_long.csv'), row.names = F)
}
}
write.csv(dpCultDistLong, file="../results/EA_distances_DPlaceDomains/CultDistancesByDPlaceMainDomain.csv",row.names = F)
#####################################
# Make sub-domain distance matrices according to the mapping to Concepticon:
# Load mappings between concepticon and Ethnographic Atlas
c2ea = read.csv("../data/Concepticon_to_EA.csv", stringsAsFactors = F)
# Remove domains that don't have matches
c2ea = c2ea[!is.na(c2ea$ea),]
c2ea = c2ea[c2ea$ea!="",]
c2ea.for.printing = data.frame()
# For each sub-domain, make a distance matrix and visualisation
for(i in 1:nrow(c2ea)){
print(c2ea$concepticon[i])
cats = strsplit(c2ea[i,]$ea,"-")[[1]]
eavars = c()
for(cx in cats){
eavars = c(eavars,eav[grepl(cx,eav$IndexCategory),]$VarID)
}
eavars = unique(eavars)
#distx = dist(eadx[,names(eadx) %in% paste0("X",eavars)])
c2ea.for.printing = rbind(c2ea.for.printing,
data.frame(
Concepticon.Domain =c2ea$concepticon[i],
EA.VarID = eavars,
EA.IndexCategory = eav[match(eavars,eav$VarID),]$IndexCategory,
EA.VarTitle = eav[match(eavars,eav$VarID),]$VarTitle,
stringsAsFactors = F
))
distsC = list()
for(j in 1:length(files)){
print(files[j])
distsC[[j]] = makeDistanceMatrix(
paste0("../data/EA_imputed/completeDataframes/",files[j]),
variables=c(paste0("X",eavars),"soc_id"))
}
distx.m = Reduce('+', distsC)
distx.m = distx.m / length(distsC)
filenamex = gsub(' ',"_",c2ea[i,]$concepticon)
write.csv(
distx.m,
file = paste0("../results/EA_distances/",filenamex,'.csv')
)
distx.long = melt(distx.m)
write.csv(distx.long,
file=paste0("../results/EA_distances/",filenamex,'_long.csv'), row.names = F)
hcx = hclust(as.dist(distx.m))
pdf(
paste0("../results/CulturalDistanceTrees/CulturalDistance_",filenamex,".pdf"),
width=20, height=10)
plot(hcx, main = c2ea[i,]$concepticon)
dev.off()
}
fs = list.files("../results/EA_distances/","*_long.csv")
longlong = data.frame()
for(f in fs){
fx = read.csv(paste0("../results/EA_distances/",f))
namex = gsub("_long.csv","",f)
namex = gsub("_"," ",namex)
fx$semantic_domain = namex
longlong = rbind(longlong,fx)
}
write.csv(longlong, "../results/EA_distances/All_Domains.csv", row.names = F)
c2ea.for.printing = c2ea.for.printing[order(c2ea.for.printing$Concepticon.Domain, c2ea.for.printing$EA.IndexCategory, c2ea.for.printing$EA.VarID),]
write.csv(c2ea.for.printing,
"../data/Concepticon_to_EA_FullVariableList.csv",row.names = F)
####
# Kinship full (all categorical variables)
# eadx.full = read.csv(filename, stringsAsFactors = F)
# eadx.full = as.data.frame(eadx.full)
# kinship.vars = eav$VarID[grepl("Kinship",eav$IndexCategory)]
# eadx.kinship = eadx.full[,names(eadx.full) %in% paste0("X",kinship.vars)]
#
# eadx.kinship =as.data.frame(apply(eadx.kinship,2,as.factor))
# distx = daisy(eadx.kinship,
#               metric = "gower")
# distx.m = as.matrix(distx)
# rownames(distx.m) = eadx.full$soc_id
# colnames(distx.m)= eadx.full$soc_id
#
# write.csv(distx.m, "../results/EA_distances/Kinship_AllSocieties.csv")
# Get historical distances between langauges from phylogentic trees, obtained from D-Place
# Then match up the taxa names to FAIR langauge names
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/analysis/")
library(ape)
library(caper)
library(phylobase)
# fair language data
f = read.csv("../data/FAIR_langauges_glotto_xdid.csv", stringsAsFactors = F)
# Indo-European
t = read.nexus("../data/trees/bouckaert_et_al2012-d-place_2.NEXUS")
treenames = read.csv("../data/trees/taxa.csv", stringsAsFactors = F)
# These are not necessarily the right glottocode, but they do link the right data
treenames[treenames$taxon=="Albanian_G",]$glottocode = "gheg1238"
treenames[treenames$taxon=="Greek_Mod",]$glottocode = "mode1248"
# convert tip labels to glotto codes
t$tip.label = treenames[match(t$tip.label,treenames$taxon),]$glottocode
f[f$xd.id %in% t$tip.label,]
keepTip = f[f$glotto %in% t$tip.label,]$glotto
t = drop.tip(t,t$tip.label[!t$tip.label %in% keepTip])
t$tip.label = f[match(t$tip.label,f$glotto),]$Language2
write.tree(t, "../data/trees/FAIR_tree_IndoEuropean.nwk")
t.dist = cophenetic(t)
write.csv(t.dist, file="../data/trees/IndoEuropean_historical_distances.csv", row.names = T)
# # Afro-Asiatic
# t2 = read.nexus("../data/trees/Grollemund_summary.trees")
# treenames2 = read.csv("../data/trees/Grollemund_taxa.csv", stringsAsFactors = F)
#
# t2$tip.label = treenames2[match(t2$tip.label,treenames2$taxon),]$glottocode
# keepTip2 = f[f$glotto %in% t2$tip.label,]$glotto
# t2 = drop.tip(t2,t2$tip.label[!t2$tip.label %in% keepTip2])
#
# t2$tip.label = f[match(t2$tip.label,f$glotto),]$Language2
#
# write.tree(t2, "../data/trees/FAIR_tree_AfroAsiatic.nwk")
# t2.dist = cophenetic(t2)
# write.csv(t2.dist, file="../data/trees/AfroAsiatic_historical_distances.csv", row.names = T)
#
# # Austronesian
# t3 = read.nexus("../data/trees/Gray_summary.trees")
# treenames3 = read.csv("../data/trees/Gray_taxa.csv", stringsAsFactors = F)
#
# t3$tip.label = treenames3[match(t3$tip.label,treenames3$taxon),]$glottocode
# keepTip3 = f[f$glotto %in% t3$tip.label,]$glotto
# t3 = drop.tip(t3,t3$tip.label[!t3$tip.label %in% keepTip3])
#
# t3$tip.label = f[match(t3$tip.label,f$glotto),]$Language2
#
# write.tree(t3, "../data/trees/FAIR_tree_Austronesian.nwk")
# t3.dist = cophenetic(t3)
# write.csv(t3.dist, file="../data/trees/Austronesian_historical_distances.csv", row.names = T)
geoDist = read.csv("../data/GeographicDistances.csv",stringsAsFactors = F)
g = read.csv("../data/glottolog-languoid.csv/languoid.csv",stringsAsFactors = F,encoding = "UTF-8",fileEncoding = "UTF-8")
l$lat = g[match(l$glotto,g$id),]$latitude
l$long = g[match(l$glotto,g$id),]$longitude
library(fields)
geoDist = fields::rdist.earth(l[,c("long","lat")],miles=F)
rownames(geoDist) = l$Language
colnames(geoDist) = l$Language
names(geoDist)
l$in.final.analysis
l$in.final.analysis==T
l$in.final.analysis || T
l$in.final.analysis | T
geoDist = geoDist[l$in.final.analysis,l$in.final.analysis]
dim(geoDist)
write.csv(geoDist,file="../data/GeographicDistances.csv",row.names = F,fileEncoding = "UTF-8")
rownames(geoDist)
g = read.csv("../data/glottolog-languoid.csv/languoid.csv",stringsAsFactors = F,encoding = "UTF-8",fileEncoding = "UTF-8")
l$lat = g[match(l$glotto,g$id),]$latitude
l$long = g[match(l$glotto,g$id),]$longitude
library(fields)
geoDist = fields::rdist.earth(l[,c("long","lat")],miles=F)
rownames(geoDist) = l$Language
colnames(geoDist) = l$Language
geoDist = geoDist[l$in.final.analysis,l$in.final.analysis]
write.csv(geoDist,file="../data/GeographicDistances.csv",row.names = F,fileEncoding = "UTF-8")
rownames(geoDist)
l = read.csv("../data/FAIR_langauges_glotto_xdid.csv", stringsAsFactors = F)
g = read.csv("../data/glottolog-languoid.csv/languoid.csv",stringsAsFactors = F,encoding = "UTF-8",fileEncoding = "UTF-8")
l$lat = g[match(l$glotto,g$id),]$latitude
l$long = g[match(l$glotto,g$id),]$longitude
library(fields)
geoDist = fields::rdist.earth(l[,c("long","lat")],miles=F)
rownames(geoDist) = l$Language
colnames(geoDist) = l$Language
geoDist = geoDist[l$in.final.analysis,l$in.final.analysis]
write.csv(geoDist,file="../data/GeographicDistances.csv",row.names = F,fileEncoding = "UTF-8")
geoDist = read.csv("../data/GeographicDistances.csv",stringsAsFactors = F)
geoDist.m = as.matrix(geoDist)
rownames(geoDist.m) = colnames(geoDist.m)
image(geoDist.m)
sum(is.na(geoDist.m))
in.analysis = intersect(rownames(ling.m),rownames(cult.m))
in.analysis = intersect(in.analysis, rownames(hist.m))
cult.m2 = cult.m[in.analysis,in.analysis]
ling.m2 = ling.m[in.analysis,in.analysis]
hist.m2 = hist.m[in.analysis,in.analysis]
geo.m2 = geoDist.m[in.analysis,in.analysis]
dim(geo.m2)
plot(as.dist(cult.m2),as.dist(ling.m2),
xlab="Cultural similarity",
ylab="Linguistic similarity")
plot(as.dist(cult.m2),as.dist(hist.m2),
xlab="Cultural similarity",
ylab="Historical distance")
plot(as.dist(ling.m2),as.dist(hist.m2),
xlab="Linguistic similarity",
ylab="Historical distance")
ecodist::mantel(as.dist(cult.m2) ~
as.dist(geo.m2),
nperm = 100000)
distms = list("Cultrual"= cult.m2,
"Linguistic" = ling.m2,
"Historical" = hist.m2,
"Geographic" = geo.m2)
names(distms)
distms = list("Cultrual"= cult.m2,
"Linguistic" = ling.m2,
"Historical" = hist.m2,
"Geographic" = geo.m2)
for(i in 1:3){
for(j in (i+1):4){
print(paste("Correlation between",
names(distms)[i],"and",names(distms)[j]))
ecodist::mantel(as.dist(distms[[i]]) ~
as.dist(distms[[j]]),
nperm = 100000)
}
}
print(ecodist::mantel(as.dist(distms[[i]]) ~
as.dist(distms[[j]]),
nperm = 100000))
distms = list("Cultrual"= cult.m2,
"Linguistic" = ling.m2,
"Historical" = hist.m2,
"Geographic" = geo.m2)
for(i in 1:3){
for(j in (i+1):4){
print(paste("Correlation between",
names(distms)[i],"and",names(distms)[j]))
print(ecodist::mantel(as.dist(distms[[i]]) ~
as.dist(distms[[j]]),
nperm = 100000))
}
}
ecodist::mantel(as.dist(ling.m2)~
as.dist(cult.m2) +
as.dist(hist.m2) +
as.dist(geo.m2),
nperm = 100000)
ecodist::mantel(as.dist(ling.m2)~
as.dist(cult.m2) +
as.dist(hist.m2),
nperm = 100000)
geoDist
geoDist.m = log(geoDist.m)
geoDist.m
geoDist.m[is.infinite(geoDist.m)] = 0
geoDist.m
ecodist::mantel(as.dist(ling.m2)~
as.dist(cult.m2) +
as.dist(hist.m2) +
as.dist(geo.m2),
nperm = 100000)
geoDist = read.csv("../data/GeographicDistances.csv",stringsAsFactors = F)
geoDist.m = as.matrix(geoDist)
# Convert to log distance
geoDist.m = log(geoDist.m)
geoDist.m[is.infinite(geoDist.m)] = 0
rownames(geoDist.m) = colnames(geoDist.m)
```
Match the distance matrices
```{r}
in.analysis = intersect(rownames(ling.m),rownames(cult.m))
in.analysis = intersect(in.analysis, rownames(hist.m))
cult.m2 = cult.m[in.analysis,in.analysis]
ling.m2 = ling.m[in.analysis,in.analysis]
hist.m2 = hist.m[in.analysis,in.analysis]
geo.m2 = geoDist.m[in.analysis,in.analysis]
ecodist::mantel(as.dist(ling.m2)~
as.dist(cult.m2) +
as.dist(hist.m2) +
as.dist(geo.m2),
nperm = 100000)
hist(geo.m2)
geoDist = read.csv("../data/GeographicDistances.csv",stringsAsFactors = F)
geoDist.m = as.matrix(geoDist)
hist(geoDist.m)
min(geoDist.m[geoDist.m>0])
geoDist.m[which(geoDist.m>0 & geoDist.m<0.001)]
geoDist.m[which(geoDist.m>0 & geoDist.m<0.001),which(geoDist.m>0 & geoDist.m<0.001)]
which(geoDist.m>0 & geoDist.m<0.001)
hist(geoDist.m[geoDist.m<1,])
hist(geoDist.m[geoDist.m<1])
geoDist = read.csv("../data/GeographicDistances.csv",stringsAsFactors = F)
geoDist.m = as.matrix(geoDist)
apply(geoDist.m,1,function(X){sum(X>0 & X<1)>0})
geoDist.m[apply(geoDist.m,1,function(X){sum(X>0 & X<1)>0}),]
diag(geoDist) =0
image(geoDist)
g = read.csv("../data/glottolog-languoid.csv/languoid.csv",stringsAsFactors = F,encoding = "UTF-8",fileEncoding = "UTF-8")
l$lat = g[match(l$glotto,g$id),]$latitude
l$long = g[match(l$glotto,g$id),]$longitude
library(fields)
geoDist = fields::rdist.earth(l[,c("long","lat")],miles=F)
rownames(geoDist) = l$Language
colnames(geoDist) = l$Language
diag(geoDist) =0
geoDist = geoDist[l$in.final.analysis,l$in.final.analysis]
write.csv(geoDist,file="../data/GeographicDistances.csv",row.names = F,fileEncoding = "UTF-8")
image(geoDist)
hist(geoDist[geoDist<1])
min(geoDist)
hist(geoDist[geoDist<1.5])
table(geoDist[geoDist<1.5])
g = read.csv("../data/glottolog-languoid.csv/languoid.csv",stringsAsFactors = F,encoding = "UTF-8",fileEncoding = "UTF-8")
l$lat = g[match(l$glotto,g$id),]$latitude
l$long = g[match(l$glotto,g$id),]$longitude
library(fields)
geoDist = fields::rdist.earth(l[,c("long","lat")],miles=F)
rownames(geoDist) = l$Language
colnames(geoDist) = l$Language
diag(geoDist) =0
geoDist = geoDist[l$in.final.analysis,l$in.final.analysis]
write.csv(geoDist,file="../data/GeographicDistances.csv",row.names = F,fileEncoding = "UTF-8")
geoDist = read.csv("../data/GeographicDistances.csv",stringsAsFactors = F)
geoDist.m = as.matrix(geoDist)
# Convert to log distance
geoDist.m = log(geoDist.m)
geoDist.m[is.infinite(geoDist.m)] = 0
rownames(geoDist.m) = colnames(geoDist.m)
in.analysis = intersect(rownames(ling.m),rownames(cult.m))
in.analysis = intersect(in.analysis, rownames(hist.m))
cult.m2 = cult.m[in.analysis,in.analysis]
ling.m2 = ling.m[in.analysis,in.analysis]
hist.m2 = hist.m[in.analysis,in.analysis]
geo.m2 = geoDist.m[in.analysis,in.analysis]
ecodist::mantel(as.dist(ling.m2)~
as.dist(cult.m2) +
as.dist(hist.m2) +
as.dist(geo.m2),
nperm = 100000)
distms = list("Cultrual"= cult.m2,
"Linguistic" = ling.m2,
"Historical" = hist.m2,
"Geographic" = geo.m2)
for(i in 1:3){
for(j in (i+1):4){
print(paste("Correlation between",
names(distms)[i],"and",names(distms)[j]))
print(ecodist::mantel(as.dist(distms[[i]]) ~
as.dist(distms[[j]]),
nperm = 100000))
}
}
hist = read.csv("../data/trees/IndoEuropean_historical_distances.csv", stringsAsFactors = F)
in.analysis
hist = read.csv("../data/trees/IndoEuropean_historical_distances.csv", stringsAsFactors = F)
hist = hist[!duplicated(hist[,1]),!duplicated(hist[,1])]
rownames(hist) = hist[,1]
hist = hist[,2:ncol(hist)]
hist.m = as.matrix(hist)
colnames(hist.m) = rownames(hist.m)
hist.m = hist.m/max(hist.m)
```
Read the cultural distance as a matrix:
```{r}
cult.m = read.csv("../results/EA_distances/CulturalDistances.csv", stringsAsFactors = F)
rownames(cult.m) = cult.m[,1]
cult.m = cult.m[,2:ncol(cult.m)]
```
Flip the cultural distance into a cultural similarity measure:
```{r}
cult.m = 1-cult.m
```
Convert the linguistic similarities to a matrix.  This uses `igraph` to make an undirected graph from the long format with `local_alignment` as the edge weights, then output a matrix of adjacencies.
```{r}
grph <- graph.data.frame(ling[,c("l1",'l2','local_alignment')], directed=FALSE)
# add value as a weight attribute
ling.m = get.adjacency(grph, attr="local_alignment", sparse=FALSE)
rownames(ling.m) = l[match(rownames(ling.m),l$iso2),]$Language2
colnames(ling.m) = l[match(colnames(ling.m),l$iso2),]$Language2
```
Load the geographic distances:
```{r}
geoDist = read.csv("../data/GeographicDistances.csv",stringsAsFactors = F)
geoDist.m = as.matrix(geoDist)
# Convert to log distance
geoDist.m = log(geoDist.m)
geoDist.m[is.infinite(geoDist.m)] = 0
rownames(geoDist.m) = colnames(geoDist.m)
```
Match the distance matrices
```{r}
in.analysis = intersect(rownames(ling.m),rownames(cult.m))
in.analysis = intersect(in.analysis, rownames(hist.m))
cult.m2 = cult.m[in.analysis,in.analysis]
ling.m2 = ling.m[in.analysis,in.analysis]
hist.m2 = hist.m[in.analysis,in.analysis]
geo.m2 = geoDist.m[in.analysis,in.analysis]
length(in.analysis)
hist = read.csv("../data/trees/IndoEuropean_historical_distances.csv", stringsAsFactors = F)
# Get historical distances between langauges from phylogentic trees, obtained from D-Place
# Then match up the taxa names to FAIR langauge names
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/analysis/")
library(ape)
library(caper)
library(phylobase)
# fair language data
f = read.csv("../data/FAIR_langauges_glotto_xdid.csv", stringsAsFactors = F)
# Indo-European
t = read.nexus("../data/trees/bouckaert_et_al2012-d-place_2.NEXUS")
treenames = read.csv("../data/trees/taxa.csv", stringsAsFactors = F)
# These are not necessarily the right glottocode, but they do link the right data
treenames[treenames$taxon=="Albanian_G",]$glottocode = "gheg1238"
treenames[treenames$taxon=="Greek_Mod",]$glottocode = "mode1248"
# convert tip labels to glotto codes
t$tip.label = treenames[match(t$tip.label,treenames$taxon),]$glottocode
f[f$xd.id %in% t$tip.label,]
keepTip = f[f$glotto %in% t$tip.label,]$glotto
t = drop.tip(t,t$tip.label[!t$tip.label %in% keepTip])
t$tip.label = f[match(t$tip.label,f$glotto),]$Language2
write.tree(t, "../data/trees/FAIR_tree_IndoEuropean.nwk",enco)
t.dist = cophenetic(t)
write.csv(t.dist, file="../data/trees/IndoEuropean_historical_distances.csv", row.names = T)
# # Afro-Asiatic
# t2 = read.nexus("../data/trees/Grollemund_summary.trees")
# treenames2 = read.csv("../data/trees/Grollemund_taxa.csv", stringsAsFactors = F)
#
# t2$tip.label = treenames2[match(t2$tip.label,treenames2$taxon),]$glottocode
# keepTip2 = f[f$glotto %in% t2$tip.label,]$glotto
# t2 = drop.tip(t2,t2$tip.label[!t2$tip.label %in% keepTip2])
#
# t2$tip.label = f[match(t2$tip.label,f$glotto),]$Language2
#
# write.tree(t2, "../data/trees/FAIR_tree_AfroAsiatic.nwk")
# t2.dist = cophenetic(t2)
# write.csv(t2.dist, file="../data/trees/AfroAsiatic_historical_distances.csv", row.names = T)
#
# # Austronesian
# t3 = read.nexus("../data/trees/Gray_summary.trees")
# treenames3 = read.csv("../data/trees/Gray_taxa.csv", stringsAsFactors = F)
#
# t3$tip.label = treenames3[match(t3$tip.label,treenames3$taxon),]$glottocode
# keepTip3 = f[f$glotto %in% t3$tip.label,]$glotto
# t3 = drop.tip(t3,t3$tip.label[!t3$tip.label %in% keepTip3])
#
# t3$tip.label = f[match(t3$tip.label,f$glotto),]$Language2
#
# write.tree(t3, "../data/trees/FAIR_tree_Austronesian.nwk")
# t3.dist = cophenetic(t3)
# write.csv(t3.dist, file="../data/trees/Austronesian_historical_distances.csv", row.names = T)
l = read.csv("../data/FAIR_langauges_glotto_xdid.csv", stringsAsFactors = F)
l = read.csv("../data/FAIR_langauges_glotto_xdid.csv", stringsAsFactors = F,eencoding = "UTF-8",fileEncoding = "UTF-8")
l = read.csv("../data/FAIR_langauges_glotto_xdid.csv", stringsAsFactors = F,encoding = "UTF-8",fileEncoding = "UTF-8")
g = read.csv("../data/glottolog-languoid.csv/languoid.csv",stringsAsFactors = F,encoding = "UTF-8",fileEncoding = "UTF-8")
l$lat = g[match(l$glotto,g$id),]$latitude
l$long = g[match(l$glotto,g$id),]$longitude
library(fields)
geoDist = fields::rdist.earth(l[,c("long","lat")],miles=F)
rownames(geoDist) = l$Language
colnames(geoDist) = l$Language
diag(geoDist) =0
geoDist = geoDist[l$in.final.analysis,l$in.final.analysis]
write.csv(geoDist,file="../data/GeographicDistances.csv",row.names = F,fileEncoding = "UTF-8")

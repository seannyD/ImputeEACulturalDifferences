s(cat,concscale,bs='re'),
data = dataloan2,
family='binomial')
plotGAMSignificantSlopes(mMeanLenControl,"SLMWL","SLMWL")
mMeanLenControl = bam(bor15.cat ~
s(phonlengthscale) +
s(SLMWL,k=3) +
s(AoAscale) +
s(subtlexzipfscale) +
s(concscale) +
s(cat,bs='re')+
s(cat,phonlengthscale,bs='re')+
s(cat,AoAscale,bs='re')+
s(cat,subtlexzipfscale,bs='re')+
s(cat,concscale,bs='re'),
data = dataloan2,
family='binomial')
plotGAMSignificantSlopes(mMeanLenControl,"SLMWL","SLMWL")
plotGAMSignificantSlopes(mMeanLenControl,"phonlengthscale",'phonlengthscale')
summary(mMeanLenControl)
plot(mMeanLenControl,select=10)
plotGAMSignificantSlopes(mMeanLenControl,
"phonlengthscale",'phonlengthscale')
plotGAMSignificantSlopes(mMeanLenControl,
"SLMWL",'SLMWL')
"phonlengthscale",'phonlengthscale')
plotGAMSignificantSlopes(mMeanLenControl,
"phonlengthscale",'phonlengthscale')
mLenFreqControl = update(m0, ~.+s(SWF,k=3))
summary(mLenFreqControl)
plot(mLenFreqControl,select=10)
m0 = lmer(bor15.cat ~
phonlengthscale + (1+phonlengthscale | cat),
data = dataloan2,
family='binomial')
library(lme4)
m0 = glmer(bor15.cat ~
phonlengthscale + (1+phonlengthscale | cat),
data = dataloan2,
family='binomial')
summary(m0)
mx.labels = c("Length","AoA","Frequency","Concreteness")
par(mfrow=c(2,2),mar=c(2,2,1,2))
for(i in 1:4){
plot(m0,select=i,main=mx.labels[i],ylim=c(-4,4))
par(new=T)
if(i>1){
i=i+1
}
plot(mMeanLenControl,select=i,ylim=c(-4,4), col=2,ylab="")
legend(-1,-1.5,legend = c("Original","With length control"),col=1:2,lty=1, bty='n')
}
par(mfrow=c(1,1))
mx.labels = c("Length","AoA","Frequency","Concreteness")
par(mfrow=c(2,2),mar=c(2,2,1,2))
for(i in 1:4){
plot(m0,select=i,main=mx.labels[i],ylim=c(-4,4))
par(new=T)
if(i>1){
i=i+1
}
plot(mMeanLenControl,select=i,ylim=c(-4,4), col=2,ylab="")
legend(-1,-1.5,legend = c("Original","With length control"),col=1:2,lty=1, bty='n')
}
par(mfrow=c(1,1))
mx.labels = c("Length","AoA","Frequency","Concreteness")
par(mfrow=c(2,2),mar=c(2,2,1,2))
for(i in 1:4){
plot(m0,select=i,main=mx.labels[i],ylim=c(-4,4))
if(i>1){
i=i+1
}
par(new=T)
plot(mMeanLenControl,select=i,ylim=c(-4,4), col=2,ylab="")
legend(-1,-1.5,legend = c("Original","With length control"),col=1:2,lty=1, bty='n')
}
par(mfrow=c(1,1))
mx.labels = c("Length","AoA","Frequency","Concreteness")
par(mfrow=c(2,2),mar=c(2,2,1,2))
for(i in 1:4){
i2 = i
if(i2>1){
i2=i2+1
}
plot(m0,select=i,main=mx.labels[i],ylim=c(-4,4))
par(new=T)
plot(mMeanLenControl,select=i2,ylim=c(-4,4), col=2,ylab="")
legend(-1,-1.5,legend = c("Original","With length control"),col=1:2,lty=1, bty='n')
}
par(mfrow=c(1,1))
i = 1
i2 = i
if(i2>1){
i2=i2+1
}
plot(m0,select=i,main=mx.labels[i],ylim=c(-4,4))
par(new=T)
plot(mMeanLenControl,select=i2,ylim=c(-4,4), col=2,ylab="")
m0 = bam(bor15.cat ~
s(phonlengthscale) +
s(AoAscale) +
s(subtlexzipfscale) +
s(concscale) +
s(cat,bs='re')+
s(cat,phonlengthscale,bs='re')+
s(cat,AoAscale,bs='re')+
s(cat,subtlexzipfscale,bs='re')+
s(cat,concscale,bs='re'),
data = dataloan2,
family='binomial')
mMeanLenControl = bam(bor15.cat ~
s(phonlengthscale) +
s(AoAscale) +
s(subtlexzipfscale) +
s(concscale) +
s(SLMWL,k=3) +
s(cat,bs='re')+
s(cat,phonlengthscale,bs='re')+
s(cat,AoAscale,bs='re')+
s(cat,subtlexzipfscale,bs='re')+
s(cat,concscale,bs='re'),
data = dataloan2,
family='binomial')
summary(mMeanLenControl)
mx.labels = c("Length","AoA","Frequency","Concreteness")
par(mfrow=c(2,2),mar=c(2,2,1,2))
for(i in 1:4){
plot(m0,select=i,main=mx.labels[i],ylim=c(-4,4))
par(new=T)
plot(mMeanLenControl,select=i,ylim=c(-4,4), col=2,ylab="")
legend(-1,-1.5,legend = c("Original","With length control"),col=1:2,lty=1, bty='n')
}
par(mfrow=c(1,1))
coef(m0)
table(dataloan2$cat)
---
title: "Cognitive influences in language evolution: Study 4"
output:
pdf_document:
toc: true
---
```{r echo=F,eval=F}
try(setwd("~/Box Sync/papersonthego/LOAN_WORDS/VERYNEWANALYSES/"))
try(setwd("~/Documents/MPI/MonaghanAoA/Stats 2/analysis/"))
```
# Load libraries
```{r message=F,warning=F}
library(mgcv)
library(sjPlot)
library(lattice)
library(ggplot2)
library(dplyr)
library(party)
library(lmtest)
library(gridExtra)
library(scales)
library(itsadug)
library(ggfortify)
library(factoextra)
library(gridExtra)
library(reshape2)
library(binom)
```
Extra helper functions:
```{r}
source("GAM_derivaties.R")
logit2per = function(X){
return(exp(X)/(1+exp(X)))
}
rescaleGam = function(px, n, xvar, xlab="",breaks=NULL,xlim=NULL){
y = logit2per(px[[n]]$fit)
x = px[[n]]$x *attr(xvar,"scaled:scale") + attr(xvar,"scaled:center")
se.upper = logit2per(px[[n]]$fit+px[[n]]$se)
se.lower = logit2per(px[[n]]$fit-px[[n]]$se)
dx = data.frame(x=x,y=y,ci.upper=se.upper,ci.lower=se.lower)
plen = ggplot(dx, aes(x=x,y=y))+
geom_ribbon(aes(ymin=ci.lower,ymax=ci.upper), alpha=0.3)+
geom_line(size=1) +
xlab(xlab)+
ylab("Probability of borrowing")
if(!is.null(breaks)){
plen = plen + scale_x_continuous(breaks = breaks)
}
if(!is.null(xlim)){
plen = plen + coord_cartesian(ylim = c(0,1),xlim=xlim)
} else{
plen = plen + coord_cartesian(ylim = c(0,1))
}
return(plen)
}
```
# Load data
```{r}
dataloan <- read.csv("../data/loanword12.csv",stringsAsFactors = F)
dataloan$bor15 <- ifelse(dataloan$borrowing==1,1, ifelse(dataloan$borrowing==5,0,NA))
dataloan$bor15.cat <- factor(dataloan$bor15)
dataloan$subtlexzipf = as.numeric(dataloan$subtlexzipf)
dataloan$AoA = as.numeric(dataloan$AoA)
dataloan$conc = as.numeric(dataloan$conc)
dataloan$old.english.length = as.numeric(dataloan$old.english.length)
aoaSD = sd(dataloan$AoA,na.rm = T)
aoaMean = mean(dataloan$AoA/aoaSD,na.rm=T)
dataloan$cat = factor(dataloan$cat)
dataloan$effect = factor(dataloan$effect)
dataloan2 = dataloan[complete.cases(dataloan[,
c("phonlength","AoA",
"subtlexzipf", "cat",
'conc','bor15')]),]
names(dataloan2)
table(dataloan2$effect)
x = dataloan2[dataloan2$effect=="Insertion",]
x$word[order(x$conc)]
hist(x$conc)
hist(dataloan2$conc)
quantile(dataloan2$conc,0.95)
quantile(dataloan2$conc,0.9)
quantile(dataloan2$conc,0.75)
x[x$conc>4.8]
x[x$conc>4.8,]$word
x[x$conc>=4.97]
x[x$conc>=4.97,]$word
x[x$conc>=4.96,]$word
x$conc
x[!is.na(x$conc) & x$conc>=4.96,]$word
x[!is.na(x$conc) & x$conc>=4.97,]$word
y = dataloan2[dataloan2$effect%in% c("Replacement","Coexistence"),]
y[!is.na(y$conc) & y$conc>=4.97,]$word
---
title: "Cultural distances: Wikipedia data"
output:
pdf_document:
toc: true
---
```{r echo=F, eval=F}
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/analysis/")
```
# Introduction
We compare cultural distances between socieites with linguistic similarities between societies, controlling for shared history in two ways.
The first test uses mixed effects modelling.  The pairing of the language family of each language (according to Glottolog) is used as a random effect.  That means that the model can capture the likelihood that two languages from the Indo-European language family will be more similar to each other than two languages from different language families.  The same is done with geographic area according to Autotyp.
The second test controls for history using distances from a phylogenetic tree.  The tree comes from Bouckaert et al. (2012).  Patristic distances between languages are used as a measure of historical distance between societies in a Mantel test.  Note that the Mantel test assumes a strict distance metric, which is not necessarily the case with this data, but there are few other ways to deal with continuous pairwise distances.
# Load libraries
```{r warning=F, message=F}
library(ape)
library(ecodist)
library(lme4)
library(sjPlot)
library(ggplot2)
library(igraph)
library(lattice)
```
Parameters (using data from Northuralex and Wikipedia, k=100, unfiltered):
```{r}
datasetName = "wikipedia-main"
lingDistancesFile = "../data/FAIR/nel-wiki-k100-alignments-by-language-pair.csv"
lingDistancesFileNK = "../data/FAIR/nel-wiki-k100-alignments-by-language-pair-without-kinship.csv"
lingDistancesByDomainFile = "../results/EA_distances/nel-wiki-k100_with_ling.csv"
# (generated by ../processing/combineCultAndLingDistances.R)
```
\newpage
# All domains
## Load data
Read the cultural distances:
```{r}
cult = read.csv("../results/EA_distances/CulturalDistances_Long.csv", stringsAsFactors = F)
names(cult) = c("l1","l2","cult.dist")
cultLangs = unique(c(cult$Var1,cult$Var2))
```
Add language family:
```{r}
l = read.csv("../data/FAIR_langauges_glotto_xdid.csv", stringsAsFactors = F)
g = read.csv("../data/glottolog-languoid.csv/languoid.csv", stringsAsFactors = F)
l$family = g[match(l$glotto,g$id),]$family_pk
l$family = g[match(l$family,g$pk),]$name
```
Read the semantic distances
```{r}
ling = read.csv(lingDistancesFile, stringsAsFactors = F)
```
There are very few possible comparisons for Slovenian and Northern Sami, so we'll remove these:
```{r}
ling = ling[!(ling$l1=="se" || ling$l2 == "se"),]
ling = ling[!(ling$l1=="sl" || ling$l2 == "sl"),]
```
Combine the lingusitic and cultural distances. Note that we flip the cultural measure from a distance measure to a similarity measure.
```{r}
cult$l1.iso2 = l[match(cult$l1,l$Language2),]$iso2
cult$l2.iso2 = l[match(cult$l2,l$Language2),]$iso2
fairisos = unique(c(ling$l1,ling$l2))
cultisos = unique(c(cult$l1.iso2, cult$l2.iso2))
cult = cult[(cult$l1.iso2 %in% fairisos) & (cult$l2.iso2 %in% fairisos),]
ling = ling[(ling$l1 %in% cultisos) & (ling$l2 %in% cultisos),]
matches = sapply(1:nrow(ling), function(i){
which(cult$l1.iso2==ling$l1[i] & cult$l2.iso2==ling$l2[i])
})
ling$cult.dist = cult[matches,]$cult.dist
# Flip
ling$cult.dist = 1 - ling$cult.dist
# Scale
ling$cult.dist.center = scale(ling$cult.dist)
cdc.s = attr(ling$cult.dist.center,"scaled:scale")
cdc.c = attr(ling$cult.dist.center,"scaled:center")
ling$cult.dist.center = as.numeric(ling$cult.dist.center)
ling$comparison_count.center =
scale(ling$comparison_count)
ling$family1 = l[match(ling$l1, l$iso2),]$family
ling$family2 = l[match(ling$l2, l$iso2),]$family
ling$area1 = l[match(ling$l1, l$iso2),]$autotyp.area
ling$area2 = l[match(ling$l2, l$iso2),]$autotyp.area
fgroup = cbind(ling$family1,ling$family2)
fgroup = apply(fgroup,1,sort)
ling$family.group = apply(fgroup,2,paste,collapse=":")
agroup = cbind(ling$area1,ling$area2)
agroup = apply(agroup,1,sort)
ling$area.group = apply(agroup,2,paste,collapse=":")
ling$rho.center = scale(ling$local_alignment)
```
Each observation is now assocaited with a language family pair:
```{r}
head(ling[,c("l1","l2","local_alignment",'family.group')])
```
And the same is true for area:
```{r}
tail(ling[,c("l1","l2","local_alignment",'area.group')])
```
Number of observations:
```{r}
# Number of datapoints:
nrow(ling)
# Number of unique languages:
length(unique(unlist(ling[,c("l1","l2")])))
# Number of unique langauge families:
uniqueFamilies = unique(unlist(ling[,c("family1","family2")]))
length(uniqueFamilies)
# Number of unique areas:
uniqueAreas = unique(unlist(ling[,c("area1","area2")]))
length(uniqueAreas)
```
Cross-over between language famlies and areas:
```{r}
tx = data.frame(lang= c(ling$l1,ling$l2),
fam = c(ling$family1,ling$family2),
area= c(ling$area1,ling$area2))
tx = tx[!duplicated(tx),]
table(tx$fam,tx$area)
```
\newpage
## LMER models
Mixed effects model, predicting Linguistic similaritys from cultural similarity, with random intercept for family and area and random slope for cultural similarity for family and area.
We start with a null model with random intercepts for family and area, and random slopes for cultural similarity by both. We add a fixed effect of the number of comparisons made for each datapoint (number of concepts that were available to compare). Then we add a fixed effect of cultural similarity
```{r}
m0 = lmer(
rho.center ~ 1 +
(1 + cult.dist.center | family.group) +
(1 + cult.dist.center | area.group),
data = ling
)
m0.5 = lmer(
rho.center ~ 1 +
comparison_count.center +
(1 + cult.dist.center | family.group) +
(1 + cult.dist.center | area.group),
data = ling
)
m1 = lmer(
rho.center ~ 1 +
comparison_count.center +
cult.dist.center +
(1 + cult.dist.center | family.group) +
(1 + cult.dist.center | area.group),
data = ling
)
anova(m0,m0.5,m1)
```
Cultural similarity is significantly correlated with Linguistic similarity.  Here are the model estimates:
```{r}
summary(m1)
an1 = anova(m0,m0.5,m1)
an1
coef(m1)
fixef(m)
fixef(m1)
fixef(m1)[2]
fixef(m1)[3]
an1
an1$`Chi Df`
an1$`Chi Df`[2]
an1$Chisq[2]
an1$Chisq
an1$Chisq[3]
an1$`Pr(>Chisq)`[3]
sprintf("$\beta$= %s, $\chi^2$(%s)= %s, $p$=",
fixef(m1)[3],
an1$`Chi Df`[3],
an1$Chisq[3],
an1$`Pr(>Chisq)`[3])
sprintf("$\\beta$= %s, $\\chi^2$(%s)= %s, $p$=",
fixef(m1)[3],
an1$`Chi Df`[3],
an1$Chisq[3],
an1$`Pr(>Chisq)`[3])
cat(sprintf("$\\beta$= %s, $\\chi^2$(%s)= %s, $p$=",
fixef(m1)[3],
an1$`Chi Df`[3],
an1$Chisq[3],
an1$`Pr(>Chisq)`[3])
)
signif(fixef(m1)[3],2)
sprintf("$\\beta$= %s, $\\chi^2$(%s)= %s, $p$=%s",
signif(fixef(m1)[3],2),
an1$`Chi Df`[3],
signif(an1$Chisq[3],2),
an1$`Pr(>Chisq)`[3])
signif(an1$`Pr(>Chisq)`[3]),1)
sprintf("$\\beta$= %s, $\\chi^2$(%s)= %s, $p$=%s",
signif(fixef(m1)[3],2),
an1$`Chi Df`[3],
signif(an1$Chisq[3],2),
signif(an1$`Pr(>Chisq)`[3],1))
?signif
signif(an1$Chisq[3],2,scientific=F)
format(signif(an1$Chisq[3],2),scientific=F)
format(signif(an1$`Pr(>Chisq)`[3],1),scientific=F)
sprintf("$\\beta$= %s, $\\chi^2$(%s)= %s, $p$=%s",
signif(fixef(m1)[3],2),
an1$`Chi Df`[3],
signif(an1$Chisq[3],2),
format(signif(an1$`Pr(>Chisq)`[3],1),scientific=F))
cat(stat0,file="../results/stats/tex/MEM_CulturalVsLinguistic.tex")
stat0 = sprintf("$\\beta$= %s, $\\chi^2$(%s)= %s, $p$=%s",
signif(fixef(m1)[3],2),
an1$`Chi Df`[3],
signif(an1$Chisq[3],2),
format(signif(an1$`Pr(>Chisq)`[3],1),scientific=F))
cat(stat0,file="../results/stats/tex/MEM_CulturalVsLinguistic.tex")
signif(an1$Chisq[3],2)
round(an1$Chisq[3],2)
stat0 = sprintf("$\\beta$= %s, $\\chi^2$(%s)= %s, $p$=%s",
signif(fixef(m1)[3],2),
an1$`Chi Df`[3],
round(an1$Chisq[3],2),
format(signif(an1$`Pr(>Chisq)`[3],1),scientific=F))
cat(stat0,file="../results/stats/tex/MEM_CulturalVsLinguistic.tex")
stat0
# Part 1: Compare each linguistic domain to the overall cultural similarity
# Part 2: Compare each linguistic domain to the cultural similarity of each original D-PLACE domain
# Part 3: Compare each linguistic domain to the phylogenetic and geographic distance
library(lme4)
library(gplots)
library(igraph)
library(ecodist)
library(RColorBrewer)
try(setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/analysis/"))
# Parameters
lingDistancesByDomainFile = "../results/EA_distances/nel-wiki-k100_with_ling.csv"
outputFolder = "../results/stats/wikipedia-main/"
# Load language details
l = read.csv("../data/FAIR_langauges_glotto_xdid.csv", stringsAsFactors = F)
g = read.csv("../data/glottolog-languoid.csv/languoid.csv", stringsAsFactors = F)
# Load cultural distances
cult = read.csv("../results/EA_distances/CulturalDistances_Long.csv", stringsAsFactors = F)
names(cult) = c("l1","l2","cult.dist")
cult$l1.iso2 = l[match(cult$l1,l$Language2),]$iso2
cult$l2.iso2 = l[match(cult$l2,l$Language2),]$iso2
cultisos = unique(c(cult$l1.iso2, cult$l2.iso2))
# Load linguistic distances
ling.dom = read.csv(
lingDistancesByDomainFile,
stringsAsFactors = F)
ling.dom = ling.dom[(ling.dom$l1 %in% cultisos) &
(ling.dom$l2 %in% cultisos),]
#There are very few possible comparisons for Slovenian and Northern Sami, so we'll remove these:
ling.dom = ling.dom[!(ling.dom$l1=="se" || ling.dom$l2 == "se"),]
ling.dom = ling.dom[!(ling.dom$l1=="sl" || ling.dom$l2 == "sl"),]
head(ling.dom)
hist(ling.dom$local_alignment)
ling.dom[which(ling.dom$local_alignment==min(ling.dom$local_alignment)),]
ling.dom[which(ling.dom$local_alignment==max(ling.dom$local_alignment)),]
ling.dom[which(ling.dom$local_alignment > 0.6,]
ling.dom[ling.dom$local_alignment > 0.6,]
geoDist = read.csv("../data/GeographicDistances.csv",stringsAsFactors = F)
names(geoDist)
l = read.csv("../data/FAIR_langauges_glotto_xdid.csv", stringsAsFactors = F)
head(l)
ling.dom[ling.dom$local_alignment > 0.6,]
ling.dom[ling.dom$local_alignment > 0.6,]$language
ling.dom[ling.dom$local_alignment > 0.6,]$Language
ling.dom$l1name = l[match(ling.dom$l1,l$iso2),]$Language
ling.dom$l1name
ling.dom$l2name = l[match(ling.dom$l2,l$iso2),]$Language
ling.dom[ling.dom$local_alignment > 0.6,]
ling.dom[ling.dom$local_alignment <-0.5,]
ling.dom[ling.dom$local_alignment <-0.3,]
ling.dom[ling.dom$local_alignment <-0.2,]
hist(ling.dom$local_alignment)
ling.dom = read.csv(
lingDistancesByDomainFile,
stringsAsFactors = F)
ling.dom = ling.dom[(ling.dom$l1 %in% cultisos) &
(ling.dom$l2 %in% cultisos),]
#There are very few possible comparisons for Slovenian and Northern Sami, so we'll remove these:
ling.dom = ling.dom[!(ling.dom$l1=="se" || ling.dom$l2 == "se"),]
ling.dom = ling.dom[!(ling.dom$l1=="sl" || ling.dom$l2 == "sl"),]
ling.dom$cult.similarity = 1-ling.dom$cult.dist
# Match overall distances to domain-specific distances
matches = sapply(1:nrow(ling.dom), function(i){
which(cult$l1.iso2==ling.dom$l1[i] & cult$l2.iso2==ling.dom$l2[i])
})
ling.dom$l1name = l[match(ling.dom$l1,l$iso2),]$Language
ling.dom$l2name = l[match(ling.dom$l2,l$iso2),]$Language
ling.dom[ling.dom$local_alignment < -0.2,]
ling.dom[ling.dom$local_alignment < -0.1,]
ling.dom[ling.dom$local_alignment > 0.6,]

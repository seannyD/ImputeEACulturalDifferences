test('‘')
test('’')
test("XX")
test("YX")
test("~")
test("asdf")
test("1111")
test("       ")
test("~~~~~")
test("abcba")
test("1")
test(" ")
test("~")
test(" ~")
test("~ ")
test("  0")
test("!@#$%^&*()ABCDEFGhijklmnop1234567890")
test(" !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~")
sQuote("‘")
sQuote("‘")
sQuote("’")
?nchar
formatC(pi)
letters
grepl("^X",s)
grepl("^X",s)+1
s
x = function(s){
#sub(".",c("X","Y")[grepl("^X",s)+1],s)
sub(".",letters[grepl("^X",s)+1],s)
}
letters[1:2]
x = function(s){
#sub(".",c("X","Y")[grepl("^X",s)+1],s)
sub(".",letters[grepl("^a",s)+1],s)
}
test("X")
test("a")
test("b")
test("ab")
test("ba")
test("'")
test("'\"")
test("\\\\")
test('"')
test('""')
test('‘')
test('’')
test("XX")
test("YX")
test("~")
test("asdf")
test("1111")
test("       ")
test("~~~~~")
test("abcba")
test("1")
test(" ")
test("~")
test(" ~")
test("~ ")
test("  0")
test("!@#$%^&*()ABCDEFGhijklmnop1234567890")
test(" !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~")
x = function(s){
#sub(".",c("X","Y")[grepl("^X",s)+1],s)
sub(".",letters[grepl("^a",s)+1],s)
}
# `letters` is constant and a slightly shorter way of doing `c("a","b")`
substring(sQuote(s),2)
substring(shQuote(s),3)
x = function(s){
#substr(shQuote(s),1,nchar(s))
substr(shQuote(s),1,nchar(s))
}
test = function(t){
t2 = x(t)
t2!=t & nchar(t)==nchar(t2)
}
# Because the string might have multiple escaped characters, we need to take a substring of the correct length
# `sQuote` is shorter, but converts "‘" to "‘‘’"
test("X")
test("a")
test("b")
test("ab")
test("ba")
test("'")
test("'\"")
test("\\\\")
test('"')
test('""')
test('‘')
test('’')
test("XX")
test("YX")
test("~")
test("asdf")
test("1111")
test("       ")
test("~~~~~")
test("abcba")
test("1")
test(" ")
test("~")
test(" ~")
test("~ ")
test("  0")
test("!@#$%^&*()ABCDEFGhijklmnop1234567890")
test(" !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~")
shQuote("'")
testStrings = c("X","a","b","ab","ba",
"'","'\"","\\\\",'"','""',
'‘','’',"XX","YX","~","asdf",
"1111","       ","~~~~~","abcba",
"1"," ","~"," ~","~ ","  0",
"!@#$%^&*()ABCDEFGhijklmnop1234567890",
" !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~")
sapply(testStrings,test)
testStrings = c("X","a","b","ab","ba",
"'","'\"","\\\\",'"','""',
'‘','’',"XX","YX","~","asdf",
"1111","       ","~~~~~","abcba",
"1"," ","~"," ~","~ ","  0",
"!@#$%^&*()ABCDEFGhijklmnop1234567890",
" !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~")
all(sapply(testStrings,test))
rm(list=ls())
x = function(s){
substr(shQuote(s),1,nchar(s))
}
test = function(t){
t2 = x(t)
t2!=t & nchar(t)==nchar(t2)
}
testStrings = c("X","a","b","ab","ba",
"'","'\"","\\\\",'"','""',
'‘','’',"XX","YX","~","asdf",
"1111","       ","~~~~~","abcba",
"1"," ","~"," ~","~ ","  0",
"!@#$%^&*()ABCDEFGhijklmnop1234567890",
" !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~")
all(sapply(testStrings,test))
testStrings = c("a","b","ab","ba","aa",
"'","'\"","\\\\",'"','""',
'‘','’',"~","asdf",
"1111","       ","~~~~~","abcba",
"1"," ","~"," ~","~ ","  0",
"!@#$%^&*()ABCDEFGhijklmnop1234567890",
" !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~")
all(sapply(testStrings,test))
T+"F"
T+1
strsplit(s)
s="abcd"
letters[strsplit(s)=="a"]
letters[strsplit(s,'')=="a"]
strsplit(s,'')
letters[strsplit(s,'')[[1]]=="a"]
letters[el(strsplit(s,''))=="a"]
?readLines
?function
??function
x = function(s)substr(shQuote(s),1,nchar(s))
test = function(t){
t2 = x(t)
t2!=t & nchar(t)==nchar(t2)
}
testStrings = c("a","b","ab","ba","aa",
"'","'\"","\\\\",'"','""',
'‘','’',"~","asdf",
"1111","       ","~~~~~","abcba",
"1"," ","~"," ~","~ ","  0",
"!@#$%^&*()ABCDEFGhijklmnop1234567890",
" !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~")
all(sapply(testStrings,test))
d = read.csv("~/Documents/Conferences/Evolang12/genderBias2018/data/E12.csv", stringsAsFactors = F)
head(d)
score = tapply(d$Score,d$Number,mean)
gender = tapply(d$FirstAuthGender,d$Number,mean)
library(ggplot2)
d2 = data.frame(
score = tapply(d$Score,d$Number,mean),
gender = tapply(d$FirstAuthGender,d$Number,mean)
)
dim(d2)
head(d2)
d$Fi
d2 = data.frame(
score = tapply(d$Score,d$Number,mean),
gender = tapply(d$FirstAuthGender,d$Number,head,n=1)
)
d = read.csv("~/Documents/Conferences/Evolang12/genderBias2018/data/E12.csv", stringsAsFactors = F)
d2 = data.frame(
score = tapply(d$Score,d$Number,mean),
gender = tapply(d$FirstAuthGender,d$Number,head,n=1)
)
library(ggplot2)
ggplot(d2,aes(x=gender,y=score)) + geom_violin()
t.test(d2$score~d2$gender)
ggplot(d2,aes(x=gender*status,y=score)) + geom_violin()
d2 = data.frame(
score = tapply(d$Score,d$Number,mean),
gender = tapply(d$FirstAuthGender,d$Number,head,n=1),
status = tapply(d$FirstAuthStatus,d$Number,head,n=1),
)
d2 = data.frame(
score = tapply(d$Score,d$Number,mean),
gender = tapply(d$FirstAuthGender,d$Number,head,n=1),
status = tapply(d$FirstAuthStatus,d$Number,head,n=1)
)
ggplot(d2,aes(x=gender*status,y=score)) + geom_violin()
ggplot(d2,aes(x=gender:status,y=score)) + geom_violin()
ggplot(d2,aes(x=status,y=score)) + geom_violin()
d2$genstatus = paste(d2$gender,d2$status)
ggplot(d2,aes(x=genstatus,y=score)) + geom_violin()
summary(lm(score~gender*status,data=d2))
summary(lm(score~gender+status,data=d2))
hist(d2$score)
d2$genstatus = paste(d2$status,d2$gender)
ggplot(d2,aes(x=genstatus,y=score)) + geom_violin()
ggplot(d2,aes(x=genstatus,y=score)) + geom_violin() + geom_boxplot()
head(d)
d = read.csv("~/Documents/Conferences/Evolang12/genderBias2018/data/E12.csv", stringsAsFactors = F)
d2 = data.frame(
score = tapply(d$Score,d$Number,mean),
gender = tapply(d$FirstAuthGender,d$Number,head,n=1),
status = tapply(d$FirstAuthStatus,d$Number,head,n=1),
SubmissionLength = tapply(d$SubmissionLength)
)
d2$genstatus = paste(d2$status,d2$gender)
library(ggplot2)
ggplot(d2,aes(x=genstatus,y=score)) + geom_violin() + geom_boxplot()
summary(lm(score~gender*status*SubmissionLength,data=d2))
d = read.csv("~/Documents/Conferences/Evolang12/genderBias2018/data/E12.csv", stringsAsFactors = F)
d2 = data.frame(
score = tapply(d$Score,d$Number,mean),
gender = tapply(d$FirstAuthGender,d$Number,head,n=1),
status = tapply(d$FirstAuthStatus,d$Number,head,n=1),
SubmissionLength = tapply(d$SubmissionLength,d$Number,head,n=1)
)
d2$genstatus = paste(d2$status,d2$gender)
library(ggplot2)
ggplot(d2,aes(x=genstatus,y=score)) + geom_violin() + geom_boxplot()
summary(lm(score~gender*status*SubmissionLength,data=d2))
summary(lm(score~gender*SubmissionLength,data=d2))
summary(lm(score~gender*status,data=d2))
d3 = read.table("/Users/sgroberts/Documents/MPI/refLexIron/LexDistances/Lesage/IronLingPy/IronWords2/Data/LingPyOutput/SWADESH_POST_lexstat.qlc", sep="\t",header=T,stringsAsFactors = F, fileEncoding = "UTF-8", encoding = "UTF-8",quote='',skip=7)
head(d3)
length(unique(d3$LEXSTATID))
dim(d3)
d2 = read.table("/Users/sgroberts/Documents/MPI/refLexIron/LexDistances/Lesage/IronLingPy/IronWords2/Data/qlc/Swadesh_lexstat.qlc", sep="\t",header=T,stringsAsFactors = F, fileEncoding = "UTF-8", encoding = "UTF-8", skip=81)
unqiue(unlist(strsplit(d2$TOKENS,"")))
unique(unlist(strsplit(d2$TOKENS,"")))
unique(unlist(strsplit(d2$TOKENS[d2$DOCULECT=="XX205"],"")))
a = d2[d2$DOCULECT=="XX205",]
b = d2[d2$DOCULECT=="luoXaa",]
head(a)
head(b)
unique(a$CONCEPT)
unique(b$CONCEPT)
x = intersect(a$CONCEPT,b$CONCEPT)
x
a[a$CONCEPT %in% x,][order(a$CONCEPT),]
a[a$CONCEPT %in% x,][order(a$CONCEPT),]$COUNTERPART
b[b$CONCEPT %in% x,][order(b$CONCEPT),]$COUNTERPART
d3 = read.table("/Users/sgroberts/Documents/MPI/refLexIron/LexDistances/Lesage/IronLingPy/IronWords2/Programs/Python/SWADESH_POST_lexstat_full.qlc", sep="\t",header=T,stringsAsFactors = F, fileEncoding = "UTF-8", encoding = "UTF-8",quote='',skip=7)
d3 = read.table("/Users/sgroberts/Documents/MPI/refLexIron/LexDistances/Lesage/IronLingPy/IronWords2/Programs/Python/SWADESH_POST_lexstat_full.qlc", sep="\t",header=T,stringsAsFactors = F, fileEncoding = "UTF-8", encoding = "UTF-8",quote='',skip=3)
length(unique(d3$DO))
length(unique(d3$LEXSTATID))
dim(d3)
n = 200
noise = 2
a = rnorm(n)
z = rnorm(n)
c = jitter(z,amount = noise)
b = jitter(c+a,amount = noise)
plot(z,c)
n = 200
noise = 2
a = rnorm(n)
z = rnorm(n)
c = jitter(z,amount = noise)
b = jitter(c+a,amount = noise)
plot(z,c)
summary(lm(c~z + a))
cor(z,c)
cor(a,c)
summary(lm(c~z + a))
n = 200
noise = 4
a = rnorm(n)
z = rnorm(n)
c = jitter(z,amount = noise)
b = jitter(c+a,amount = noise)
plot(z,c)
cor(z,c)
cor(a,c)
summary(lm(c~z + a))
summary(lm(c~z + a + b))
summary(lm(c~z + a))
cor(z,c)
cor(a,c)
plot(z,c)
summary(lm(c~z + a))
summary(lm(c~z + a + b))
m0 = lm(X ~ Y)
summary(m0)
m1 = lm(X ~ Y + A)
summary(m1)
m2 = lm(X ~ Y + A + B)
summary(m2)
m3 = lm(X ~ Y + A + B + C)
summary(m3)
n=200
err = 2
A = rnorm(n)
C = rnorm(n)
B = jitter(A + C,amount=err)
X = jitter(A + B,amount=err)
Y = jitter(X + C,amount=err)
m0 = lm(X ~ Y)
summary(m0)
m1 = lm(X ~ Y + A)
summary(m1)
m2 = lm(X ~ Y + A + B)
summary(m2)
m3 = lm(X ~ Y + A + B + C)
summary(m3)
n=200
err = 5
A = rnorm(n)
C = rnorm(n)
B = jitter(A + C,amount=err)
X = jitter(A + B,amount=err)
Y = jitter(X + C,amount=err)
m0 = lm(X ~ Y)
summary(m0)
m1 = lm(X ~ Y + A)
summary(m1)
m2 = lm(X ~ Y + A + B)
summary(m2)
m3 = lm(X ~ Y + A + B + C)
summary(m3)
n=200
err = 10
A = rnorm(n)
C = rnorm(n)
B = jitter(A + C,amount=err)
X = jitter(A + B,amount=err)
Y = jitter(X + C,amount=err)
m0 = lm(X ~ Y)
summary(m0)
m1 = lm(X ~ Y + A)
summary(m1)
m2 = lm(X ~ Y + A + B)
summary(m2)
m3 = lm(X ~ Y + A + B + C)
summary(m3)
m3 = lm(X ~ Y + C)
summary(m3)
summary(m1)
summary(m3)
m3 = lm(X ~ Y + A + B + C)
summary(m3)
m4 = lm(X ~ Y + C)
summary(m4)
n=200
err = 10
A = rnorm(n)
C = rnorm(n)
B = jitter(A + C,amount=err)
X = jitter(A + B,amount=err)
Y = jitter(X + C,amount=err)
m0 = lm(X ~ Y)
summary(m0)
m1 = lm(X ~ Y + B)
summary(m1)
n=200
err = 10
A = rnorm(n)
C = rnorm(n)
B = jitter(A + C,amount=err)
X = jitter(A + B,amount=err)
Y = jitter((0.35*X) + (0.65*C),amount=err)
m0 = lm(X ~ Y)
summary(m0)
m1 = lm(X ~ Y + B)
summary(m1)
m2 = lm(X ~ Y + A + B)
summary(m2)
m3 = lm(X ~ Y + A + B + C)
summary(m3)
m4 = lm(X ~ Y + C)
summary(m4)
m0 = lm(X ~ Y)
summary(m0)
m1 = lm(X ~ Y + B)
summary(m1)
m4 = lm(X ~ Y + C)
summary(m4)
n=1000
err = 10
A = rnorm(n)
C = rnorm(n)
B = jitter(A + C,amount=err)
X = jitter(A + B,amount=err)
Y = jitter((0.35*X) + (0.65*C),amount=err)
m0 = lm(X ~ Y)
summary(m0)
m1 = lm(X ~ Y + B)
summary(m1)
m2 = lm(X ~ Y + A + B)
summary(m2)
m3 = lm(X ~ Y + A + B + C)
summary(m3)
m4 = lm(X ~ Y + C)
summary(m4)
hist(X)
hist(Y)
hist(Z)
hist(A)
hist(B)
hist(C)
hist(Y)
mean(Y)
summary(m4)
m4 = lm(X ~ 0 + Y + C)
summary(m4)
m0 = lm(X ~ 0 + Y)
summary(m0)
m1 = lm(X ~ 0 + Y + B)
summary(m1)
m2 = lm(X ~ 0 + Y + A + B)
summary(m2)
cor(X,Y)
cor(X,Y)
n=1000
err = 10
A = rnorm(n) + 10
C = rnorm(n) + 10
B = jitter(A + C,amount=err)
X = jitter(A + B,amount=err)
Y = jitter((0.35*X) + (0.65*C),amount=err)
m0 = lm(X ~ Y)
summary(m0)
m1 = lm(X ~ Y + B)
summary(m1)
m2 = lm(X ~ Y + A + B)
summary(m2)
m3 = lm(X ~ Y + A + B + C)
summary(m3)
m4 = lm(X ~ Y + C)
summary(m4)
cor(X,Y)
m1 = lm(X ~ Y + B)
summary(m1)
m2 = lm(X ~ Y + A + B)
summary(m2)
m3 = lm(X ~ Y + A + B + C)
summary(m3)
m4 = lm(X ~ Y + C)
summary(m4)
library(devtools)
install_github("jtextor/dagitty/r")
install.packages("devtools")
install.packages("devtools")
library(devtools)
install_github("jtextor/dagitty/r")
library(dagitty)
g <- dagitty("pdag { x[e] y[o] a -- {i z b}; {a z i} -> x -> y <- {z b} }")
plot(g)
?plot(g)
plot.daggity
plot(g)
?graphLayout
graphLayout(g)
plot(graphLayout(g))
adjustmentSets( g )
graphLayout(g)
g <- dagitty("pdag { x[e] y[o] a -- {i z b}; {a z i} -> x -> y <- {z b} }")
plot(graphLayout(g))
adjustmentSets( g )
plot(graphLayout(g))
# Get historical distances between langauges from phylogentic trees, obtained from D-Place
# Then match up the taxa names to FAIR langauge names
setwd("~/Documents/Bristol/word2vec/word2vec_DPLACE/analysis/")
library(ape)
library(caper)
library(phylobase)
# fair language data
f = read.csv("../data/FAIR_langauges_glotto_xdid.csv", stringsAsFactors = F)
# Indo-European
t = read.nexus("../data/trees/bouckaert_et_al2012-d-place_2.NEXUS")
treenames = read.csv("../data/trees/taxa.csv", stringsAsFactors = F)
# These are not necessarily the right glottocode, but they do link the right data
treenames[treenames$taxon=="Albanian_G",]$glottocode = "gheg1238"
treenames[treenames$taxon=="Greek_Mod",]$glottocode = "mode1248"
# convert tip labels to glotto codes
t$tip.label = treenames[match(t$tip.label,treenames$taxon),]$glottocode
f[f$xd.id %in% t$tip.label,]
keepTip = f[f$glotto %in% t$tip.label,]$glotto
t = drop.tip(t,t$tip.label[!t$tip.label %in% keepTip])
t$tip.label = f[match(t$tip.label,f$glotto),]$Language2
write.tree(t, "../data/trees/FAIR_tree_IndoEuropean.nwk",enco)
t.dist = cophenetic(t)
t.dist.long = melt(t.dist)
library(reshape2)
t.dist.long = melt(t.dist)
head(t.dist.long)
rownames(t.dist)
sort(rownames(t.dist))
write.csv(t.dist.long, file="../data/trees/IndoEuropean_historical_distances_long.csv", row.names = F)
